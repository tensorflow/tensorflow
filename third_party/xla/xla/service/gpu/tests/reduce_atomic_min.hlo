// RUN: hlo-opt %s --platform=gpu --stage=llvm-before-optimizations --xla_gpu_target_config_filename=%S/../../../tools/hlo_opt/gpu_specs/%{GPU}.txtpb | FileCheck %s --check-prefixes=CHECK,CHECK-%{PTX}

// Check that for "min" we are still using atomics (CAS loop).

HloModule MinReduce, is_scheduled=true

Min {
  x.1 = f32[] parameter(0)
  y.1 = f32[] parameter(1)
  ROOT min.1 = f32[] minimum(x.1, y.1)
}

fused_computation {
  param_0 = f32[300000]{0} parameter(0)
  param_1 = f32[] parameter(1)
  ROOT reduce.1 = f32[] reduce(f32[300000]{0} param_0, f32[] param_1), dimensions={0}, to_apply=Min
}

ENTRY reduce.1 {
  parameter = f32[300000] parameter(0)
  init_value = f32[] constant(0)
  ROOT wrapped_reduce = f32[] fusion(f32[300000]{0} parameter, f32[] init_value), kind=kInput, calls=fused_computation
}

// CHECK-LABEL: entry:
// CHECK-PTX:     %[[VAL_0:.*]] = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !4
// CHECK-GCN:     %[[VAL_0:.*]] = call i32 @llvm.amdgcn.workgroup.id.x
// CHECK:         %[[VAL_1:.*]] = zext i32 %[[VAL_0]] to i64
// CHECK-PTX:     %[[VAL_2:.*]] = call i32 @llvm.nvvm.read.ptx.sreg.tid.x(), !range !4
// CHECK-GCN:     %[[VAL_2:.*]] = call i32 @llvm.amdgcn.workitem.id.x
// CHECK:         %[[VAL_3:.*]] = zext i32 %[[VAL_2]] to i64
// CHECK:         %[[VAL_4:.*]] = mul nuw nsw i64 %[[VAL_1]], 1
// CHECK:         %[[VAL_5:.*]] = add nuw nsw i64 %[[VAL_4]], %[[VAL_3]]
// CHECK:         %[[VAL_6:.*]] = icmp ult i64 %[[VAL_5]], 1
// CHECK:         call void @llvm.assume(i1 %[[VAL_6]])
// CHECK:         %[[VAL_7:.*]] = add nuw nsw i64 %[[VAL_5]], 0
// CHECK:         %[[VAL_8:.*]] = icmp ult i64 %[[VAL_5]], 1
// CHECK:         br i1 %[[VAL_8]], label %[[VAL_9:.*]], label %[[VAL_10:.*]]
// CHECK:       wrapped_reduce.in_bounds-after:                   ; preds = %[[VAL_9]], %[[VAL_11:.*]]
// CHECK:         ret void
// CHECK:       wrapped_reduce.in_bounds-true:                    ; preds = %[[VAL_11]]
// CHECK:         %[[VAL_12:.*]] = load float, ptr %[[VAL_13:.*]], align 4, !invariant.load
// CHECK:         store float %[[VAL_12]], ptr %[[VAL_14:.*]], align 4
// CHECK:         br label %[[VAL_10]]
// CHECK:       entry:
// CHECK:         %[[VAL_15:.*]] = alloca i32, align 4
// CHECK:         %[[VAL_16:.*]] = alloca i32, align 4
// CHECK:         %[[VAL_17:.*]] = alloca float, align 4
// CHECK:         %[[VAL_18:.*]] = alloca float, align 4
// CHECK:         %[[VAL_19:.*]] = alloca float, align 4
// CHECK:         %[[VAL_20:.*]] = alloca float, align 4
// CHECK:         %[[VAL_21:.*]] = alloca float, align 4
// CHECK:         %[[VAL_22:.*]] = alloca float, align 4
// CHECK:         %[[VAL_23:.*]] = alloca float, align 4
// CHECK:         %[[VAL_24:.*]] = alloca float, align 4
// CHECK:         %[[VAL_25:.*]] = alloca float, align 4
// CHECK:         %[[VAL_26:.*]] = alloca float, align 4
// CHECK:         %[[VAL_27:.*]] = alloca float, align 4
// CHECK:         %[[VAL_28:.*]] = alloca float, align 4
// CHECK:         %[[VAL_29:.*]] = alloca float, align 4
// CHECK:         %[[VAL_30:.*]] = alloca float, align 4
// CHECK:         %[[VAL_31:.*]] = alloca float, align 4
// CHECK:         %[[VAL_32:.*]] = alloca float, align 4
// CHECK:         %[[VAL_33:.*]] = alloca float, align 4
// CHECK:         %[[VAL_34:.*]] = alloca float, align 4
// CHECK:         %[[VAL_35:.*]] = alloca float, align 4
// CHECK:         %[[VAL_36:.*]] = alloca float, align 4
// CHECK:         %[[VAL_37:.*]] = alloca float, align 4
// CHECK:         %[[VAL_38:.*]] = alloca float, align 4
// CHECK:         %[[LOOP3_I_2:loop[23].invar_address.*]] = alloca i32, align 4
// CHECK-GCN:     %[[VAL_42:return_buffer.*]] = alloca float, align 4
// CHECK:         %[[LOOP2_I_2:loop2.invar_address.*]] = alloca i32, align 4
// CHECK-PTX:     %[[VAL_42:return_buffer.*]] = alloca float, align 4
// CHECK-PTX:     %[[VAL_40:.*]] = alloca i32, align 4
// CHECK-PTX:     %[[VAL_43:.*]] = alloca i32, align 4
// CHECK:         %partial_reduction_result = alloca float, align 4
// CHECK:         %reduction_input_address = alloca float, align 4
// CHECK-PTX:     %[[VAL_47:.*]] = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.y(), !range !4
// CHECK-GCN:     %[[VAL_47:.*]] = call i32 @llvm.amdgcn.workgroup.id.y
// CHECK:         %[[VAL_48:.*]] = icmp eq i32 %[[VAL_47]], 0
// CHECK:         br i1 %[[VAL_48]], label %[[VAL_49:.*]], label %[[VAL_50:.*]]
// CHECK:       reduce-group-0-after:                             ; preds = %[[VAL_51:.*]], %[[VAL_52:.*]]
// CHECK:         ret void
// CHECK:       reduce-group-0-true:                              ; preds = %[[VAL_52]]
// CHECK:         %[[VAL_53:.*]] = load float, ptr %[[VAL_54:.*]], align 4, !invariant.load !{{[0-9]}}
// CHECK:         store float %[[VAL_53]], ptr{{.*}} %partial_reduction_result, align 4
// CHECK-PTX:     %thread.id.x = call i32 @llvm.nvvm.read.ptx.sreg.tid.x(), !range !6
// CHECK-GCN:     %thread.id.x = call i32 @llvm.amdgcn.workitem.id.x
// CHECK-PTX:     %block.id.x = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x(), !range !7
// CHECK-GCN:     %block.id.x = call i32 @llvm.amdgcn.workgroup.id.x
// CHECK:         %thread.id.2 = urem i32 %thread.id.x, 1024
// CHECK:         %lane_id = urem i32 %thread.id.x, 32
// CHECK-PTX:     %[[VAL_63:.*]] = udiv i32 %block.id.x, 1
// CHECK-PTX:     %[[VECTOR_OFFSET:.*]] = urem i32 %[[VAL_63]], 1
// CHECK:         %[[VAL_63_2:.*]] = udiv i32 %block.id.x, 1
// CHECK:         %[[VAL_64:.*]] = urem i32 %[[VAL_63_2]], 19
// CHECK:         %[[VAL_65:.*]] = udiv i32 %block.id.x, 19
// CHECK:         %[[VAL_66:.*]] = urem i32 %[[VAL_65]], 1
// CHECK:         %[[VAL_67:.*]] = udiv i32 %block.id.x, 19
// CHECK:         %[[VAL_68:.*]] = icmp eq i32 %[[VAL_64]], 18
// CHECK-PTX:     %tile_bound.2 = select i1 %[[VAL_68]], i32 2544, i32 8192
// CHECK-GCN:     %tile_bound.2 = select i1 %[[VAL_68]], i32 5088, i32 16384
// CHECK:         %tile_origin.0 = mul i32 %[[VAL_67]], 1
// CHECK:         %tile_origin.1 = mul i32 %[[VAL_66]], 1
// CHECK-PTX:     %tile_origin.2 = mul i32 %[[VAL_64]], 8192
// CHECK-GCN:     %tile_origin.2 = mul i32 %[[VAL_64]], 16384
// CHECK-PTX:     %tile_origin.3 = mul i32 %[[VECTOR_OFFSET]], 2
// CHECK-PTX:     %[[VAL_81:.*]] = icmp eq i32 8192, %tile_bound.2
// CHECK-GCN:     %[[VAL_81:.*]] = icmp eq i32 16384, %tile_bound.2
// CHECK:         br i1 %[[VAL_81]], label %[[VAL_82:.*]], label %[[VAL_83:.*]]
// CHECK:       is_full_tile-after:                               ; preds = %[[VAL_84:.*]], %[[VAL_85:.*]]
// CHECK:         %[[VAL_86:.*]] = load float, ptr{{.*}} %partial_reduction_result, align 4
// CHECK-PTX:     %[[VAL_87:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_86]], i32 16, i32 31)
// CHECK-GCN:     %[[VAL_87_1:.*]] = bitcast float %[[VAL_86]] to i32
// CHECK-GCN:     %[[VAL_87_2:.*]] = call i32 @__ockl_readuplane_i32
// CHECK-GCN:     %[[VAL_87:.*]] = bitcast i32 %[[VAL_87_2]] to float 
// CHECK:         store float %[[VAL_87]], ptr{{.*}} %[[VAL_37]], align 4
// CHECK-GCN:     %[[VAL_88_1:.*]] = addrspacecast ptr{{.*}} %partial_reduction_result to ptr
// CHECK-GCN:     %[[VAL_88_2:.*]] = addrspacecast ptr{{.*}} %[[VAL_37]] to ptr
// CHECK-GCN:     %[[VAL_88_3:.*]] = addrspacecast ptr{{.*}} %[[VAL_36]] to ptr
// CHECK-PTX:     call void @[[MIN:Min.*]](ptr %partial_reduction_result, ptr %[[VAL_37]], ptr %[[VAL_36]])
// CHECK-GCN:     call void @[[MIN:Min.*]](ptr %[[VAL_88_1]], ptr %[[VAL_88_2]], ptr %[[VAL_88_3]])
// CHECK:         %[[VAL_88:.*]] = load float, ptr{{.*}} %[[VAL_36]], align 4
// CHECK:         store float %[[VAL_88]], ptr{{.*}} %partial_reduction_result, align 4
// CHECK:         %[[VAL_89:.*]] = load float, ptr{{.*}} %partial_reduction_result, align 4
// CHECK-PTX:     %[[VAL_90:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_89]], i32 8, i32 31)
// CHECK-GCN:     %[[VAL_90_1:.*]] = bitcast float %[[VAL_89]] to i32
// CHECK-GCN:     %[[VAL_90_2:.*]] = call i32 @__ockl_readuplane_i32
// CHECK-GCN:     %[[VAL_90:.*]] = bitcast i32 %[[VAL_90_2]] to float
// CHECK:         store float %[[VAL_90]], ptr{{.*}} %[[VAL_35]], align 4
// CHECK-GCN:     %[[VAL_91_1:.*]] = addrspacecast ptr{{.*}} %partial_reduction_result to ptr
// CHECK-GCN:     %[[VAL_91_2:.*]] = addrspacecast ptr{{.*}} %[[VAL_35]] to ptr
// CHECK-GCN:     %[[VAL_91_3:.*]] = addrspacecast ptr{{.*}} %[[VAL_34]] to ptr
// CHECK-PTX:     call void @[[MIN]](ptr %partial_reduction_result, ptr %[[VAL_35]], ptr %[[VAL_34]])
// CHECK-GCN:     call void @[[MIN]](ptr %[[VAL_91_1]], ptr %[[VAL_91_2]], ptr %[[VAL_91_3]])
// CHECK:         %[[VAL_91:.*]] = load float, ptr{{.*}} %[[VAL_34]], align 4
// CHECK:         store float %[[VAL_91]], ptr{{.*}} %partial_reduction_result, align 4
// CHECK:         %[[VAL_92:.*]] = load float, ptr{{.*}} %partial_reduction_result, align 4
// CHECK-PTX:     %[[VAL_93:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_92]], i32 4, i32 31)
// CHECK-GCN:     %[[VAL_93_1:.*]] = bitcast float %[[VAL_92]] to i32
// CHECK-GCN:     %[[VAL_93_2:.*]] = call i32 @__ockl_readuplane_i32
// CHECK-GCN:     %[[VAL_93:.*]] = bitcast i32 %[[VAL_93_2]] to float
// CHECK:         store float %[[VAL_93]], ptr{{.*}} %[[VAL_33]], align 4
// CHECK-GCN:     %[[VAL_94_1:.*]] = addrspacecast ptr{{.*}} %partial_reduction_result to ptr
// CHECK-GCN:     %[[VAL_94_2:.*]] = addrspacecast ptr{{.*}} %[[VAL_33]] to ptr
// CHECK-GCN:     %[[VAL_94_3:.*]] = addrspacecast ptr{{.*}} %[[VAL_32]] to ptr
// CHECK-PTX:     call void @[[MIN]](ptr %partial_reduction_result, ptr %[[VAL_33]], ptr %[[VAL_32]])
// CHECK-GCN:     call void @[[MIN]](ptr %[[VAL_94_1]], ptr %[[VAL_94_2]], ptr %[[VAL_94_3]])
// CHECK:         %[[VAL_94:.*]] = load float, ptr{{.*}} %[[VAL_32]], align 4
// CHECK:         store float %[[VAL_94]], ptr{{.*}} %partial_reduction_result, align 4
// CHECK:         %[[VAL_95:.*]] = load float, ptr{{.*}} %partial_reduction_result, align 4
// CHECK-PTX:     %[[VAL_96:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_95]], i32 2, i32 31)
// CHECK-GCN:      %[[VAL_96_1:.*]] = bitcast float %[[VAL_95]] to i32
// CHECK-GCN:      %[[VAL_96_2:.*]] = call i32 @__ockl_readuplane_i32
// CHECK-GCN:      %[[VAL_96:.*]] = bitcast i32 %[[VAL_96_2]] to float
// CHECK:         store float %[[VAL_96]], ptr{{.*}} %[[VAL_31]], align 4
// CHECK-GCN:     %[[VAL_97_1:.*]] = addrspacecast ptr{{.*}} %partial_reduction_result to ptr
// CHECK-GCN:     %[[VAL_97_2:.*]] = addrspacecast ptr{{.*}} %[[VAL_31]] to ptr
// CHECK-GCN:     %[[VAL_97_3:.*]] = addrspacecast ptr{{.*}} %[[VAL_30]] to ptr
// CHECK-PTX:     call void @[[MIN]](ptr %partial_reduction_result, ptr %[[VAL_31]], ptr %[[VAL_30]])
// CHECK-GCN:     call void @[[MIN]](ptr %[[VAL_97_1]], ptr %[[VAL_97_2]], ptr %[[VAL_97_3]])
// CHECK:         %[[VAL_97:.*]] = load float, ptr{{.*}} %[[VAL_30]], align 4
// CHECK:         store float %[[VAL_97]], ptr{{.*}} %partial_reduction_result, align 4
// CHECK:         %[[VAL_98:.*]] = load float, ptr{{.*}} %partial_reduction_result, align 4
// CHECK-PTX:     %[[VAL_99:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_98]], i32 1, i32 31)
// CHECK-GCN:     %[[VAL_99_1:.*]] = bitcast float %[[VAL_98]] to i32
// CHECK-GCN:     %[[VAL_99_2:.*]] = call i32 @__ockl_readuplane_i32
// CHECK-GCN:     %[[VAL_99:.*]] = bitcast i32 %[[VAL_99_2]] to float
// CHECK:         store float %[[VAL_99]], ptr{{.*}} %[[VAL_29]], align 4
// CHECK-GCN:     %[[VAL_100_1:.*]] = addrspacecast ptr{{.*}} %partial_reduction_result to ptr
// CHECK-GCN:     %[[VAL_100_2:.*]] = addrspacecast ptr{{.*}} %[[VAL_29]] to ptr
// CHECK-GCN:     %[[VAL_100_3:.*]] = addrspacecast ptr{{.*}} %[[VAL_28]] to ptr
// CHECK-PTX:     call void @[[MIN]](ptr %partial_reduction_result, ptr %[[VAL_29]], ptr %[[VAL_28]])
// CHECK-GCN:     call void @[[MIN]](ptr %[[VAL_100_1]], ptr %[[VAL_100_2]], ptr %[[VAL_100_3]])
// CHECK:         %[[VAL_100:.*]] = load float, ptr{{.*}} %[[VAL_28]], align 4
// CHECK:         store float %[[VAL_100]], ptr{{.*}} %partial_reduction_result, align 4
// CHECK:         %[[VAL_101:.*]] = udiv i32 %thread.id.2, 32
// CHECK:         br i1 true, label %[[VAL_105:.*]], label %[[VAL_51]]

// CHECK:       thread_in_bounds-after:
// CHECK:         br label %[[VAL_50]]
// CHECK:       is_full_tile-true:
// CHECK-PTX:     store i32 0, ptr{{.*}} %[[VAL_43]], align 4
// CHECK-GCN:     store i32 0, ptr{{.*}} %[[LOOP2_I_2]], align 4
// CHECK:         br label %[[VAL_107:.*]]
// CHECK:       loop2.loop_header:                                ; preds = %[[VAL_108:.*]], %[[VAL_82]]
// CHECK-PTX:     %[[VAL_109:.*]] = load i32, ptr %[[VAL_43]], align 4
// CHECK-GCN:     %[[VAL_109:.*]] = load i32, ptr{{.*}} %[[LOOP2_I_2]], align 4
// CHECK:         %[[VAL_110:.*]] = icmp uge i32 %[[VAL_109]], 
// CHECK:         br i1 %[[VAL_110]], label %loop2.loop_exit, label %loop2.loop_body

// CHECK:       loop2.loop_body:                                  ; preds = %[[VAL_107]]
// CHECK:         %[[VAL_111:.*]] = add nuw nsw i32 %[[VAL_109]], 1
// CHECK-PTX:     store i32 %[[VAL_111]], ptr %[[VAL_43]], align 4
// CHECK-GCN:     store i32 %[[VAL_111]], ptr{{.*}} %[[LOOP2_I_2]], align 4
// CHECK:         %[[OFFSET_2:.*]] = add i32 %loop2.indvar, %thread.id.2
// CHECK-GCN:     %[[START_0:.*]] = add i32 %tile_origin.0, 0
// CHECK-GCN:     %[[START_1:.*]] = add i32 %tile_origin.1, 0
// CHECK-GCN:     %[[START_2:.*]] = add i32 %tile_origin.2, %[[OFFSET_2]]
// CHECK-GCN:     %[[VAL_119:.*]] = getelementptr inbounds [300000 x float], ptr %[[VAL_120:.*]], i32 0, i32 %[[START_2]]
// CHECK-GCN:     %[[VAL_121:.*]] = load float, ptr %[[VAL_119]], align 4, !invariant.load !3
// CHECK-GCN:     store float %[[VAL_121]], ptr{{.*}} %reduction_input_address, align 4
// CHECK-GCN:     %[[VAL_123_1:.*]] = addrspacecast ptr addrspace(5) %partial_reduction_result to ptr
// CHECK-GCN:     %[[VAL_123_2:.*]] = addrspacecast ptr addrspace(5) %reduction_input_address to ptr
// CHECK-GCN:     %[[VAL_123_3:.*]] = addrspacecast ptr addrspace(5) %[[VAL_42]] to ptr
// CHECK-GCN:     call void @[[MIN]](ptr %[[VAL_123_1]], ptr %[[VAL_123_2]], ptr %[[VAL_123_3]])
// CHECK-GCN:     %[[VAL_123:.*]] = load float, ptr{{.*}} %[[VAL_42]], align 4
// CHECK-GCN:     store float %[[VAL_123]], ptr{{.*}} %partial_reduction_result, align 4
// CHECK-GCN:     br label %loop2.loop_header
// CHECK-PTX:     store i32 0, ptr %loop3.invar_address, align 4
// CHECK-PTX:     br label %loop3.loop_header

// CHECK-PTX:   loop3.loop_header:
// CHECK-PTX:     %loop3.indvar = load i32, ptr %loop3.invar_address, align 4
// CHECK-PTX:     %[[LOOP3_OOB:.*]] = icmp uge i32 %loop3.indvar, 2
// CHECK-PTX:     br i1 %[[LOOP3_OOB]], label %loop3.loop_exit, label %loop3.loop_body
// CHECK-PTX:   loop3.loop_body:
// CHECK-PTX:     %[[LOOP3_INC:.*]] = add nuw nsw i32 %loop3.indvar, 1
// CHECK-PTX:     store i32 %[[LOOP3_INC]], ptr %loop3.invar_address, align 4
// CHECK-PTX:     %[[START_0:.*]] = add i32 %tile_origin.0, 0
// CHECK-PTX:     %[[START_1:.*]] = add i32 %tile_origin.1, 0
// CHECK-PTX:     %[[START_2:.*]] = add i32 %tile_origin.2, %[[OFFSET_2]]
// CHECK-PTX:     %[[START_3:.*]] = add i32 %tile_origin.3, %loop3.indvar
// CHECK-PTX:     %[[VAL_113:.*]] = mul nuw nsw i32 %[[START_3]], 1
// CHECK-PTX:     %[[VAL_114:.*]] = add nuw nsw i32 0, %[[VAL_113]]
// CHECK-PTX:     %[[VAL_115:.*]] = mul nuw nsw i32 %[[START_2]], 2
// CHECK-PTX:     %[[VAL_116:.*]] = add nuw nsw i32 %[[VAL_114]], %[[VAL_115]]
// CHECK-PTX:     %[[VAL_119:.*]] = getelementptr inbounds [300000 x float], ptr %[[VAL_120:.*]], i32 0, i32 %[[VAL_116]]
// CHECK-PTX:     %[[VAL_121:.*]] = load float, ptr %[[VAL_119]], align 4, !invariant.load !5
// CHECK-PTX:     store float %[[VAL_121]], ptr %reduction_input_address, align 4
// CHECK-PTX:     call void @[[MIN]](ptr %partial_reduction_result, ptr %reduction_input_address, ptr %[[VAL_42]])
// CHECK-PTX:     %[[VAL_123:.*]] = load float, ptr %[[VAL_42]], align 4
// CHECK-PTX:     store float %[[VAL_123]], ptr %partial_reduction_result, align 4
// CHECK-PTX:     br label %loop3.loop_header
// CHECK-PTX:   loop3.loop_exit:
// CHECK-PTX:     br label %loop2.loop_header

// CHECK:       loop2.loop_exit:
// CHECK:         br label %is_full_tile-after

// CHECK:       is_full_tile-false:
// CHECK-PTX:     store i32 0, ptr %[[LOOP2_I_2]], align 4
// CHECK-GCN:     store i32 0, ptr{{.*}} %[[LOOP3_I_2]], align 4
// CHECK:         br label %[[VAL_134:.*]]

// CHECK:       loop2.loop_header{{(4|3)}}:
// CHECK-PTX:     %[[VAL_136:.*]] = load i32, ptr %[[LOOP2_I_2]], align 4
// CHECK-GCN:     %[[VAL_136:.*]] = load i32, ptr{{.*}} %[[LOOP3_I_2]], align 4
// CHECK:         %[[VAL_137:.*]] = icmp uge i32 %[[VAL_136]], {{(8|16384)}}
// CHECK:         br i1 %[[VAL_137]], label %[[VAL_84]], label %[[VAL_138:.*]]

// CHECK:       loop2.loop_body{{(5|4)}}:
// CHECK:         %[[VAL_139:.*]] = add nuw nsw i32 %[[VAL_136]], 1
// CHECK-PTX:     store i32 %[[VAL_139]], ptr %[[LOOP2_I_2]], align 4
// CHECK-GCN:     store i32 %[[VAL_139]], ptr{{.*}} %[[LOOP3_I_2]], align 4
// CHECK:         %[[VAL_141:.*]] = add i32 %[[VAL_136]], %thread.id.2
// CHECK:         %[[VAL_144:.*]] = icmp ult i32 %[[VAL_141]], %tile_bound.2
// CHECK:         br i1 %[[VAL_144]], label %x_in_tile-true, label %x_in_tile-after

// CHECK:       x_in_tile-after:
// CHECK:         br label %loop2.loop_header{{(4|3)}}

// CHECK:       loop2.loop_exit{{(3|2)}}:
// CHECK:         br label %is_full_tile-after

// CHECK:       x_in_tile-true:                                   ; preds = %[[VAL_138]]
// CHECK-GCN:     %[[IDX0:.*]] = add i32 %tile_origin.0, 0
// CHECK-GCN:     %[[IDX1:.*]] = add i32 %tile_origin.1, 0
// CHECK-GCN:     %[[IDX2:.*]] = add i32 %tile_origin.2, %[[VAL_141]]
// CHECK-GCN:     %[[VAL_155:.*]] = getelementptr inbounds [300000 x float], ptr %[[VAL_120]], i32 0, i32 %[[IDX2]]
// CHECK-GCN:     %[[VAL_156:.*]] = load float, ptr %[[VAL_155]], align 4, !invariant.load !3
// CHECK-GCN:     store float %[[VAL_156]], ptr{{.*}} %reduction_input_address, align 4
// CHECK-GCN:     %[[VAL_158_1:.*]] = addrspacecast ptr addrspace(5) %partial_reduction_result to ptr
// CHECK-GCN:     %[[VAL_158_2:.*]] = addrspacecast ptr addrspace(5) %reduction_input_address to ptr
// CHECK-GCN:     %[[VAL_158_3:.*]] = addrspacecast ptr addrspace(5) %[[VAL_38]] to ptr
// CHECK-GCN:     call void @[[MIN]](ptr %[[VAL_158_1]], ptr %[[VAL_158_2]], ptr %[[VAL_158_3]])
// CHECK-GCN:     %[[VAL_158:.*]] = load float, ptr{{.*}} %[[VAL_38]], align 4
// CHECK-GCN:     store float %[[VAL_158]], ptr{{.*}} %partial_reduction_result, align 4
// CHECK-GCN:     br label %x_in_tile-after
// CHECK-PTX:     store i32 0, ptr %[[LOOP3_I_2]], align 4
// CHECK-PTX:     br label %loop3.loop_header10

// CHECK-PTX:   loop3.loop_header10:
// CHECK-PTX:      %[[VAL_145:.*]] = load i32, ptr %[[LOOP3_I_2]], align 4
// CHECK-PTX:      %[[VAL_146:.*]] = icmp uge i32 %[[VAL_145]], 2
// CHECK-PTX:      br i1 %[[VAL_146]], label %loop3.loop_exit9, label %loop3.loop_body11

// CHECK-PTX:   loop3.loop_body11:
// CHECK-PTX:      %[[VAL_147:.*]] = add nuw nsw i32 %[[VAL_145]], 1
// CHECK-PTX:      store i32 %[[VAL_147]], ptr %[[LOOP3_I_2]], align 4
// CHECK-PTX:      %[[IDX0:.*]] = add i32 %tile_origin.0, 0
// CHECK-PTX:      %[[IDX1:.*]] = add i32 %tile_origin.1, 0
// CHECK-PTX:      %[[IDX2:.*]] = add i32 %tile_origin.2, %[[VAL_141]]
// CHECK-PTX:      %[[IDX3:.*]] = add i32 %tile_origin.3, %[[VAL_145]]
// CHECK-PTX:      %[[VAL_148:.*]] = mul nuw nsw i32 %[[IDX3]], 1
// CHECK-PTX:      %[[VAL_149:.*]] = add nuw nsw i32 0, %[[VAL_148]]
// CHECK-PTX:      %[[VAL_150:.*]] = mul nuw nsw i32 %[[IDX2]], 2
// CHECK-PTX:      %[[VAL_151:.*]] = add nuw nsw i32 %[[VAL_149]], %[[VAL_150]]
// CHECK-PTX:      %[[VAL_155:.*]] = getelementptr inbounds [300000 x float], ptr %[[VAL_120]], i32 0, i32 %[[VAL_151]]
// CHECK-PTX:      %[[VAL_156:.*]] = load float, ptr %[[VAL_155]], align 4, !invariant.load !5
// CHECK-PTX:      store float %[[VAL_156]], ptr %reduction_input_address, align 4
// CHECK-PTX:      call void @[[MIN]](ptr %partial_reduction_result, ptr %reduction_input_address, ptr %[[VAL_38]])
// CHECK-PTX:      %[[VAL_158:.*]] = load float, ptr %[[VAL_38]], align 4
// CHECK-PTX:      store float %[[VAL_158]], ptr %partial_reduction_result, align 4
// CHECK-PTX:      br label %loop3.loop_header10

// CHECK-PTX:   loop3.loop_exit9:
// CHECK-PTX:     br label %x_in_tile-after

// CHECK:       thread_in_bounds-true:
// CHECK:         %[[VAL_166:.*]] = icmp eq i32 %lane_id, 0
// CHECK:         br i1 %[[VAL_166]], label %[[VAL_167:.*]], label %[[VAL_168:.*]]

// CHECK:       intra_warp_reduce_write-after:                    ; preds = %[[VAL_167]], %[[VAL_105]]
// CHECK-GCM:     fence syncscope("workgroup") seq_cst
// CHECK-GCM:     call void @llvm.amdgcn.s.barrier()
// CHECK-PTX:     call void @llvm.nvvm.barrier0()
// CHECK:         %[[VAL_169:.*]] = icmp eq i32 %[[VAL_101]], 0
// CHECK:         br i1 %[[VAL_169]], label %inter_warp_reduce-true, label %inter_warp_reduce-after
// CHECK:       inter_warp_reduce-after:                          ; preds = %[[VAL_171:.*]], %[[VAL_168]]
// CHECK:         br label %[[VAL_51]]
// CHECK:       intra_warp_reduce_write-true:                     ; preds = %[[VAL_105]]
// CHECK:         %[[VAL_172:.*]] = load float, ptr{{.*}} %partial_reduction_result, align 4
// CHECK:         %[[VAL_173:.*]] = getelementptr inbounds [1 x [32 x float]], ptr addrspace(3) @shared_cache, i32 0, i32 0, i32 %[[VAL_101]]
// CHECK:         %[[VAL_174:.*]] = addrspacecast ptr addrspace(3) %[[VAL_173]] to ptr
// CHECK:         store float %[[VAL_172]], ptr %[[VAL_174]], align 4
// CHECK:         br label %[[VAL_168]]
// CHECK:       inter_warp_reduce-true:                           ; preds = %[[VAL_168]]
// CHECK:         %[[VAL_175:.*]] = getelementptr inbounds [1 x [32 x float]], ptr addrspace(3) @shared_cache, i32 0, i32 0, i32 %lane_id
// CHECK:         %[[VAL_176:.*]] = addrspacecast ptr addrspace(3) %[[VAL_175]] to ptr
// CHECK-GCN:     %[[VAL_176_1:.*]] = addrspacecast ptr addrspace(5) %[[VAL_27]] to ptr
// CHECK-GCN:     store float %[[VAL_53]], ptr{{.*}} %[[VAL_176_1]], align 4
// CHECK-PTX:     store float %[[VAL_53]], ptr %[[VAL_27]], align 4
// CHECK:         %[[VAL_177:.*]] = icmp ult i32 %thread.id.2, 32
// CHECK-GCN:     %[[VAL_178:.*]] = select i1 %[[VAL_177]], ptr %[[VAL_176]], ptr %[[VAL_176_1]]
// CHECK-PTX:     %[[VAL_178:.*]] = select i1 %[[VAL_177]], ptr %[[VAL_176]], ptr %[[VAL_27]]
// CHECK:         %[[VAL_179:.*]] = load float, ptr %[[VAL_178]], align 4
// CHECK-GCN:     %[[VAL_179_1:.*]] = bitcast float %[[VAL_179]] to i32
// CHECK-GCN:     %[[VAL_180:.*]] = call i32 @__ockl_readuplane_i32(i32 %[[VAL_179_1]], i32 16)
// CHECK-GCN:     %[[VAL_180_1:.*]] = bitcast i32 %[[VAL_180]] to float
// CHECK-GCN:     store float %[[VAL_180_1]], ptr{{.*}} %[[VAL_26]], align 4
// CHECK-PTX:     %[[VAL_180:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_179]], i32 16, i32 31)
// CHECK-PTX:     store float %[[VAL_180]], ptr %[[VAL_26]], align 4
// CHECK-GCN:     %[[VAL_181_2:.*]] = addrspacecast ptr addrspace(5) %[[VAL_26]] to ptr
// CHECK-GCN:     %[[VAL_181_3:.*]] = addrspacecast ptr addrspace(5) %[[VAL_25]] to ptr
// CHECK-GCN:     call void @[[MIN]](ptr %[[VAL_178]], ptr %[[VAL_181_2]], ptr %[[VAL_181_3]])
// CHECK-PTX:     call void @[[MIN]](ptr %[[VAL_178]], ptr %[[VAL_26]], ptr %[[VAL_25]])
// CHECK:         %[[VAL_181:.*]] = load float, ptr{{.*}} %[[VAL_25]], align 4
// CHECK:         store float %[[VAL_181]], ptr %[[VAL_178]], align 4
// CHECK:         %[[VAL_182:.*]] = load float, ptr %[[VAL_178]], align 4
// CHECK-GCN:     %[[VAL_182_1:.*]] = bitcast float %[[VAL_182]] to i32
// CHECK-GCN:     %[[VAL_183:.*]] = call i32 @__ockl_readuplane_i32(i32 %[[VAL_182_1]], i32 8)
// CHECK-GCN:     %[[VAL_183_1:.*]] = bitcast i32 %[[VAL_183]] to float
// CHECK-GCN:     store float %[[VAL_183_1]], ptr{{.*}} %[[VAL_24]], align 4
// CHECK-PTX:     %[[VAL_183:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_182]], i32 8, i32 31)
// CHECK-PTX:     store float %[[VAL_183]], ptr %[[VAL_24]], align 4
// CHECK-GCN:     %[[VAL_184_2:.*]] = addrspacecast ptr addrspace(5) %[[VAL_24]] to ptr
// CHECK-GCN:     %[[VAL_184_3:.*]] = addrspacecast ptr addrspace(5) %[[VAL_23]] to ptr
// CHECK-GCN:     call void @[[MIN]](ptr %[[VAL_178]], ptr %[[VAL_184_2]], ptr %[[VAL_184_3]])
// CHECK-PTX:     call void @[[MIN]](ptr %[[VAL_178]], ptr %[[VAL_24]], ptr %[[VAL_23]])
// CHECK:         %[[VAL_184:.*]] = load float, ptr{{.*}} %[[VAL_23]], align 4
// CHECK:         store float %[[VAL_184]], ptr %[[VAL_178]], align 4
// CHECK:         %[[VAL_185:.*]] = load float, ptr %[[VAL_178]], align 4
// CHECK-GCN:     %[[VAL_185_1:.*]] = bitcast float %[[VAL_185]] to i32
// CHECK-GCN:     %[[VAL_186:.*]] = call i32 @__ockl_readuplane_i32(i32 %[[VAL_185_1]], i32 4)
// CHECK-GCN:     %[[VAL_186_1:.*]] = bitcast i32 %[[VAL_186]] to float
// CHECK-GCN:     store float %[[VAL_186_1]], ptr{{.*}} %[[VAL_22]], align 4
// CHECK-PTX:     %[[VAL_186:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_185]], i32 4, i32 31)
// CHECK-PTX:     store float %[[VAL_186]], ptr %[[VAL_22]], align 4
// CHECK-GCN:     %[[VAL_187_2:.*]] = addrspacecast ptr addrspace(5) %[[VAL_22]] to ptr
// CHECK-GCN:     %[[VAL_187_3:.*]] = addrspacecast ptr addrspace(5) %[[VAL_21]] to ptr
// CHECK-GCN:     call void @[[MIN]](ptr %[[VAL_178]], ptr %[[VAL_187_2]], ptr %[[VAL_187_3]])
// CHECK-PTX:     call void @[[MIN]](ptr %[[VAL_178]], ptr %[[VAL_22]], ptr %[[VAL_21]])
// CHECK:         %[[VAL_187:.*]] = load float, ptr{{.*}} %[[VAL_21]], align 4
// CHECK:         store float %[[VAL_187]], ptr %[[VAL_178]], align 4
// CHECK:         %[[VAL_188:.*]] = load float, ptr %[[VAL_178]], align 4
// CHECK-GCN:     %[[VAL_188_1:.*]] = bitcast float %[[VAL_188]] to i32
// CHECK-GCN:     %[[VAL_189:.*]] = call i32 @__ockl_readuplane_i32(i32 %[[VAL_188_1]], i32 2)
// CHECK-GCN:     %[[VAL_189_1:.*]] = bitcast i32 %[[VAL_189]] to float
// CHECK-GCN:     store float %[[VAL_189_1]], ptr{{.*}} %[[VAL_20]], align 4
// CHECK-PTX:     %[[VAL_189:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_188]], i32 2, i32 31)
// CHECK-PTX:     store float %[[VAL_189]], ptr %[[VAL_20]], align 4
// CHECK-GCN:     %[[VAL_190_2:.*]] = addrspacecast ptr addrspace(5) %[[VAL_20]] to ptr
// CHECK-GCN:     %[[VAL_190_3:.*]] = addrspacecast ptr addrspace(5) %[[VAL_19]] to ptr
// CHECK-GCN:     call void @[[MIN]](ptr %[[VAL_178]], ptr %[[VAL_190_2]], ptr %[[VAL_190_3]])
// CHECK-PTX:     call void @[[MIN]](ptr %[[VAL_178]], ptr %[[VAL_20]], ptr %[[VAL_19]])
// CHECK:         %[[VAL_190:.*]] = load float, ptr{{.*}} %[[VAL_19]], align 4
// CHECK:         store float %[[VAL_190]], ptr %[[VAL_178]], align 4
// CHECK:         %[[VAL_191:.*]] = load float, ptr %[[VAL_178]], align 4
// CHECK-GCN:     %[[VAL_191_1:.*]] = bitcast float %[[VAL_191]] to i32
// CHECK-GCN:     %[[VAL_192:.*]] = call i32 @__ockl_readuplane_i32(i32 %[[VAL_191_1]], i32 1)
// CHECK-GCN:     %[[VAL_192_1:.*]] = bitcast i32 %[[VAL_192]] to float
// CHECK-GCN:     store float %[[VAL_192_1]], ptr{{.*}} %[[VAL_18]], align 4
// CHECK-PTX:     %[[VAL_192:.*]] = call float @llvm.nvvm.shfl.sync.down.f32(i32 -1, float %[[VAL_191]], i32 1, i32 31)
// CHECK-PTX:     store float %[[VAL_192]], ptr %[[VAL_18]], align 4
// CHECK-GCN:     %[[VAL_193_2:.*]] = addrspacecast ptr addrspace(5) %[[VAL_18]] to ptr
// CHECK-GCN:     %[[VAL_193_3:.*]] = addrspacecast ptr addrspace(5) %[[VAL_17]] to ptr
// CHECK-GCN:     call void @[[MIN]](ptr %[[VAL_178]], ptr %[[VAL_193_2]], ptr %[[VAL_193_3]])
// CHECK-PTX:     call void @[[MIN]](ptr %[[VAL_178]], ptr %[[VAL_18]], ptr %[[VAL_17]])
// CHECK:         %[[VAL_193:.*]] = load float, ptr{{.*}} %[[VAL_17]], align 4
// CHECK:         store float %[[VAL_193]], ptr %[[VAL_178]], align 4
// CHECK:         %[[VAL_194:.*]] = icmp eq i32 %thread.id.2, 0
// CHECK:         br i1 %[[VAL_194]], label %[[VAL_195:.*]], label %[[VAL_171]]
// CHECK:       reduction_write_output-after:
// CHECK:         br label %inter_warp_reduce-after
// CHECK:       reduction_write_output-true:
// CHECK:         %[[VAL_200:.*]] = load float, ptr %[[VAL_178]], align 4
// CHECK:         %[[VAL_201:.*]] = load i32, ptr %[[VAL_202:.*]], align 4
// CHECK:         store i32 %[[VAL_201]], ptr{{.*}} %[[VAL_16]], align 4
// CHECK:         br label %[[VAL_203:.*]]
// CHECK:       atomic_op_loop_exit:                              ; preds = %[[VAL_204:.*]], %[[VAL_203]]
// CHECK:         br label %[[VAL_171]]
// CHECK:       atomic_op_loop_body:                              ; preds = %[[VAL_204]], %[[VAL_195]]
// CHECK:         %[[VAL_205:.*]] = load i32, ptr{{.*}} %[[VAL_16]], align 4
// CHECK:         store i32 %[[VAL_205]], ptr{{.*}} %[[VAL_15]], align 4
// CHECK-GCN:     %[[VAL_206_1:.*]] = addrspacecast ptr addrspace(5) %[[VAL_15]] to ptr
// CHECK-GCN:     %[[VAL_206_2:.*]] = addrspacecast ptr addrspace(5) %[[VAL_15]] to ptr
// CHECK-GCN:     call void @[[MIN]](ptr %[[VAL_206_1]], ptr %[[VAL_178]], ptr %[[VAL_206_2]])
// CHECK-PTX:     call void @[[MIN]](ptr %[[VAL_15]], ptr %[[VAL_178]], ptr %[[VAL_15]])
// CHECK:         %[[VAL_206:.*]] = load i32, ptr{{.*}} %[[VAL_15]], align 4
// CHECK:         %[[VAL_207:.*]] = icmp eq i32 %[[VAL_205]], %[[VAL_206]]
// CHECK:         br i1 %[[VAL_207]], label %atomic_op_loop_exit, label %atomic_op_loop_cas
// CHECK:       atomic_op_loop_cas:                               ; preds = %[[VAL_203]]
// CHECK:         %[[VAL_208:.*]] = cmpxchg ptr %[[VAL_202]], i32 %[[VAL_205]], i32 %[[VAL_206]]{{.*}} seq_cst seq_cst, align 4
// CHECK:         %[[VAL_209:.*]] = extractvalue { i32, i1 } %[[VAL_208]], 0
// CHECK:         store i32 %[[VAL_209]], ptr{{.*}} %[[VAL_16]], align 4
// CHECK:         %[[VAL_210:.*]] = extractvalue { i32, i1 } %[[VAL_208]], 1
// CHECK:         br i1 %[[VAL_210]], label %atomic_op_loop_exit, label %atomic_op_loop_body
// CHECK:       entry:
// CHECK:         %[[VAL_211:.*]] = alloca float, align 4
// CHECK:         %[[VAL_212:.*]] = load float, ptr %[[VAL_213:.*]], align 4
// CHECK:         %[[VAL_214:.*]] = load float, ptr %[[VAL_215:.*]], align 4
// CHECK-PTX:     %[[VAL_216:.*]] = call float @llvm.minimum.f32(float %[[VAL_212]], float %[[VAL_214]])
// CHECK-GCN:     %[[VAL_216_1:.*]] = fcmp une float %[[VAL_212]], %[[VAL_212]]
// CHECK-GCN:     %[[VAL_216_2:.*]] = fcmp oeq float %[[VAL_214]], %[[VAL_214]]
// CHECK-GCN:     %[[VAL_216_3:.*]] = fcmp ole float %[[VAL_212]], %[[VAL_214]]
// CHECK-GCN:     %[[VAL_216_4:.*]] = and i1 %[[VAL_216_2]], %[[VAL_216_3]]
// CHECK-GCN:     %[[VAL_216_5:.*]] = or i1 %[[VAL_216_1]], %[[VAL_216_4]]
// CHECK-GCN:     %[[VAL_216:.*]] = select i1 %[[VAL_216_5]], float %[[VAL_212]], float %[[VAL_214]]
// CHECK:         store float %[[VAL_216]], ptr{{.*}} %[[VAL_211]], align 4
// CHECK:         %[[VAL_217:.*]] = load float, ptr{{.*}} %[[VAL_211]], align 4
// CHECK:         store float %[[VAL_217]], ptr %[[VAL_218:.*]], align 4
// CHECK:         ret void
