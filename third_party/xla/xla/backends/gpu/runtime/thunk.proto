/* Copyright 2025 The OpenXLA Authors.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

syntax = "proto3";

package xla.gpu;

import "xla/backends/gpu/runtime/convolution_filter_thunk.proto";
import "xla/backends/gpu/runtime/dynamic_slice_thunk.proto";
import "xla/backends/gpu/runtime/shaped_slice.proto";
import "xla/core/host_offloading/host_offloading_executable.proto";
import "xla/ffi/attribute_map.proto";
import "xla/service/buffer_assignment.proto";
import "xla/service/gpu/gpu_conv_runner.proto";
import "xla/service/gpu/gpu_norm_runner.proto";
import "xla/service/gpu/launch_dimensions.proto";
import "xla/service/hlo.proto";
import "xla/stream_executor/gpu/gpu_blas_lt.proto";
import "xla/stream_executor/gpu/tma_metadata.proto";
import "xla/stream_executor/launch_dim.proto";
import "xla/xla_data.proto";

// Contains basic pieces of information that every thunk type has.
message ThunkInfoProto {
  string profile_annotation = 1;
  int64 execution_stream_id = 2;
  int64 thunk_id = 3;
}

// A lightweight version of ThunkProto which only stores the thunk kind and
// the thunk info.
message ThunkMetadataProto {
  ThunkInfoProto thunk_info = 1;
  string thunk_kind = 2;
}

// The metadata of a list of thunks - usually an entire thunk graph.
message ThunkMetadataListProto {
  repeated ThunkMetadataProto thunk_metadata = 1;
}

message CopyThunkProto {
  xla.buffer_assignment.BufferAllocationSliceProto source_buffer = 1;
  xla.buffer_assignment.BufferAllocationSliceProto destination_buffer = 2;
  int64 mem_size = 3;
}

message DeviceToHostCopyThunkProto {
  CopyThunkProto copy_thunk = 1;
}

message HostToDeviceCopyThunkProto {
  CopyThunkProto copy_thunk = 1;
}

message DeviceToDeviceCopyThunkProto {
  CopyThunkProto copy_thunk = 1;
}

message ConditionalThunkProto {
  xla.buffer_assignment.BufferAllocationSliceProto branch_index_buffer = 1;
  repeated SequentialThunkProto branch_thunks = 2;
  bool branch_index_is_bool = 3;
}

message WhileThunkProto {
  xla.buffer_assignment.BufferAllocationSliceProto
      condition_result_buffer_index = 1;
  SequentialThunkProto condition_thunk_sequence = 2;
  SequentialThunkProto body_thunk_sequence = 3;
  optional int64 trip_count = 4;
}

message KernelThunkProto {
  repeated xla.buffer_assignment.BufferAllocationSliceProto args = 1;
  repeated bool written = 2;
  string kernel_name = 3;
  LaunchDimensionsProto launch_dimensions = 4;
  optional stream_executor.ClusterDimProto cluster_dim = 5;
  int64 shmem_bytes = 6;
  optional stream_executor.gpu.TmaMetadataProto tma_metadata = 7;
}

message GemmThunkProto {
  xla.GemmConfigProto gemm_config = 1;
  xla.buffer_assignment.BufferAllocationSliceProto lhs_buffer = 2;
  xla.buffer_assignment.BufferAllocationSliceProto rhs_buffer = 3;
  xla.buffer_assignment.BufferAllocationSliceProto output_buffer = 4;
  optional xla.buffer_assignment.BufferAllocationSliceProto workspace = 5;
  bool deterministic = 6;
}

message WaitForStreamsThunkProto {
  int64 stream_id = 1;
  int64 wait_for_stream_id = 2;
}

message TriangularSolveThunkProto {
  xla.TriangularSolveOptions options = 1;
  xla.buffer_assignment.BufferAllocationSliceProto a_buffer = 2;
  xla.buffer_assignment.BufferAllocationSliceProto b_buffer = 3;
  xla.buffer_assignment.BufferAllocationSliceProto temp_buffer = 4;
  xla.PrimitiveType type = 5;
  int64 batch_size = 6;
  int64 m = 7;
  int64 n = 8;
  int64 a_batch_stride = 9;
  int64 b_batch_stride = 10;
}

message ReplicaIdThunkProto {
  xla.buffer_assignment.BufferAllocationSliceProto dest_buffer = 1;
}

message PartitionIdThunkProto {
  xla.buffer_assignment.BufferAllocationSliceProto dest_buffer = 1;
}

message CudnnThunkProto {
  string fingerprint = 1;
  repeated xla.buffer_assignment.BufferAllocationSliceProto args = 2;
  repeated bool output_args = 4;
  optional int64 sdpa_dropout_seed = 3;
}

message HostExecuteStartThunkProto {
  HostOffloadingExecutableProto executable_proto = 1;
  repeated ShapedSliceProto args = 2;
  repeated ShapedSliceProto results = 3;
  uint64 async_events_unique_id = 4;
}

message HostExecuteDoneThunkProto {
  uint64 async_events_unique_id = 1;
}

message DynamicSliceThunkProto {
  SequentialThunkProto embedded_thunk = 1;
  repeated OptionalBufferAllocationSliceProto arguments = 2;
  repeated OptionalDynamicSliceOffsetsProto offsets = 3;
  repeated OptionalShapeProto orig_shapes = 4;
  repeated OptionalShapeProto sliced_shapes = 5;
  repeated OptionalInt64Proto offset_byte_sizes = 6;
  optional OffsetAsFunctionOfIndvarModulesMetadataProto
      offset_as_function_of_indvar_modules_metadata = 7;
  repeated BufferAllocationProto fake_allocations = 8;
}

message MemzeroThunkProto {
  xla.buffer_assignment.BufferAllocationSliceProto dest_buffer = 1;
}

message Memset32BitValueThunkProto {
  xla.buffer_assignment.BufferAllocationSliceProto dest_buffer = 1;
  uint32 value = 2;
}

message InfeedThunkProto {
  repeated ShapedSliceProto dest_slices = 1;
}

message OutfeedThunkProto {
  repeated ShapedSliceProto source_slices = 1;
}

message SelectKThunkProto {
  repeated xla.buffer_assignment.BufferAllocationSliceProto args = 1;
  uint32 batch_size = 3;
  uint32 num_elements = 4;
  uint32 k = 5;
  xla.PrimitiveType dtype = 6;
}

message CublasLtMatmulThunkProto {
  xla.GemmConfigProto gemm_config = 1;
  xla.BlasLtEpilogueProto epilogue = 2;
  int64 algorithm_idx = 3;
  string canonical_hlo = 4;
  xla.buffer_assignment.BufferAllocationSliceProto a = 5;
  xla.buffer_assignment.BufferAllocationSliceProto b = 6;
  xla.buffer_assignment.BufferAllocationSliceProto c = 7;
  xla.buffer_assignment.BufferAllocationSliceProto d = 8;
  optional xla.buffer_assignment.BufferAllocationSliceProto bias = 9;
  optional xla.buffer_assignment.BufferAllocationSliceProto aux = 10;
  optional xla.buffer_assignment.BufferAllocationSliceProto a_scale = 11;
  optional xla.buffer_assignment.BufferAllocationSliceProto b_scale = 12;
  optional xla.buffer_assignment.BufferAllocationSliceProto c_scale = 13;
  optional xla.buffer_assignment.BufferAllocationSliceProto d_scale = 14;
  optional xla.buffer_assignment.BufferAllocationSliceProto d_amax = 15;
  optional xla.buffer_assignment.BufferAllocationSliceProto workspace = 16;
}

message CubSortThunkProto {
  xla.PrimitiveType type = 1;
  optional xla.PrimitiveType value_type = 3;
  repeated xla.buffer_assignment.BufferAllocationSliceProto operands = 4;
  repeated xla.buffer_assignment.BufferAllocationSliceProto results = 5;
  xla.buffer_assignment.BufferAllocationSliceProto scratch = 6;
  bool descending = 7;
  int64 batch_size = 8;
}

message NormThunkProto {
  GpuNormDescriptorProto norm_descriptor = 1;
  xla.buffer_assignment.BufferAllocationSliceProto x = 2;
  xla.buffer_assignment.BufferAllocationSliceProto scale = 3;
  xla.buffer_assignment.BufferAllocationSliceProto y_or_dx = 4;
  optional xla.buffer_assignment.BufferAllocationSliceProto bias = 5;
  optional xla.buffer_assignment.BufferAllocationSliceProto expectation = 6;
  optional xla.buffer_assignment.BufferAllocationSliceProto norm_factor = 7;
  optional xla.buffer_assignment.BufferAllocationSliceProto dy = 8;
  optional xla.buffer_assignment.BufferAllocationSliceProto dscale = 9;
  optional xla.buffer_assignment.BufferAllocationSliceProto dbias = 10;
  xla.buffer_assignment.BufferAllocationSliceProto scratch = 11;
}

message ConvolutionThunkProto {
  GpuConvDescriptorProto conv_descriptor = 1;
  repeated xla.buffer_assignment.BufferAllocationSliceProto operand_buffers = 2;
  repeated xla.buffer_assignment.BufferAllocationSliceProto result_buffers = 3;
  xla.buffer_assignment.BufferAllocationSliceProto scratch_buffer = 4;
}

message ConvolutionReorderThunkProto {
  ConvolutionFilterDimensions filter_dimensions = 1;
  xla.buffer_assignment.BufferAllocationSliceProto filter_input = 2;
  xla.buffer_assignment.BufferAllocationSliceProto filter_output = 3;
  optional ConvolutionReorderBiasBuffers biases = 4;
}

message FftThunkProto {
  FftType fft_type = 1;
  repeated int64 fft_length = 2;
  xla.buffer_assignment.BufferAllocationSliceProto input_buffer = 3;
  xla.buffer_assignment.BufferAllocationSliceProto output_buffer = 4;
  xla.ShapeProto input_shape = 5;
  xla.ShapeProto output_shape = 6;
}

message CustomCallThunkProto {
  string target_name = 1;
  repeated NullableShapedSliceProto operands = 2;
  repeated NullableShapedSliceProto results = 3;
  string opaque = 4;
  CustomCallApiVersion api_version = 5;
  xla.ffi.AttributesMapProto attributes = 6;
  // The name of the called computation. It needs to match the HloCompuation in
  // the HloModule that is used to deserialize the thunk.
  optional string called_computation = 7;
}

message ThunkProto {
  ThunkInfoProto thunk_info = 1;

  oneof impl {
    SequentialThunkProto sequential_thunk = 2;
    CopyThunkProto copy_thunk = 3;
    DeviceToHostCopyThunkProto device_to_host_copy_thunk = 4;
    HostToDeviceCopyThunkProto host_to_device_copy_thunk = 5;
    ConditionalThunkProto conditional_thunk = 6;
    WhileThunkProto while_thunk = 7;
    KernelThunkProto kernel_thunk = 8;
    GemmThunkProto gemm_thunk = 9;
    WaitForStreamsThunkProto wait_for_streams_thunk = 10;
    TriangularSolveThunkProto triangular_solve_thunk = 11;
    ReplicaIdThunkProto replica_id_thunk = 12;
    DeviceToDeviceCopyThunkProto device_to_device_copy_thunk = 13;
    PartitionIdThunkProto partition_id_thunk = 14;
    CudnnThunkProto cudnn_thunk = 15;
    HostExecuteStartThunkProto host_execute_start_thunk = 16;
    HostExecuteDoneThunkProto host_execute_done_thunk = 17;
    DynamicSliceThunkProto dynamic_slice_thunk = 18;
    MemzeroThunkProto memzero_thunk = 19;
    SelectKThunkProto select_k_thunk = 20;
    InfeedThunkProto infeed_thunk = 21;
    CublasLtMatmulThunkProto cublas_lt_matmul_thunk = 22;
    OutfeedThunkProto outfeed_thunk = 23;
    NormThunkProto norm_thunk = 24;
    ConvolutionThunkProto convolution_thunk = 25;
    ConvolutionReorderThunkProto convolution_reorder_thunk = 26;
    FftThunkProto fft_thunk = 27;
    Memset32BitValueThunkProto memset32bit_value_thunk = 28;
    CustomCallThunkProto custom_call_thunk = 30;
    CubSortThunkProto cub_sort_thunk = 31;
  }
}

message SequentialThunkProto {
  repeated ThunkProto thunks = 1;
}
