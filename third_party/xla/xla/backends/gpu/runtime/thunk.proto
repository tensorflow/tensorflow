/* Copyright 2025 The OpenXLA Authors.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

syntax = "proto3";

package xla.gpu;

import "xla/backends/gpu/runtime/convolution_filter_thunk.proto";
import "xla/backends/gpu/runtime/copy_thunk.proto";
import "xla/backends/gpu/runtime/dynamic_slice_thunk.proto";
import "xla/core/host_offloading/host_offloading_executable.proto";
import "xla/ffi/attribute_map.proto";
import "xla/ffi/execution_state.proto";
import "xla/service/buffer_assignment.proto";
import "xla/service/gpu/gpu_conv_runner.proto";
import "xla/service/gpu/gpu_norm_runner.proto";
import "xla/service/gpu/kernels/custom_kernel.proto";
import "xla/service/gpu/launch_dimensions.proto";
import "xla/service/hlo.proto";
import "xla/service/shaped_slice.proto";
import "xla/stream_executor/gpu/gpu_blas_lt.proto";
import "xla/stream_executor/gpu/tma_metadata.proto";
import "xla/stream_executor/launch_dim.proto";
import "xla/xla_data.proto";

// Contains basic pieces of information that every thunk type has.
message ThunkInfoProto {
  string profile_annotation = 1;
  int64 execution_stream_id = 2;
  int64 thunk_id = 3;
}

// A lightweight version of ThunkProto which only stores the thunk kind and
// the thunk info.
message ThunkMetadataProto {
  ThunkInfoProto thunk_info = 1;
  string thunk_kind = 2;
}

// The metadata of a list of thunks - usually an entire thunk graph.
message ThunkMetadataListProto {
  repeated ThunkMetadataProto thunk_metadata = 1;
}

enum ThunkKindProto {
  THUNK_KIND_UNSPECIFIED = 0;
  THUNK_KIND_ALL_GATHER = 1;
  THUNK_KIND_ALL_GATHER_DONE = 2;
  THUNK_KIND_ALL_GATHER_START = 3;
  THUNK_KIND_ALL_REDUCE = 4;
  THUNK_KIND_ALL_REDUCE_DONE = 5;
  THUNK_KIND_ALL_REDUCE_START = 6;
  THUNK_KIND_ALL_TO_ALL = 7;
  THUNK_KIND_ALL_TO_ALL_DONE = 8;
  THUNK_KIND_ALL_TO_ALL_START = 9;
  THUNK_KIND_BUFFERS_DEBUG_CHECKSUM = 10;
  THUNK_KIND_BUFFERS_DEBUG_FLOAT_CHECK = 11;
  THUNK_KIND_COLLECTIVE_BROADCAST = 12;
  THUNK_KIND_COLLECTIVE_BROADCAST_DONE = 13;
  THUNK_KIND_COLLECTIVE_BROADCAST_START = 14;
  THUNK_KIND_COLLECTIVE_KERNEL = 15;
  THUNK_KIND_COLLECTIVE_METADATA = 16;
  THUNK_KIND_COLLECTIVE_PERMUTE = 17;
  THUNK_KIND_COLLECTIVE_PERMUTE_DONE = 18;
  THUNK_KIND_COLLECTIVE_PERMUTE_START = 19;
  THUNK_KIND_COMMAND_BUFFER = 20;
  THUNK_KIND_CONDITIONAL = 21;
  THUNK_KIND_CONVOLUTION = 22;
  THUNK_KIND_CONVOLUTION_REORDER = 23;
  THUNK_KIND_COPY = 24;
  THUNK_KIND_COPY_DONE = 25;
  THUNK_KIND_CU_DNN = 26;
  THUNK_KIND_CUB_SORT = 27;
  THUNK_KIND_CUBLAS_LT_MATMUL = 28;
  THUNK_KIND_CUSTOM_CALL = 29;
  THUNK_KIND_CUSTOM_KERNEL = 30;
  THUNK_KIND_DYNAMIC_SLICE = 31;
  THUNK_KIND_FFT = 32;
  THUNK_KIND_GEMM = 33;
  THUNK_KIND_GROUP_DONE = 34;
  THUNK_KIND_GROUP_START = 35;
  THUNK_KIND_HOST_EXECUTE_DONE = 36;
  THUNK_KIND_HOST_EXECUTE_START = 37;
  THUNK_KIND_HOST_RECV = 38;
  THUNK_KIND_HOST_RECV_DONE = 39;
  THUNK_KIND_HOST_SEND = 40;
  THUNK_KIND_HOST_SEND_DONE = 41;
  THUNK_KIND_INFEED = 42;
  THUNK_KIND_KERNEL = 43;
  THUNK_KIND_MEMSET32_BIT_VALUE = 44;
  THUNK_KIND_MEMZERO = 45;
  THUNK_KIND_NORM = 46;
  THUNK_KIND_NVSHMEM_ALL_REDUCE_DONE = 47;
  THUNK_KIND_NVSHMEM_ALL_REDUCE_START = 48;
  THUNK_KIND_NVSHMEM_COLLECTIVE_PERMUTE = 49;
  THUNK_KIND_NVSHMEM_COLLECTIVE_PERMUTE_DONE = 50;
  THUNK_KIND_NVSHMEM_COLLECTIVE_PERMUTE_START = 51;
  THUNK_KIND_NVSHMEM_RECV = 52;
  THUNK_KIND_NVSHMEM_RECV_DONE = 53;
  THUNK_KIND_NVSHMEM_SEND = 54;
  THUNK_KIND_NVSHMEM_SEND_DONE = 55;
  THUNK_KIND_OUTFEED = 56;
  THUNK_KIND_PARTITION_ID = 57;
  THUNK_KIND_RAGGED_ALL_TO_ALL = 58;
  THUNK_KIND_RAGGED_ALL_TO_ALL_DONE = 59;
  THUNK_KIND_RAGGED_ALL_TO_ALL_START = 60;
  THUNK_KIND_RECV = 61;
  THUNK_KIND_RECV_DONE = 62;
  THUNK_KIND_REDUCE_SCATTER = 63;
  THUNK_KIND_REDUCE_SCATTER_DONE = 64;
  THUNK_KIND_REDUCE_SCATTER_START = 65;
  THUNK_KIND_REPLICA_ID = 66;
  THUNK_KIND_SELECT_K = 67;
  THUNK_KIND_SEND = 68;
  THUNK_KIND_SEND_DONE = 69;
  THUNK_KIND_SEQUENTIAL = 70;
  THUNK_KIND_TRIANGULAR_SOLVE = 71;
  THUNK_KIND_WAIT_FOR_STREAMS = 72;
  THUNK_KIND_WHILE = 73;
}

message ConditionalThunkProto {
  ShapedSliceProto branch_index_buffer = 1;
  repeated SequentialThunkProto branch_thunks = 2;
}

message WhileThunkProto {
  xla.buffer_assignment.BufferAllocationSliceProto
      condition_result_buffer_index = 1;
  SequentialThunkProto condition_thunk_sequence = 2;
  SequentialThunkProto body_thunk_sequence = 3;
  optional int64 trip_count = 4;
}

message KernelThunkProto {
  repeated xla.buffer_assignment.BufferAllocationSliceProto args = 1;
  repeated xla.ShapeProto args_shape = 8;
  repeated bool written = 2;
  string kernel_name = 3;
  LaunchDimensionsProto launch_dimensions = 4;
  optional stream_executor.ClusterDimProto cluster_dim = 5;
  int64 shmem_bytes = 6;
  optional stream_executor.gpu.TmaMetadataProto tma_metadata = 7;
}

message GemmThunkProto {
  xla.GemmConfigProto gemm_config = 1;
  xla.buffer_assignment.BufferAllocationSliceProto lhs_buffer = 2;
  xla.buffer_assignment.BufferAllocationSliceProto rhs_buffer = 3;
  xla.buffer_assignment.BufferAllocationSliceProto output_buffer = 4;
  optional xla.buffer_assignment.BufferAllocationSliceProto workspace = 5;
  bool deterministic = 6;
}

message WaitForStreamsThunkProto {
  int64 stream_id = 1;
  int64 wait_for_stream_id = 2;
}

message TriangularSolveThunkProto {
  xla.TriangularSolveOptions options = 1;
  ShapedSliceProto a_buffer = 2;
  ShapedSliceProto b_buffer = 3;
  ShapedSliceProto temp_buffer = 4;
}

message ReplicaIdThunkProto {
  xla.buffer_assignment.BufferAllocationSliceProto dest_buffer = 1;
}

message PartitionIdThunkProto {
  xla.buffer_assignment.BufferAllocationSliceProto dest_buffer = 1;
}

message CudnnThunkProto {
  string fingerprint = 1;
  repeated xla.buffer_assignment.BufferAllocationSliceProto args = 2;
  repeated bool output_args = 4;
  optional int64 sdpa_dropout_seed = 3;
}

message HostSendThunkProto {
  xla.ShapeProto shape = 1;
  xla.buffer_assignment.BufferAllocationSliceProto buffer = 2;
  int64 channel_id = 3;
  map<string, string> frontend_attrs = 4;
  optional int64 device_constraint = 5;
  uint64 async_events_unique_id = 6;
}

message HostSendDoneThunkProto {
  int64 channel_id = 1;
  optional int64 device_constraint = 2;
  uint64 async_events_unique_id = 3;
}

message HostRecvThunkProto {
  xla.ShapeProto shape = 1;
  xla.buffer_assignment.BufferAllocationSliceProto buffer = 2;
  int64 channel_id = 3;
  map<string, string> frontend_attrs = 4;
  optional int64 device_constraint = 5;
  uint64 async_events_unique_id = 6;
}

message HostRecvDoneThunkProto {
  int64 channel_id = 1;
  optional int64 device_constraint = 2;
  uint64 async_events_unique_id = 3;
}

message HostExecuteStartThunkProto {
  HostOffloadingExecutableProto executable_proto = 1;
  repeated ShapedSliceProto args = 2;
  repeated ShapedSliceProto results = 3;
  uint64 async_events_unique_id = 4;
}

message HostExecuteDoneThunkProto {
  uint64 async_events_unique_id = 1;
}

message DynamicSliceThunkProto {
  SequentialThunkProto embedded_thunk = 1;
  repeated OptionalBufferAllocationSliceProto arguments = 2;
  repeated OptionalDynamicSliceOffsetsProto offsets = 3;
  repeated OptionalShapeProto orig_shapes = 4;
  repeated OptionalShapeProto sliced_shapes = 5;
  repeated OptionalPrimitiveType offset_primitive_types = 6;
  optional OffsetAsFunctionOfIndvarModulesMetadataProto
      offset_as_function_of_indvar_modules_metadata = 7;
  repeated BufferAllocationProto fake_allocations = 8;
}

message MemzeroThunkProto {
  ShapedSliceProto dest_buffer = 1;
}

message Memset32BitValueThunkProto {
  xla.buffer_assignment.BufferAllocationSliceProto dest_buffer = 1;
  uint32 value = 2;
}

message InfeedThunkProto {
  repeated ShapedSliceProto dest_slices = 1;
}

message OutfeedThunkProto {
  repeated ShapedSliceProto source_slices = 1;
}

message SelectKThunkProto {
  repeated xla.buffer_assignment.BufferAllocationSliceProto args = 1;
  uint32 batch_size = 3;
  uint32 num_elements = 4;
  uint32 k = 5;
  xla.PrimitiveType dtype = 6;
}

message CublasLtMatmulThunkProto {
  xla.GemmConfigProto gemm_config = 1;
  xla.BlasLtEpilogueProto epilogue = 2;
  int64 algorithm_idx = 3;
  string canonical_hlo = 4;
  xla.buffer_assignment.BufferAllocationSliceProto a = 5;
  xla.buffer_assignment.BufferAllocationSliceProto b = 6;
  xla.buffer_assignment.BufferAllocationSliceProto c = 7;
  xla.buffer_assignment.BufferAllocationSliceProto d = 8;
  optional xla.buffer_assignment.BufferAllocationSliceProto bias = 9;
  optional xla.buffer_assignment.BufferAllocationSliceProto aux = 10;
  optional xla.buffer_assignment.BufferAllocationSliceProto a_scale = 11;
  optional xla.buffer_assignment.BufferAllocationSliceProto b_scale = 12;
  optional xla.buffer_assignment.BufferAllocationSliceProto c_scale = 13;
  optional xla.buffer_assignment.BufferAllocationSliceProto d_scale = 14;
  optional xla.buffer_assignment.BufferAllocationSliceProto d_amax = 15;
  optional xla.buffer_assignment.BufferAllocationSliceProto workspace = 16;
  int64 autotune_workspace_size = 17;
}

message CubSortThunkProto {
  repeated ShapedSliceProto operands = 1;
  repeated ShapedSliceProto results = 2;
  xla.buffer_assignment.BufferAllocationSliceProto scratch = 3;
  bool descending = 4;
  int64 batch_size = 5;
}

message NormThunkProto {
  GpuNormDescriptorProto norm_descriptor = 1;
  xla.buffer_assignment.BufferAllocationSliceProto x = 2;
  xla.buffer_assignment.BufferAllocationSliceProto scale = 3;
  xla.buffer_assignment.BufferAllocationSliceProto y_or_dx = 4;
  optional xla.buffer_assignment.BufferAllocationSliceProto bias = 5;
  optional xla.buffer_assignment.BufferAllocationSliceProto expectation = 6;
  optional xla.buffer_assignment.BufferAllocationSliceProto norm_factor = 7;
  optional xla.buffer_assignment.BufferAllocationSliceProto dy = 8;
  optional xla.buffer_assignment.BufferAllocationSliceProto dscale = 9;
  optional xla.buffer_assignment.BufferAllocationSliceProto dbias = 10;
  xla.buffer_assignment.BufferAllocationSliceProto scratch = 11;
}

message ConvolutionThunkProto {
  GpuConvDescriptorProto conv_descriptor = 1;
  repeated ShapedSliceProto operand_buffers = 2;
  repeated ShapedSliceProto result_buffers = 3;
  xla.buffer_assignment.BufferAllocationSliceProto scratch_buffer = 4;
}

message ConvolutionReorderThunkProto {
  ShapedSliceProto filter_input = 1;
  ShapedSliceProto filter_output = 2;
  optional ConvolutionReorderBiasBuffers biases = 3;
}

message FftThunkProto {
  FftType fft_type = 1;
  repeated int64 fft_length = 2;
  xla.buffer_assignment.BufferAllocationSliceProto input_buffer = 3;
  xla.buffer_assignment.BufferAllocationSliceProto output_buffer = 4;
  xla.ShapeProto input_shape = 5;
  xla.ShapeProto output_shape = 6;
}

message CustomCallThunkProto {
  string target_name = 1;
  repeated NullableShapedSliceProto operands = 2;
  repeated NullableShapedSliceProto results = 3;
  bytes opaque = 4;
  CustomCallApiVersion api_version = 5;
  xla.ffi.AttributesMapProto attributes = 6;
  // The name of the called computation. It needs to match the HloCompuation in
  // the HloModule that is used to deserialize the thunk.
  optional string called_computation = 7;
  optional xla.ffi.ExecutionStateProto execution_state = 8;
}

message CustomKernelThunkProto {
  repeated xla.buffer_assignment.BufferAllocationSliceProto args = 1;
  repeated bool written = 2;
  CustomKernelProto custom_kernel = 3;
}

message CollectiveBufferProto {
  int64 element_count = 1;
  ShapedSliceProto source_buffer = 2;
  ShapedSliceProto destination_buffer = 3;
  int64 source_memory_space = 4;
  int64 destination_memory_space = 5;
}

message CollectiveConfigProto {
  repeated PrimitiveType operand_element_type = 1;
  repeated ReplicaGroup replica_groups = 2;
  CollectiveOpGroupMode group_mode = 3;
  bool use_symmetric_buffer = 4;
}

message CollectiveThunkProto {
  ThunkKindProto thunk_kind = 1;
  uint64 async_events_unique_id = 3;
}

message AllGatherStartThunkProto {
  optional uint64 async_events_unique_id = 1;
  CollectiveConfigProto collective_config = 2;
  repeated CollectiveBufferProto buffers = 3;
}

enum ReductionKindProto {
  REDUCTION_KIND_UNSPECIFIED = 0;
  REDUCTION_KIND_SUM = 1;
  REDUCTION_KIND_PRODUCT = 2;
  REDUCTION_KIND_MIN = 3;
  REDUCTION_KIND_MAX = 4;
}

message AllReduceStartThunkProto {
  optional uint64 async_events_unique_id = 1;
  CollectiveConfigProto collective_config = 2;
  repeated CollectiveBufferProto buffers = 3;

  ReductionKindProto reduction_kind = 4;
  bool is_multimem_enabled = 5;
  int32 shmem_bytes = 6;
  string kernel_name = 7;
  bool collective_kernel_enabled = 8;
  bool is_async = 9;
}

message ReduceScatterStartThunkProto {
  optional uint64 async_events_unique_id = 1;
  CollectiveConfigProto collective_config = 2;
  repeated CollectiveBufferProto buffers = 3;
  ReductionKindProto reduction_kind = 4;
}

message AllToAllStartThunkProto {
  optional uint64 async_events_unique_id = 1;
  CollectiveConfigProto collective_config = 2;
  repeated CollectiveBufferProto buffers = 3;

  bool has_split_dimension = 4;
  bool p2p_memcpy_enabled = 5;
}

message RaggedAllToAllStartThunkProto {
  optional uint64 async_events_unique_id = 1;
  CollectiveConfigProto collective_config = 2;
  repeated CollectiveBufferProto buffers = 3;

  int64 num_total_updates = 4;
  int64 num_input_rows = 5;
  int64 num_row_elements = 6;
  bool one_shot_kernel_enabled = 7;
}

message CollectivePermuteStartThunkProto {
  optional uint64 async_events_unique_id = 1;
  repeated CollectiveBufferProto buffers = 2;

  CollectiveConfigProto collective_config = 3;
  repeated SourceTarget source_target_pairs = 4;

  bool p2p_memcpy_enabled = 6;
}

message SendThunkProto {
  uint64 async_events_unique_id = 1;
  CollectiveBufferProto buffer = 2;

  CollectiveConfigProto collective_config = 3;
  repeated SourceTarget source_target_pairs = 4;

  string instruction_name = 6;
}

message RecvThunkProto {
  uint64 async_events_unique_id = 1;
  CollectiveBufferProto buffer = 2;

  CollectiveConfigProto collective_config = 3;
  repeated SourceTarget source_target_pairs = 4;

  string instruction_name = 6;
}

message CollectiveBroadcastStartThunkProto {
  optional uint64 async_events_unique_id = 1;
  repeated CollectiveBufferProto buffers = 2;
  CollectiveConfigProto collective_config = 3;
}

message CollectiveDoneThunkProto {
  ThunkKindProto thunk_kind = 1;
  optional uint64 async_events_unique_id = 3;
}

message CollectiveGroupThunkProto {
  ThunkKindProto thunk_kind = 1;
  repeated ThunkProto thunks = 2;
  optional uint64 async_events_unique_id = 4;
}

message ThunkProto {
  ThunkInfoProto thunk_info = 1;

  oneof impl {
    SequentialThunkProto sequential_thunk = 2;
    CopyThunkProto copy_thunk = 3;
    DeviceToHostCopyThunkProto device_to_host_copy_thunk = 4;
    HostToDeviceCopyThunkProto host_to_device_copy_thunk = 5;
    ConditionalThunkProto conditional_thunk = 6;
    WhileThunkProto while_thunk = 7;
    KernelThunkProto kernel_thunk = 8;
    GemmThunkProto gemm_thunk = 9;
    WaitForStreamsThunkProto wait_for_streams_thunk = 10;
    TriangularSolveThunkProto triangular_solve_thunk = 11;
    ReplicaIdThunkProto replica_id_thunk = 12;
    DeviceToDeviceCopyThunkProto device_to_device_copy_thunk = 13;
    PartitionIdThunkProto partition_id_thunk = 14;
    CudnnThunkProto cudnn_thunk = 15;
    HostExecuteStartThunkProto host_execute_start_thunk = 16;
    HostExecuteDoneThunkProto host_execute_done_thunk = 17;
    DynamicSliceThunkProto dynamic_slice_thunk = 18;
    MemzeroThunkProto memzero_thunk = 19;
    SelectKThunkProto select_k_thunk = 20;
    InfeedThunkProto infeed_thunk = 21;
    CublasLtMatmulThunkProto cublas_lt_matmul_thunk = 22;
    OutfeedThunkProto outfeed_thunk = 23;
    NormThunkProto norm_thunk = 24;
    ConvolutionThunkProto convolution_thunk = 25;
    ConvolutionReorderThunkProto convolution_reorder_thunk = 26;
    FftThunkProto fft_thunk = 27;
    Memset32BitValueThunkProto memset32bit_value_thunk = 28;
    CustomCallThunkProto custom_call_thunk = 30;
    CubSortThunkProto cub_sort_thunk = 31;
    HostSendThunkProto host_send_thunk = 32;
    HostSendDoneThunkProto host_send_done_thunk = 33;
    HostRecvThunkProto host_recv_thunk = 34;
    HostRecvDoneThunkProto host_recv_done_thunk = 35;
    CustomKernelThunkProto custom_kernel_thunk = 36;
    CollectiveDoneThunkProto collective_done_thunk = 37;
    AllGatherStartThunkProto all_gather_start_thunk = 38;
    AllReduceStartThunkProto all_reduce_start_thunk = 39;
    ReduceScatterStartThunkProto reduce_scatter_start_thunk = 40;
    AllToAllStartThunkProto all_to_all_start_thunk = 41;
    RaggedAllToAllStartThunkProto ragged_all_to_all_start_thunk = 42;
    CollectivePermuteStartThunkProto collective_permute_start_thunk = 43;
    SendThunkProto send_thunk = 44;
    RecvThunkProto recv_thunk = 45;
    CollectiveBroadcastStartThunkProto collective_broadcast_start_thunk = 46;
    CollectiveGroupThunkProto collective_group_thunk = 47;
    DynamicMemcpyThunkProto dynamic_memcpy_thunk = 48;
  }
}

message SequentialThunkProto {
  repeated ThunkProto thunks = 1;
}
