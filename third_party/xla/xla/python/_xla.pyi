# Copyright 2025 The OpenXLA Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from collections.abc import Sequence
import enum
from typing import Annotated, TypeAlias, overload
import numpy
from numpy.typing import NDArray

class PrimitiveType(enum.IntEnum):
  PRIMITIVE_TYPE_INVALID = 0

  PRED = 1

  S4 = 21

  S8 = 2

  S16 = 3

  S32 = 4

  S64 = 5

  U4 = 22

  U8 = 6

  U16 = 7

  U32 = 8

  U64 = 9

  F16 = 10

  F4E2M1FN = 32

  F8E3M4 = 29

  F8E4M3 = 28

  F8E4M3FN = 20

  F8E4M3B11FNUZ = 23

  F8E4M3FNUZ = 25

  F8E5M2 = 19

  F8E5M2FNUZ = 24

  F8E8M0FNU = 33

  BF16 = 16

  F32 = 11

  F64 = 12

  C64 = 15

  C128 = 18

  TUPLE = 13

  OPAQUE_TYPE = 14

  TOKEN = 17

class Layout:
  @overload
  def __init__(self, arg: Sequence[int], /) -> None: ...
  @overload
  def __init__(
      self, arg0: Sequence[int], arg1: Sequence[tuple[int, ...]], arg2: int, /
  ) -> None: ...
  def minor_to_major(self) -> tuple[int, ...]: ...
  def element_size_in_bits(self) -> int: ...
  def tiling(self) -> list[tuple[int, ...]]: ...
  def __eq__(self, other: object, /) -> bool: ...
  def __ne__(self, other: object, /) -> bool: ...
  def __str__(self) -> str: ...
  def __hash__(self) -> int: ...
  def to_string(self) -> str: ...
  def __getstate__(self) -> tuple: ...
  def __setstate__(self, arg: tuple, /) -> None: ...

class Shape:
  def __init__(self, arg: str, /) -> None: ...
  @staticmethod
  def tuple_shape(arg: Sequence[Shape], /) -> Shape:
    """Constructs a tuple shape."""

  @overload
  @staticmethod
  def array_shape(
      type: PrimitiveType,
      dims: Sequence[int],
      layout: Sequence[int] | None = ...,
      dynamic_dimensions: Sequence[bool] | None = ...,
  ) -> Shape:
    """Constructs an array shape."""

  @overload
  @staticmethod
  def array_shape(
      type: numpy.dtype,
      dims: Sequence[int],
      layout: Sequence[int] | None = ...,
      dynamic_dimensions: Sequence[bool] | None = ...,
  ) -> Shape: ...
  @staticmethod
  def token_shape() -> Shape: ...
  @overload
  @staticmethod
  def scalar_shape(type: PrimitiveType) -> Shape:
    """Constructs a scalar shape."""

  @overload
  @staticmethod
  def scalar_shape(type: numpy.dtype) -> Shape: ...
  def dimensions(self) -> tuple[int, ...]: ...
  def layout(self) -> Layout: ...
  def xla_element_type(self) -> PrimitiveType: ...
  def element_type(self) -> numpy.dtype: ...
  def numpy_dtype(self) -> numpy.dtype: ...
  def is_tuple(self) -> bool: ...
  def is_array(self) -> bool: ...
  def is_token(self) -> bool: ...
  def is_static(self) -> bool: ...
  def is_dynamic(self) -> bool: ...
  def is_dynamic_dimension(self, dimension: int) -> bool: ...
  def set_dynamic_dimension(self, dimension: int, is_dynamic: bool) -> None: ...
  def rank(self) -> int: ...
  def to_serialized_proto(self) -> bytes: ...
  def tuple_shapes(self) -> list[Shape]: ...
  def leaf_count(self) -> int: ...
  def with_major_to_minor_layout_if_absent(self) -> Shape:
    """Returns a copy of a shape with missing layouts set to major-to-minor."""

  def __eq__(self, other: object, /) -> bool: ...
  def __ne__(self, other: object, /) -> bool: ...
  def __hash__(self) -> int: ...
  def __repr__(self) -> str: ...

class ProgramShape:
  def __init__(self, arg0: Sequence[Shape], arg1: Shape, /) -> None: ...
  def parameter_shapes(self) -> list[Shape]: ...
  def result_shape(self) -> Shape: ...
  def __repr__(self) -> str: ...

class Literal:
  def __init__(self, arg: Shape, /) -> None: ...
  def __repr__(self) -> str: ...
  def __array__(
      self, dtype: object | None = ..., copy: bool | None = ...
  ) -> NDArray: ...
  def shape(self) -> Shape: ...

class XlaComputation:
  def __init__(self, arg: bytes, /) -> None: ...
  def get_hlo_module(self) -> HloModule: ...
  def program_shape(self) -> ProgramShape: ...
  def name(self) -> str: ...
  def as_serialized_hlo_module_proto(self) -> bytes: ...
  def as_hlo_text(self, print_large_constants: bool = ...) -> str: ...
  def as_hlo_dot_graph(self) -> str: ...
  def hash(self) -> int: ...
  def as_hlo_module(self) -> HloModule: ...

class HloPrintOptions:
  def __init__(self) -> None: ...
  @staticmethod
  def short_parsable() -> HloPrintOptions: ...
  @staticmethod
  def canonical() -> HloPrintOptions: ...
  @staticmethod
  def fingerprint() -> HloPrintOptions: ...
  @property
  def print_large_constants(self) -> bool: ...
  @print_large_constants.setter
  def print_large_constants(self, arg: bool, /) -> HloPrintOptions: ...
  @property
  def print_metadata(self) -> bool: ...
  @print_metadata.setter
  def print_metadata(self, arg: bool, /) -> HloPrintOptions: ...
  @property
  def print_backend_config(self) -> bool: ...
  @print_backend_config.setter
  def print_backend_config(self, arg: bool, /) -> HloPrintOptions: ...
  @property
  def print_result_shape(self) -> bool: ...
  @print_result_shape.setter
  def print_result_shape(self, arg: bool, /) -> HloPrintOptions: ...
  @property
  def print_operand_shape(self) -> bool: ...
  @print_operand_shape.setter
  def print_operand_shape(self, arg: bool, /) -> HloPrintOptions: ...
  @property
  def print_operand_names(self) -> bool: ...
  @print_operand_names.setter
  def print_operand_names(self, arg: bool, /) -> HloPrintOptions: ...
  @property
  def print_ids(self) -> bool: ...
  @print_ids.setter
  def print_ids(self, arg: bool, /) -> HloPrintOptions: ...
  @property
  def print_extra_attributes(self) -> bool: ...
  @print_extra_attributes.setter
  def print_extra_attributes(self, arg: bool, /) -> HloPrintOptions: ...
  @property
  def print_program_shape(self) -> bool: ...
  @print_program_shape.setter
  def print_program_shape(self, arg: bool, /) -> HloPrintOptions: ...
  @property
  def print_percent(self) -> bool: ...
  @print_percent.setter
  def print_percent(self, arg: bool, /) -> HloPrintOptions: ...
  @property
  def print_control_dependencies(self) -> bool: ...
  @print_control_dependencies.setter
  def print_control_dependencies(self, arg: bool, /) -> HloPrintOptions: ...
  @property
  def compact_operands(self) -> bool: ...
  @compact_operands.setter
  def compact_operands(self, arg: bool, /) -> HloPrintOptions: ...
  @property
  def include_layout_in_shapes(self) -> bool: ...
  @include_layout_in_shapes.setter
  def include_layout_in_shapes(self, arg: bool, /) -> HloPrintOptions: ...
  @property
  def canonicalize_instruction_names(self) -> bool: ...
  @canonicalize_instruction_names.setter
  def canonicalize_instruction_names(self, arg: bool, /) -> HloPrintOptions: ...
  @property
  def canonicalize_computations(self) -> bool: ...
  @canonicalize_computations.setter
  def canonicalize_computations(self, arg: bool, /) -> HloPrintOptions: ...
  @property
  def indent_amount(self) -> int: ...
  @indent_amount.setter
  def indent_amount(self, arg: int, /) -> HloPrintOptions: ...
  @property
  def is_in_nested_computation(self) -> int: ...
  @is_in_nested_computation.setter
  def is_in_nested_computation(self, arg: bool, /) -> HloPrintOptions: ...

class HloComputation:
  @property
  def name(self) -> str: ...
  def render_html(self, arg: str, /) -> None: ...

class HloModule:
  @property
  def name(self) -> str: ...
  def to_string(self, options: HloPrintOptions = ...) -> str: ...
  def as_serialized_hlo_module_proto(self) -> bytes: ...
  def from_serialized_hlo_module_proto(self) -> HloModule: ...
  def computations(self) -> list[HloComputation]: ...
  @property
  def spmd_output_sharding(self) -> OpSharding | None: ...
  @property
  def spmd_parameters_shardings(self) -> list[OpSharding] | None: ...

def hlo_module_to_dot_graph(arg: HloModule, /) -> str: ...
def hlo_module_from_text(arg: str, /) -> HloModule: ...

class DeviceAssignment:
  @staticmethod
  def create(
      arg: Annotated[NDArray[numpy.int32], dict(shape=(None, None))], /
  ) -> DeviceAssignment: ...
  def replica_count(self) -> int: ...
  def computation_count(self) -> int: ...
  def __repr__(self) -> str: ...
  def serialize(self) -> bytes: ...

class CompileOptions:
  def __init__(self) -> None: ...
  def __getstate__(self) -> tuple: ...
  def __setstate__(self, arg: tuple, /) -> None: ...
  def SerializeAsString(self) -> bytes: ...
  @staticmethod
  def ParseFromString(arg: bytes, /) -> CompileOptions: ...
  @property
  def argument_layouts(self) -> list[Shape] | None: ...
  @argument_layouts.setter
  def argument_layouts(self, arg: Sequence[Shape], /) -> None: ...
  @property
  def parameter_is_tupled_arguments(self) -> bool: ...
  @parameter_is_tupled_arguments.setter
  def parameter_is_tupled_arguments(self, arg: bool, /) -> None: ...
  @property
  def compile_portable_executable(self) -> bool: ...
  @compile_portable_executable.setter
  def compile_portable_executable(self, arg: bool, /) -> None: ...
  @property
  def executable_build_options(self) -> ExecutableBuildOptions: ...
  @property
  def env_option_overrides(
      self,
  ) -> list[tuple[str, str | bool | int | float]]: ...
  @env_option_overrides.setter
  def env_option_overrides(
      self, arg: Sequence[tuple[str, str | bool | int | float]], /
  ) -> None: ...
  @property
  def num_replicas(self) -> int: ...
  @num_replicas.setter
  def num_replicas(self, arg: int, /) -> None: ...
  @property
  def num_partitions(self) -> int: ...
  @num_partitions.setter
  def num_partitions(self, arg: int, /) -> None: ...
  @property
  def profile_version(self) -> int: ...
  @profile_version.setter
  def profile_version(self, arg: int, /) -> None: ...
  @property
  def device_assignment(self) -> DeviceAssignment | None: ...
  @device_assignment.setter
  def device_assignment(self, arg: DeviceAssignment, /) -> None: ...

class AutotuneCacheMode(enum.Enum):
  UNSPECIFIED = 0

  UPDATE = 1

  READ = 2

class DebugOptions:
  def __repr__(self) -> str: ...
  @property
  def xla_backend_optimization_level(self) -> int: ...
  @xla_backend_optimization_level.setter
  def xla_backend_optimization_level(self, arg: int, /) -> None: ...
  @property
  def xla_cpu_enable_fast_math(self) -> bool: ...
  @xla_cpu_enable_fast_math.setter
  def xla_cpu_enable_fast_math(self, arg: bool, /) -> None: ...
  @property
  def xla_cpu_enable_xprof_traceme(self) -> bool: ...
  @xla_cpu_enable_xprof_traceme.setter
  def xla_cpu_enable_xprof_traceme(self, arg: bool, /) -> None: ...
  @property
  def xla_cpu_fast_math_honor_infs(self) -> bool: ...
  @xla_cpu_fast_math_honor_infs.setter
  def xla_cpu_fast_math_honor_infs(self, arg: bool, /) -> None: ...
  @property
  def xla_cpu_fast_math_honor_nans(self) -> bool: ...
  @xla_cpu_fast_math_honor_nans.setter
  def xla_cpu_fast_math_honor_nans(self, arg: bool, /) -> None: ...
  @property
  def xla_cpu_fast_math_honor_division(self) -> bool: ...
  @xla_cpu_fast_math_honor_division.setter
  def xla_cpu_fast_math_honor_division(self, arg: bool, /) -> None: ...
  @property
  def xla_cpu_fast_math_honor_functions(self) -> bool: ...
  @xla_cpu_fast_math_honor_functions.setter
  def xla_cpu_fast_math_honor_functions(self, arg: bool, /) -> None: ...
  @property
  def xla_detailed_logging(self) -> bool: ...
  @xla_detailed_logging.setter
  def xla_detailed_logging(self, arg: bool, /) -> None: ...
  @property
  def xla_enable_dumping(self) -> bool: ...
  @xla_enable_dumping.setter
  def xla_enable_dumping(self, arg: bool, /) -> None: ...
  @property
  def xla_gpu_enable_fast_min_max(self) -> bool: ...
  @xla_gpu_enable_fast_min_max.setter
  def xla_gpu_enable_fast_min_max(self, arg: bool, /) -> None: ...
  @property
  def xla_gpu_dump_autotune_results_to(self) -> str: ...
  @xla_gpu_dump_autotune_results_to.setter
  def xla_gpu_dump_autotune_results_to(self, arg: str, /) -> None: ...
  @property
  def xla_gpu_load_autotune_results_from(self) -> str: ...
  @xla_gpu_load_autotune_results_from.setter
  def xla_gpu_load_autotune_results_from(self, arg: str, /) -> None: ...
  @property
  def xla_gpu_cuda_data_dir(self) -> str: ...
  @xla_gpu_cuda_data_dir.setter
  def xla_gpu_cuda_data_dir(self, arg: str, /) -> None: ...
  @property
  def xla_llvm_disable_expensive_passes(self) -> bool: ...
  @xla_llvm_disable_expensive_passes.setter
  def xla_llvm_disable_expensive_passes(self, arg: bool, /) -> None: ...
  @property
  def xla_disable_hlo_passes(self) -> str: ...
  @xla_disable_hlo_passes.setter
  def xla_disable_hlo_passes(self, arg: str, /) -> None: ...
  @property
  def xla_enable_hlo_passes_only(self) -> str: ...
  @xla_enable_hlo_passes_only.setter
  def xla_enable_hlo_passes_only(self, arg: str, /) -> None: ...
  @property
  def xla_test_all_input_layouts(self) -> bool: ...
  @xla_test_all_input_layouts.setter
  def xla_test_all_input_layouts(self, arg: bool, /) -> None: ...
  @property
  def xla_force_host_platform_device_count(self) -> int: ...
  @xla_force_host_platform_device_count.setter
  def xla_force_host_platform_device_count(self, arg: int, /) -> None: ...
  @property
  def xla_dump_to(self) -> str: ...
  @xla_dump_to.setter
  def xla_dump_to(self, arg: str, /) -> None: ...
  @property
  def xla_dump_hlo_module_re(self) -> str: ...
  @xla_dump_hlo_module_re.setter
  def xla_dump_hlo_module_re(self, arg: str, /) -> None: ...
  @property
  def xla_dump_hlo_pass_re(self) -> str: ...
  @xla_dump_hlo_pass_re.setter
  def xla_dump_hlo_pass_re(self, arg: str, /) -> None: ...
  @property
  def xla_dump_hlo_as_text(self) -> bool: ...
  @xla_dump_hlo_as_text.setter
  def xla_dump_hlo_as_text(self, arg: bool, /) -> None: ...
  @property
  def xla_dump_hlo_as_proto(self) -> bool: ...
  @xla_dump_hlo_as_proto.setter
  def xla_dump_hlo_as_proto(self, arg: bool, /) -> None: ...
  @property
  def xla_dump_hlo_as_dot(self) -> bool: ...
  @xla_dump_hlo_as_dot.setter
  def xla_dump_hlo_as_dot(self, arg: bool, /) -> None: ...
  @property
  def xla_dump_hlo_as_url(self) -> bool: ...
  @xla_dump_hlo_as_url.setter
  def xla_dump_hlo_as_url(self, arg: bool, /) -> None: ...
  @property
  def xla_dump_hlo_as_html(self) -> bool: ...
  @xla_dump_hlo_as_html.setter
  def xla_dump_hlo_as_html(self, arg: bool, /) -> None: ...
  @property
  def xla_dump_fusion_visualization(self) -> bool: ...
  @xla_dump_fusion_visualization.setter
  def xla_dump_fusion_visualization(self, arg: bool, /) -> None: ...
  @property
  def xla_dump_hlo_snapshots(self) -> bool: ...
  @xla_dump_hlo_snapshots.setter
  def xla_dump_hlo_snapshots(self, arg: bool, /) -> None: ...
  @property
  def xla_dump_max_hlo_modules(self) -> int: ...
  @xla_dump_max_hlo_modules.setter
  def xla_dump_max_hlo_modules(self, arg: int, /) -> None: ...
  @property
  def xla_dump_module_metadata(self) -> bool: ...
  @xla_dump_module_metadata.setter
  def xla_dump_module_metadata(self, arg: bool, /) -> None: ...
  @property
  def xla_dump_compress_protos(self) -> bool: ...
  @xla_dump_compress_protos.setter
  def xla_dump_compress_protos(self, arg: bool, /) -> None: ...
  @property
  def xla_dump_hlo_as_long_text(self) -> bool: ...
  @xla_dump_hlo_as_long_text.setter
  def xla_dump_hlo_as_long_text(self, arg: bool, /) -> None: ...
  @property
  def xla_dump_disable_metadata(self) -> bool: ...
  @xla_dump_disable_metadata.setter
  def xla_dump_disable_metadata(self, arg: bool, /) -> None: ...
  @property
  def xla_dump_hlo_pipeline_re(self) -> str: ...
  @xla_dump_hlo_pipeline_re.setter
  def xla_dump_hlo_pipeline_re(self, arg: str, /) -> None: ...
  @property
  def xla_gpu_dump_autotune_logs_to(self) -> str: ...
  @xla_gpu_dump_autotune_logs_to.setter
  def xla_gpu_dump_autotune_logs_to(self, arg: str, /) -> None: ...
  @property
  def xla_gpu_kernel_cache_file(self) -> str: ...
  @xla_gpu_kernel_cache_file.setter
  def xla_gpu_kernel_cache_file(self, arg: str, /) -> None: ...
  @property
  def xla_gpu_enable_llvm_module_compilation_parallelism(self) -> bool: ...
  @xla_gpu_enable_llvm_module_compilation_parallelism.setter
  def xla_gpu_enable_llvm_module_compilation_parallelism(
      self, arg: bool, /
  ) -> None: ...
  @property
  def xla_gpu_per_fusion_autotune_cache_dir(self) -> str: ...
  @xla_gpu_per_fusion_autotune_cache_dir.setter
  def xla_gpu_per_fusion_autotune_cache_dir(self, arg: str, /) -> None: ...
  @property
  def xla_gpu_experimental_autotune_cache_mode(self) -> AutotuneCacheMode: ...
  @xla_gpu_experimental_autotune_cache_mode.setter
  def xla_gpu_experimental_autotune_cache_mode(
      self, arg: AutotuneCacheMode, /
  ) -> None: ...

class ExecutableBuildOptions:
  def __init__(self) -> None: ...
  def __repr__(self) -> str: ...
  @property
  def fdo_profile(self) -> bytes: ...
  @fdo_profile.setter
  def fdo_profile(self, arg: bytes, /) -> None: ...
  @property
  def result_layout(self) -> Shape | None: ...
  @result_layout.setter
  def result_layout(self, arg: Shape, /) -> ExecutableBuildOptions: ...
  @property
  def num_replicas(self) -> int: ...
  @num_replicas.setter
  def num_replicas(self, arg: int, /) -> ExecutableBuildOptions: ...
  @property
  def num_partitions(self) -> int: ...
  @num_partitions.setter
  def num_partitions(self, arg: int, /) -> ExecutableBuildOptions: ...
  @property
  def debug_options(self) -> DebugOptions: ...
  @property
  def device_assignment(self) -> DeviceAssignment | None: ...
  @device_assignment.setter
  def device_assignment(
      self, arg: DeviceAssignment, /
  ) -> ExecutableBuildOptions: ...
  def compilation_environments_from_serialized_proto(
      self, arg: bytes, /
  ) -> None: ...
  @property
  def exec_time_optimization_effort(self) -> float: ...
  @exec_time_optimization_effort.setter
  def exec_time_optimization_effort(
      self, arg: float, /
  ) -> ExecutableBuildOptions: ...
  @property
  def memory_fitting_effort(self) -> float: ...
  @memory_fitting_effort.setter
  def memory_fitting_effort(self, arg: float, /) -> ExecutableBuildOptions: ...
  @property
  def optimization_level(self) -> int: ...
  @optimization_level.setter
  def optimization_level(self, arg: int, /) -> None: ...
  @property
  def memory_fitting_level(self) -> int: ...
  @memory_fitting_level.setter
  def memory_fitting_level(self, arg: int, /) -> None: ...
  @property
  def use_spmd_partitioning(self) -> bool: ...
  @use_spmd_partitioning.setter
  def use_spmd_partitioning(self, arg: bool, /) -> ExecutableBuildOptions: ...
  @property
  def use_auto_spmd_partitioning(self) -> bool: ...
  @use_auto_spmd_partitioning.setter
  def use_auto_spmd_partitioning(
      self, arg: bool, /
  ) -> ExecutableBuildOptions: ...
  @property
  def auto_spmd_partitioning_mesh_shape(self) -> list[int]: ...
  @auto_spmd_partitioning_mesh_shape.setter
  def auto_spmd_partitioning_mesh_shape(
      self, arg: Sequence[int], /
  ) -> ExecutableBuildOptions: ...
  @property
  def auto_spmd_partitioning_mesh_ids(self) -> list[int]: ...
  @auto_spmd_partitioning_mesh_ids.setter
  def auto_spmd_partitioning_mesh_ids(
      self, arg: Sequence[int], /
  ) -> ExecutableBuildOptions: ...
  @property
  def allow_spmd_sharding_propagation_to_parameters(self) -> list[bool]: ...
  @allow_spmd_sharding_propagation_to_parameters.setter
  def allow_spmd_sharding_propagation_to_parameters(
      self, arg: Sequence[bool], /
  ) -> None: ...
  @property
  def allow_spmd_sharding_propagation_to_output(self) -> list[bool]: ...
  @allow_spmd_sharding_propagation_to_output.setter
  def allow_spmd_sharding_propagation_to_output(
      self, arg: Sequence[bool], /
  ) -> None: ...
  @property
  def use_shardy_partitioner(self) -> bool: ...
  @use_shardy_partitioner.setter
  def use_shardy_partitioner(self, arg: bool, /) -> ExecutableBuildOptions: ...

class OpSharding_Type(enum.IntEnum):
  REPLICATED = 0

  MAXIMAL = 1

  MANUAL = 4

  UNREDUCED = 6

  TUPLE = 2

  OTHER = 3

  UNKNOWN = 5

class OpSharding_ShardGroupType(enum.Enum):
  AS = 0

  LIKE = 1

class OpSharding:
  def __init__(self) -> None: ...

  Type: TypeAlias = OpSharding_Type

  ShardGroupType: TypeAlias = OpSharding_ShardGroupType

  def __getstate__(self) -> tuple: ...
  def __setstate__(self, arg: tuple, /) -> None: ...
  @property
  def type(self) -> OpSharding_Type: ...
  @type.setter
  def type(self, arg: OpSharding_Type, /) -> None: ...
  @property
  def replicate_on_last_tile_dim(self) -> bool: ...
  @replicate_on_last_tile_dim.setter
  def replicate_on_last_tile_dim(self, arg: bool, /) -> None: ...
  @property
  def is_shard_group(self) -> bool: ...
  @is_shard_group.setter
  def is_shard_group(self, arg: bool, /) -> None: ...
  @property
  def shard_group_id(self) -> int: ...
  @shard_group_id.setter
  def shard_group_id(self, arg: int, /) -> None: ...
  @property
  def shard_group_type(self) -> OpSharding_ShardGroupType: ...
  @shard_group_type.setter
  def shard_group_type(self, arg: OpSharding_ShardGroupType, /) -> None: ...
  def __repr__(self) -> str: ...
  def ParseFromString(self, arg: bytes, /) -> None: ...
  def SerializeToString(self) -> bytes: ...
  def clone(self) -> OpSharding: ...
  @property
  def tile_assignment_dimensions(self) -> list[int]: ...
  @tile_assignment_dimensions.setter
  def tile_assignment_dimensions(self, arg: Sequence[int], /) -> None: ...
  @property
  def tile_assignment_devices(self) -> list[int]: ...
  @tile_assignment_devices.setter
  def tile_assignment_devices(self, arg: Sequence[int], /) -> None: ...
  @property
  def iota_reshape_dims(self) -> list[int]: ...
  @iota_reshape_dims.setter
  def iota_reshape_dims(self, arg: Sequence[int], /) -> None: ...
  @property
  def iota_transpose_perm(self) -> list[int]: ...
  @iota_transpose_perm.setter
  def iota_transpose_perm(self, arg: Sequence[int], /) -> None: ...
  @property
  def tuple_shardings(self) -> list[OpSharding]: ...
  @tuple_shardings.setter
  def tuple_shardings(self, arg: Sequence[OpSharding], /) -> None: ...
  @property
  def last_tile_dims(self) -> list[int]: ...
  @last_tile_dims.setter
  def last_tile_dims(self, arg: Sequence[int], /) -> None: ...

class HloSharding:
  @staticmethod
  def from_proto(arg: OpSharding, /) -> HloSharding: ...
  @staticmethod
  def from_string(arg: str, /) -> HloSharding: ...
  @staticmethod
  def tuple_sharding(
      arg0: Shape, arg1: Sequence[HloSharding], /
  ) -> HloSharding:
    """Constructs a tuple sharding."""

  @staticmethod
  def iota_tile(
      dims: Sequence[int],
      reshape_dims: Sequence[int] = ...,
      transpose_perm: Sequence[int] = ...,
      subgroup_types: Sequence[OpSharding_Type] = ...,
  ) -> HloSharding: ...
  @staticmethod
  def manual() -> HloSharding: ...
  @staticmethod
  def replicate() -> HloSharding: ...
  @staticmethod
  def unreduced() -> HloSharding: ...
  @staticmethod
  def unknown() -> HloSharding: ...
  @staticmethod
  def subgroup_with_device_ordering(
      tile_assignment: Annotated[NDArray[numpy.int64], dict(order='C')],
      subgroup_types: Sequence[OpSharding_Type] = ...,
  ) -> HloSharding: ...
  def __eq__(self, other: object, /) -> bool: ...
  def __ne__(self, other: object, /) -> bool: ...
  def __hash__(self) -> int: ...
  def is_replicated(self) -> bool: ...
  def is_manual(self) -> bool: ...
  def is_unreduced(self) -> bool: ...
  def is_unknown(self) -> bool: ...
  def is_tiled(self) -> bool: ...
  def is_maximal(self) -> bool: ...
  def tile(self, arg: Shape, /) -> Shape: ...
  def tuple_elements(self) -> list[HloSharding]: ...
  def num_devices(self) -> int: ...
  def num_dimensions(self) -> int: ...
  def is_tile_assignment_iota(self) -> bool: ...
  def tile_assignment_dimensions(self) -> Sequence[int]: ...
  def tile_assignment_devices(self) -> Sequence[int]: ...
  def replicate_on_last_tile_dim(self) -> bool: ...
  def subgroup_types(self) -> list[OpSharding_Type]: ...
  def __repr__(self) -> str: ...
  def to_proto(self) -> OpSharding: ...
  def get_axis_sizes(self) -> list[int]: ...
