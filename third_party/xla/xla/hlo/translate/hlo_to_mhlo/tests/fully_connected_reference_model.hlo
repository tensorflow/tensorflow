// RUN: xla-translate -hlo-text-to-mlir-hlo -hlo-flatten-computation-args-result=false %s -o - | FileCheck %s

// This test comes from a fully connected reference model.

HloModule tfcompile.48

// CHECK-LABEL:   func @main(
// CHECK-SAME:               %[[VAL_0:.*]]: tensor<1x300xf32>,
// CHECK-SAME:               %[[VAL_1:.*]]: tensor<1x300x3x1xf32>) -> tuple<tensor<300x1x5xf32>> {
ENTRY %tfcompile.48 {
  %arg0.1 = f32[1,300] parameter(0)
  %arg1.2 = f32[1,300,3,1] parameter(1)

  // CHECK-NEXT: %[[VAL_2:.*]] = mhlo.reshape %[[VAL_0]] : (tensor<1x300xf32>) -> tensor<1x300xf32>
  %reshape.3 = f32[1,300] reshape(%arg0.1)

  // CHECK-NEXT: %[[VAL_3:.*]] = "mhlo.transpose"(%[[VAL_2]]) <{permutation = dense<[1, 0]> : tensor<2xi64>}> : (tensor<1x300xf32>) -> tensor<300x1xf32>
  %transpose.27 = f32[300,1] transpose(%reshape.3), dimensions={1,0}

  // CHECK-NEXT: %[[VAL_4:.*]] = mhlo.reshape %[[VAL_3]] : (tensor<300x1xf32>) -> tensor<300x1x1xf32>
  %reshape.28 = f32[300,1,1] reshape(%transpose.27)

  // CHECK-NEXT: %[[VAL_5:.*]] = mhlo.reshape %[[VAL_4]] : (tensor<300x1x1xf32>) -> tensor<300x1xf32>
  %reshape.29 = f32[300,1] reshape(%reshape.28)

  // CHECK-NEXT: %[[VAL_6:.*]] = "mhlo.broadcast_in_dim"(%[[VAL_5]]) <{broadcast_dimensions = dense<[0, 1]> : tensor<2xi64>}> : (tensor<300x1xf32>) -> tensor<300x1x5xf32>
  %broadcast.30 = f32[300,1,5] broadcast(%reshape.29), dimensions={0,1}

  // CHECK-NEXT: %[[VAL_7:.*]] = mhlo.constant dense<1.000000e+00> : tensor<f32>
  %constant.8 = f32[] constant(1)

  // CHECK-NEXT: %[[VAL_8:.*]] = "mhlo.broadcast_in_dim"(%[[VAL_7]]) <{broadcast_dimensions = dense<> : tensor<0xi64>}> : (tensor<f32>) -> tensor<300x1x5xf32>
  %broadcast.9 = f32[300,1,5] broadcast(%constant.8), dimensions={}

  // CHECK-NEXT: %[[VAL_9:.*]] = mhlo.multiply %[[VAL_6]], %[[VAL_8]] : tensor<300x1x5xf32>
  %multiply.31 = f32[300,1,5] multiply(%broadcast.30, %broadcast.9)

  // CHECK-NEXT: %[[VAL_10:.*]] = mhlo.constant dense<0.000000e+00> : tensor<f32>
  %constant.32 = f32[] constant(0)

  // CHECK-NEXT: %[[VAL_11:.*]] = "mhlo.broadcast_in_dim"(%[[VAL_10]]) <{broadcast_dimensions = dense<> : tensor<0xi64>}> : (tensor<f32>) -> tensor<300x1x5xf32>
  %broadcast.33 = f32[300,1,5] broadcast(%constant.32), dimensions={}

  // CHECK-NEXT: %[[VAL_12:.*]] = mhlo.compare GT, %[[VAL_9]], %[[VAL_11]] : (tensor<300x1x5xf32>, tensor<300x1x5xf32>) -> tensor<300x1x5xi1>
  %compare.34 = pred[300,1,5] compare(%multiply.31, %broadcast.33), direction=GT

  // CHECK-NEXT: %[[VAL_13:.*]] = mhlo.constant dense<0.000000e+00> : tensor<f32>
  %constant.10 = f32[] constant(0)

  // CHECK-NEXT: %[[VAL_14:.*]] = "mhlo.broadcast_in_dim"(%[[VAL_13]]) <{broadcast_dimensions = dense<> : tensor<0xi64>}> : (tensor<f32>) -> tensor<300x1x5xf32>
  %broadcast.11 = f32[300,1,5] broadcast(%constant.10), dimensions={}

  // CHECK-NEXT: %[[VAL_15:.*]] = mhlo.constant dense<0.000000e+00> : tensor<f32>
  %constant.40 = f32[] constant(0)

  // CHECK-NEXT: %[[VAL_16:.*]] = "mhlo.broadcast_in_dim"(%[[VAL_15]]) <{broadcast_dimensions = dense<> : tensor<0xi64>}> : (tensor<f32>) -> tensor<300x5xf32>
  %broadcast.41 = f32[300,5] broadcast(%constant.40), dimensions={}

  // CHECK-NEXT: %[[VAL_17:.*]] = mhlo.copy %[[VAL_1]] : tensor<1x300x3x1xf32>
  %copy.1 = f32[1,300,3,1] copy(%arg1.2)

  // CHECK-NEXT: %[[VAL_18:.*]] = mhlo.reshape %[[VAL_17]] : (tensor<1x300x3x1xf32>) -> tensor<1x300x3x1xf32>
  %reshape.4 = f32[1,300,3,1] reshape(%copy.1)

  // CHECK-NEXT: %[[VAL_19:.*]] = mhlo.reshape %[[VAL_18]] : (tensor<1x300x3x1xf32>) -> tensor<1x300x3xf32>
  %reshape.24 = f32[1,300,3] reshape(%reshape.4)

  // CHECK-NEXT: %[[VAL_20:.*]] = "mhlo.transpose"(%[[VAL_19]]) <{permutation = dense<[1, 0, 2]> : tensor<3xi64>}> : (tensor<1x300x3xf32>) -> tensor<300x1x3xf32>
  %transpose.25 = f32[300,1,3] transpose(%reshape.24), dimensions={1,0,2}

  // CHECK-NEXT: %[[VAL_21:.*]] = mhlo.reshape %[[VAL_20]] : (tensor<300x1x3xf32>) -> tensor<300x3xf32>
  %reshape.26 = f32[300,3] reshape(%transpose.25)

  // CHECK-NEXT: %[[VAL_22:.*]] = mhlo.constant dense<{{\[\[}}-1.060230e-01, 1.215050e-01, 8.002390e-01, -7.688850e-01, 0.0966112986], [6.890140e-01, -4.070560e-01, -0.797852993, 3.789250e-03, -2.088810e-01], [-6.085290e-01, 2.766170e-02, 2.685570e-01, 5.774010e-01, -4.284370e-01]]> : tensor<3x5xf32>
  %constant.35 = f32[3,5] constant({ { -0.106023, 0.121505, 0.800239, -0.768885, 0.0966113 }, { 0.689014, -0.407056, -0.797853, 0.00378925, -0.208881 }, { -0.608529, 0.0276617, 0.268557, 0.577401, -0.428437 } })

  // TODO(b/129709049) consider making this default precision config implied.
  // CHECK-NEXT: %[[VAL_23:.*]] = "mhlo.dot"(%[[VAL_21]], %[[VAL_22]]) <{precision_config = [#mhlo<precision DEFAULT>, #mhlo<precision DEFAULT>]}> : (tensor<300x3xf32>, tensor<3x5xf32>) -> tensor<300x5xf32>
  %dot.36 = f32[300,5] dot(%reshape.26, %constant.35), lhs_contracting_dims={1}, rhs_contracting_dims={0}

  // CHECK-NEXT: %[[VAL_24:.*]] = mhlo.constant dense<0.000000e+00> : tensor<5xf32>
  %constant.37 = f32[5]{0} constant({0, 0, 0, 0, 0})

  // CHECK-NEXT: %[[VAL_25:.*]] = "mhlo.broadcast_in_dim"(%[[VAL_24]]) <{broadcast_dimensions = dense<1> : tensor<1xi64>}> : (tensor<5xf32>) -> tensor<300x5xf32>
  %broadcast.38 = f32[300,5] broadcast(%constant.37), dimensions={1}

  // CHECK-NEXT: %[[VAL_26:.*]] = mhlo.add %[[VAL_23]], %[[VAL_25]] : tensor<300x5xf32>
  %add.39 = f32[300,5] add(%dot.36, %broadcast.38)

  // CHECK-NEXT: %[[VAL_27:.*]] = mhlo.maximum %[[VAL_16]], %[[VAL_26]] : tensor<300x5xf32>
  %maximum.42 = f32[300,5] maximum(%broadcast.41, %add.39)

  // CHECK-NEXT: %[[VAL_28:.*]] = mhlo.reshape %[[VAL_27]] : (tensor<300x5xf32>) -> tensor<300x1x5xf32>
  %reshape.44 = f32[300,1,5] reshape(%maximum.42)

  // CHECK-NEXT: %[[VAL_29:.*]] = mhlo.select %[[VAL_12]], %[[VAL_14]], %[[VAL_28]] : tensor<300x1x5xi1>, tensor<300x1x5xf32>
  %select.45 = f32[300,1,5] select(%compare.34, %broadcast.11, %reshape.44)

  // CHECK-NEXT: %[[VAL_30:.*]] = mhlo.reshape %[[VAL_29]] : (tensor<300x1x5xf32>) -> tensor<300x1x5xf32>
  %reshape.46 = f32[300,1,5] reshape(%select.45)

  // CHECK-NEXT: %[[VAL_31:.*]] = mhlo.tuple %[[VAL_30]] {xla_shape = {{.*}}} : tuple<tensor<300x1x5xf32>>
  // CHECK-NEXT: return %[[VAL_31]] : tuple<tensor<300x1x5xf32>>
  ROOT %tuple.47 = (f32[300,1,5]) tuple(%reshape.46)
}
