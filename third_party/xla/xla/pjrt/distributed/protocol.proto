// Copyright 2020 The OpenXLA Authors.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
// ==============================================================================
//
// Distributed XLA service protocol.
//
// This is a minimal distributed protocol intended for a small set of purposes
// * barriers to wait for all clients to start up or shut down
// * health checking to detect when clients vanish
// * for sharing GPU topology and NCCL communicator state between distributed
//   hosts.
//
// The intention is that a service is started during cluster initialization and
// persists for the lifetime of the cluster.

syntax = "proto3";

package xla;

option go_package = "github.com/tensorflow/tensorflow/tensorflow/go/compiler/"
                    "xla/pjrt/distributed/protocol_go_proto";

message IntValuesProto {
  repeated int64 values = 1;
}

message DeviceAttributeProto {
  oneof attribute {
    string string_value = 1;
    bool bool_value = 2;
    int64 int_value = 3;
    IntValuesProto int_values = 4;
    float float_value = 5;
  }
}

// Describes a device local to a host.
message DeviceProto {
  int32 local_device_ordinal = 1;
  string name = 2;
  string vendor = 3;

  // The following fields are present in the GlobalTopologyProto message
  // returned by EnumerateDevices() but not in the LocalTopologyProto messages
  // passed to EnumerateDevices(). In other words, the coordinator node
  // determines the global device IDs during EnumerateDevices().
  int32 global_device_id = 4;  // Globally unique ID number.

  // Devices with the same partition_index are connected by fast network, e.g.
  // NVLink on GPUs. Note that fast-interconnect can be cross-host, i.e. a
  // partition may include multiple hosts.
  int32 partition_index = 5;

  // The NUMA node of the device. If this information is not available, filled
  // with `tsl::port::kNUMANoAffinity`.
  int32 numa_node = 14;

  // Store vendor-specific compute capability.
  string compute_capability = 6;

  // The number of cores (e.g. SMs on GPUs) on the device.
  int32 core_count = 7;

  string device_kind = 8;
  string to_string = 9;
  string debug_string = 10;

  map<string, DeviceAttributeProto> attributes = 11;

  // Multiple hosts may be connected by NVLink, fabric_uuid uniquely identifies
  // a fast-interconnect domain, thus can be used to identify the actual number
  // of ranks connected in a single fast-interconnect domain. Only meaningful
  // for SM100 (Blackwell) and onwards.
  // fabric_uuid is constructed in the format of "clusterUuid/cliqueId".
  string fabric_uuid = 12;

  // Maximum amount of shared memory per block that can possibly be configured
  // for a kernel on this device. The name of this attribute mirrors the CUDA
  // driver enum member CU_DEVICE_ATTRIBUTE_MAX_SHARED_MEMORY_PER_BLOCK_OPTIN:
  // https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__DEVICE.html#:~:text=CU_DEVICE_ATTRIBUTE_MAX_SHARED_MEMORY_PER_BLOCK_OPTIN
  // The _OPTIN suffix indicates that this is the maximum amount configurable on
  // an opt-in basis (a property of the device), as opposed to
  // CU_DEVICE_ATTRIBUTE_MAX_SHARED_MEMORY_PER_BLOCK, which is the amount of
  // shared memory that is actually made available to kernels through software
  // configuration.
  // For CUDA, shared_memory_per_block_optin also corresponds to the "Maximum
  // amount of shared memory per thread block" row of this table:
  // https://docs.nvidia.com/cuda/cuda-c-programming-guide/#id401:~:text=100%20KB-,Maximum%20amount%20of%20shared%20memory%20per%20thread%20block,-35
  int32 shared_memory_per_block_optin = 13;
}

message LocalTopologyProto {
  int32 node_id = 1;
  // Unique per OS kernel restart to uniquely identify a host.
  // See /proc/sys/kernel/random/boot_id.
  string boot_id = 2;
  repeated DeviceProto devices = 3;

  // Explicit partition index; derived from boot_id if absent
  optional int32 partition_index = 4;
}

message GlobalTopologyProto {
  repeated LocalTopologyProto nodes = 1;
}
