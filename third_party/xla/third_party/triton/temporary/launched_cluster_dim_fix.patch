https://github.com/triton-lang/triton/pull/8645 removed cluster dimensions from the
kernel metadata. We don't need to pass them to the launch API anymore.

--- a/third_party/nvidia/backend/cuda_utils.cc	2025-11-17 02:33:44.000000000 -0800
+++ b/third_party/nvidia/backend/cuda_utils.cc	2025-11-18 03:58:02.000000000 -0800
@@ -119,8 +119,8 @@
     constexpr int size() const { return x * y * z; }
   };
   Dim grid;                     // Number of clusters per grid
-  Dim cluster;                  // Number of blocks per cluster
   int num_warps;                // number of warps per block
+  int num_ctas;                 // number of CTAs per block
   int shared_memory;            // Size of shared memory in bytes to allocate
   int launch_cooperative_grid;  // Non-zero to launch coop grid
   int launch_pdl;               // Non-zero to use programatic-dependent launch
@@ -137,16 +137,15 @@
   // APIs if needed.
   Py_BEGIN_ALLOW_THREADS;
   const auto& grid = config.grid;
-  const auto& cluster = config.cluster;
   if (grid.size() == 0) {
     PyEval_RestoreThread(_save);
     Py_RETURN_NONE;
   }
 
   CUlaunchConfig cu_config;
-  cu_config.gridDimX = grid.x * cluster.x;
-  cu_config.gridDimY = grid.y * cluster.y;
-  cu_config.gridDimZ = grid.z * cluster.z;
+  cu_config.gridDimX = grid.x * config.num_ctas;
+  cu_config.gridDimY = grid.y;
+  cu_config.gridDimZ = grid.z;
   cu_config.blockDimX = 32 * config.num_warps;
   cu_config.blockDimY = 1;
   cu_config.blockDimZ = 1;
@@ -169,12 +168,12 @@
       .value = { .cooperative =  1}
     };
   }
-  if (config.cluster.size() > 1) {
+  if (config.num_ctas != 1) {
     auto& clusterDimAttr = launchAttr[cu_config.numAttrs++];
     clusterDimAttr.id = CU_LAUNCH_ATTRIBUTE_CLUSTER_DIMENSION;
-    clusterDimAttr.value.clusterDim.x = cluster.x;
-    clusterDimAttr.value.clusterDim.y = cluster.y;
-    clusterDimAttr.value.clusterDim.z = cluster.z;
+    clusterDimAttr.value.clusterDim.x = config.num_ctas;
+    clusterDimAttr.value.clusterDim.y = 1;
+    clusterDimAttr.value.clusterDim.z = 1;
     auto& clusterDimSchedulingAttr = launchAttr[cu_config.numAttrs++];
     clusterDimSchedulingAttr.id =
         CU_LAUNCH_ATTRIBUTE_CLUSTER_SCHEDULING_POLICY_PREFERENCE;
@@ -518,9 +517,8 @@
 :param launch_pdl: enable programmatic dependent launch
 :type launch_pdl: bool
 :param packed_metadata: Kernel metadata, including in sequence:
-    number of warps, number of CTAs, required bytes of shared memory,
-    cluster dimensions x, y, and z
-:type packed_metadata: 6-tuple
+    number of warps, number of CTAs, required bytes of shared memory
+:type packed_metadata: 3-tuple
 :param hook_args: arguments to pass to the enter and exit hooks
 :type hook_args: object
 :param launch_enter_hook: hook to call just before launching the kernel
@@ -542,7 +540,6 @@
   ensureCudaContext();
   TritonLaunchConfig config{};
   auto& grid = config.grid;
-  auto& cluster = config.cluster;
   // PyObject* kernel_metadata = nullptr;
   PyObject* hook_args = nullptr;
   PyObject* launch_enter_hook = nullptr;
@@ -551,15 +548,13 @@
   PyObject* kernel_args = nullptr;
   PyObject* global_scratch = nullptr;
   PyObject* profile_scratch = nullptr;
-  int num_ctas = 0;
-  if (!PyArg_ParseTuple(args, "iiiKKpp(iiiiii)OOOSOOO", &grid.x, &grid.y,
-                        &grid.z, &config.stream, &config.function,
+  if (!PyArg_ParseTuple(args, "iiiKKpp(iii)OOOSOOO", &grid.x, &grid.y, &grid.z,
+                        &config.stream, &config.function,
                         &config.launch_cooperative_grid, &config.launch_pdl,
-                        &config.num_warps, &num_ctas, &config.shared_memory,
-                        &cluster.x, &cluster.y, &cluster.z, &hook_args,
-                        &launch_enter_hook, &launch_exit_hook,
-                        &signature_metadata_bytes, &global_scratch,
-                        &profile_scratch, &kernel_args)) {
+                        &config.num_warps, &config.num_ctas,
+                        &config.shared_memory, &hook_args, &launch_enter_hook,
+                        &launch_exit_hook, &signature_metadata_bytes,
+                        &global_scratch, &profile_scratch, &kernel_args)) {
     return nullptr;
   }
   llvm::ArrayRef<char> signature_metadata(

--- a/third_party/nvidia/backend/driver.py	2025-11-13 05:31:00.000000000 -0800
+++ b/third_party/nvidia/backend/driver.py	2025-11-18 03:45:28.000000000 -0800
@@ -223,7 +223,7 @@
     def wrapper(grid_dim_x: int, grid_dim_y: int, grid_dim_z: int,
                 stream: int, kernel: int, launch_cooperative_grid: bool,
                 launch_pdl: bool, global_scratch: any, profile_scratch: any,
-                packed_metadata: tuple[int, int, int, int, int, int],
+                packed_metadata: tuple[int, int, int],
                 hook_args: any,
                 launch_enter_hook: Callable[..., None],
                 launch_exit_hook: Callable[..., None],
