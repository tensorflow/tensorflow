diff --ruN a/stablehlo/BUILD.bazel b/stablehlo/BUILD.bazel
--- stablehlo/BUILD.bazel
+++ stablehlo/BUILD.bazel
@@ -257,6 +257,7 @@
         ":chlo_enums_inc_gen",
         ":chlo_ops_inc_gen",
         ":stablehlo_assembly_format",
+        ":stablehlo_broadcast_lowering",
         ":stablehlo_type_inference",
         "@llvm-project//llvm:Support",
         "@llvm-project//mlir:BytecodeOpInterface",
diff --ruN a/stablehlo/stablehlo/dialect/Base.cpp b/stablehlo/stablehlo/dialect/Base.cpp
--- stablehlo/stablehlo/dialect/Base.cpp
+++ stablehlo/stablehlo/dialect/Base.cpp
@@ -25,7 +25,6 @@
 #include <utility>
 
 #include "llvm/ADT/APInt.h"
-#include "llvm/ADT/Hashing.h"
 #include "llvm/ADT/STLExtras.h"
 #include "llvm/ADT/Sequence.h"
 #include "llvm/ADT/SmallVector.h"
@@ -47,7 +46,6 @@
 #include "mlir/Interfaces/SideEffectInterfaces.h"
 #include "mlir/Support/LLVM.h"
 #include "mlir/Support/LogicalResult.h"
-#include "mlir/Support/TypeID.h"
 
 // Include order matters
 #include "stablehlo/dialect/BaseAttrInterfaces.cpp.inc"
@@ -246,7 +244,7 @@
   if (boundsLen != rank)
     return emitError() << "Bounds length is " << boundsLen
                        << ", expected to be equal to rank(" << rank
-                       << ") of the tensor";
+                       << ") of the tensor " << type;
 
   for (int64_t dim = 0; dim < rank; ++dim) {
     int64_t bound = bounds[dim];
@@ -254,7 +252,8 @@
     if (bound != ShapedType::kDynamic && dimSize != ShapedType::kDynamic)
       return emitError() << "Static dimension " << dim
                          << " cannot have a bound, use ShapedType::kDynamic to "
-                            "indicate a missing bound";
+                            "indicate a missing bound in tensor "
+                         << type;
   }
 
   return success();
diff --ruN a/stablehlo/stablehlo/dialect/Base.h b/stablehlo/stablehlo/dialect/Base.h
--- stablehlo/stablehlo/dialect/Base.h
+++ stablehlo/stablehlo/dialect/Base.h
@@ -486,9 +486,12 @@
                                 inferredReturnTypes)))
       return failure();
     if (inferredReturnTypes.size() != 1) return failure();
-    auto inferredReturnType = dyn_cast<ShapedType>(inferredReturnTypes[0]);
+    auto inferredReturnType =
+        dyn_cast<RankedTensorType>(inferredReturnTypes[0]);
     if (!inferredReturnType) return failure();
-    inferredReturnShapes.push_back(inferredReturnType);
+    inferredReturnShapes.emplace_back(inferredReturnType.getShape(),
+                                      inferredReturnType.getElementType(),
+                                      inferredReturnType.getEncoding());
     return success();
   }
 };
diff --ruN a/stablehlo/stablehlo/dialect/ChloOps.cpp b/stablehlo/stablehlo/dialect/ChloOps.cpp
--- stablehlo/stablehlo/dialect/ChloOps.cpp
+++ stablehlo/stablehlo/dialect/ChloOps.cpp
@@ -19,14 +19,14 @@
 #include <algorithm>
 #include <cassert>
 #include <cstdint>
-#include <iostream>
 #include <iterator>
 #include <optional>
 #include <string>
 
 #include "llvm/ADT/STLExtras.h"
 #include "llvm/ADT/SmallVector.h"
-#include "llvm/ADT/TypeSwitch.h"
+#include "llvm/ADT/TypeSwitch.h"  // IWYU pragma: keep
+#include "llvm/Support/ErrorHandling.h"
 #include "mlir/Dialect/Complex/IR/Complex.h"
 #include "mlir/Dialect/Traits.h"
 #include "mlir/IR/Attributes.h"
@@ -51,6 +51,7 @@
 #include "stablehlo/dialect/BroadcastUtils.h"
 #include "stablehlo/dialect/ChloBytecode.h"
 #include "stablehlo/dialect/TypeInference.h"
+#include "stablehlo/transforms/StablehloBroadcastLowering.h"
 
 // Include order matters
 #include "stablehlo/dialect/ChloEnums.cpp.inc"
@@ -104,54 +105,95 @@
 //===----------------------------------------------------------------------===//
 
 namespace {
+
+bool isStaticOrBoundedDynamicTensor(RankedTensorType type) {
+  return type.hasStaticShape() || hlo::isBoundedDynamic(type);
+}
+
 // Gets the resulting type from a broadcast between two types.
-ShapedTypeComponents getBroadcastType(
-    Type x, Type y, Type elementType,
-    std::optional<ArrayRef<int64_t>> broadcastDimensionsAttr) {
-  auto xRanked = dyn_cast<RankedTensorType>(x);
-  auto yRanked = dyn_cast<RankedTensorType>(y);
-  if (!xRanked || !yRanked) return {elementType};
-
-  auto shapeX = xRanked.getShape();
-  auto shapeY = yRanked.getShape();
-
-  // If no broadcast dimensions, assume "numpy" broadcasting.
-  if (shapeX.size() == shapeY.size() || !broadcastDimensionsAttr.has_value()) {
-    llvm::SmallVector<int64_t, 4> outShape;
-    if (!mlir::OpTrait::util::getBroadcastedShape(shapeX, shapeY, outShape)) {
+ShapedTypeComponents getNumpyBroadcastType(ArrayRef<Value> operands,
+                                           Type elementType) {
+  if (operands.empty())
+    llvm::report_fatal_error("Called getNumpyBroadcastType with no operands");
+
+  // Handle unranked tensors
+  if (llvm::any_of(operands,
+                   [](Value v) { return !isa<RankedTensorType>(v.getType()); }))
+    return {elementType};
+
+  // All static or bounded, use bounded dynamic aware broadcasting.
+  bool allStaticOrBounded = llvm::all_of(operands, [](Value v) {
+    return isStaticOrBoundedDynamicTensor(cast<RankedTensorType>(v.getType()));
+  });
+  if (allStaticOrBounded) {
+    Location errorLoc = operands[0].getLoc();
+    FailureOr<stablehlo::Dimensions> outShape =
+        stablehlo::getNumpyBroadcastShape(errorLoc, operands);
+    if (failed(outShape)) {
       // Signal illegal broadcast_dimensions as unranked.
       return {elementType};
     }
-    return {outShape, elementType};
-  }
-
-  auto shapeLarge = shapeX.size() > shapeY.size() ? shapeX : shapeY;
-  auto shapeSmall = shapeX.size() <= shapeY.size() ? shapeX : shapeY;
+    RankedTensorType outType =
+        stablehlo::getRankedTensorType(*outShape, elementType);
+    return {outType.getShape(), outType.getElementType(),
+            outType.getEncoding()};
+  }
+
+  // Fall back to non-bounded dynamic aware broadcasting
+  // Will pick more lenient output shapes `x . ? => ?`
+  llvm::SmallVector<int64_t, 4> outShape =
+      llvm::to_vector(cast<RankedTensorType>(operands[0].getType()).getShape());
+  for (Value operand : operands) {
+    // Make a copy of current shape since `getBroadcastedShape` will modify it.
+    llvm::SmallVector<int64_t, 4> currentShape = outShape;
+    auto operandShape = cast<RankedTensorType>(operand.getType()).getShape();
+    if (!mlir::OpTrait::util::getBroadcastedShape(currentShape, operandShape,
+                                                  outShape)) {
+      return {elementType};
+    }
+  }
+  return {outShape, elementType};
+}
+
+ShapedTypeComponents getBroadcastTypeWithBroadcastDimensions(
+    Value x, Value y, Type elementType,
+    std::optional<ArrayRef<int64_t>> broadcastDimensionsAttr) {
+  if (!broadcastDimensionsAttr.has_value())
+    return getNumpyBroadcastType({x, y}, elementType);
+
+  // Only support two operands if broadcast_dimensions is specified.
+  auto shapeX = dyn_cast<RankedTensorType>(x.getType());
+  auto shapeY = dyn_cast<RankedTensorType>(y.getType());
+
+  // Handle unranked tensors
+  if (!shapeX || !shapeY) return {elementType};
+
+  auto shapeLarge = shapeX.getRank() > shapeY.getRank() ? shapeX : shapeY;
+  auto shapeSmall = shapeX.getRank() <= shapeY.getRank() ? shapeX : shapeY;
 
   auto broadcastDimensions = broadcastDimensionsAttr.value();
-  if (broadcastDimensions.size() != shapeSmall.size()) {
+  if (broadcastDimensions.size() != shapeSmall.getRank()) {
     // Signal illegal broadcast_dimensions as unranked.
     return {elementType};
   }
   llvm::SmallVector<int64_t, 4> shapeLargeFiltered;
-  shapeLargeFiltered.reserve(shapeSmall.size());
+  shapeLargeFiltered.reserve(shapeSmall.getRank());
   for (const auto& dim : broadcastDimensions) {
-    if (dim >= static_cast<int64_t>(shapeLarge.size())) return {elementType};
-    shapeLargeFiltered.push_back(shapeLarge[dim]);
+    if (dim >= static_cast<int64_t>(shapeLarge.getRank())) return {elementType};
+    shapeLargeFiltered.push_back(shapeLarge.getDimSize(dim));
   }
   llvm::SmallVector<int64_t, 4> outShapeFiltered;
-  if (!mlir::OpTrait::util::getBroadcastedShape(shapeSmall, shapeLargeFiltered,
-                                                outShapeFiltered))
+  if (!mlir::OpTrait::util::getBroadcastedShape(
+          shapeSmall.getShape(), shapeLargeFiltered, outShapeFiltered))
     // Signal illegal broadcast_dimensions as unranked.
     return {elementType};
 
   // Update according to the broadcast dimensions.
-  llvm::SmallVector<int64_t, 4> outShape(shapeLarge.begin(), shapeLarge.end());
+  llvm::SmallVector<int64_t, 4> outShape(shapeLarge.getShape());
   for (const auto& indexPair : llvm::enumerate(broadcastDimensions)) {
     auto newValue = outShapeFiltered[indexPair.index()];
     outShape[indexPair.value()] = newValue;
   }
-
   return {outShape, elementType};
 }
 
@@ -160,6 +202,7 @@
     DictionaryAttr attributes, OpaqueProperties properties,
     std::optional<ArrayRef<int64_t>> broadcastDimensions, Type elementType,
     SmallVectorImpl<ShapedTypeComponents>& inferredReturnShapes) {
+  // Handle unranked.
   ShapedType lhsType = cast<ShapedType>(operands[0].getType());
   ShapedType rhsType = cast<ShapedType>(operands[1].getType());
   if (!lhsType || !rhsType ||
@@ -167,8 +210,8 @@
           lhsType.getElementType(), rhsType.getElementType()))
     return emitOptionalError(location, "mismatched operand types");
   if (!elementType) elementType = lhsType.getElementType();
-  inferredReturnShapes.push_back(
-      getBroadcastType(lhsType, rhsType, elementType, broadcastDimensions));
+  inferredReturnShapes.push_back(getBroadcastTypeWithBroadcastDimensions(
+      operands[0], operands[1], elementType, broadcastDimensions));
   return success();
 }
 
@@ -397,7 +440,6 @@
     DictionaryAttr, OpaqueProperties, RegionRange,
     SmallVectorImpl<ShapedTypeComponents>& inferredReturnShapes) {
   BroadcastSelectOp::Adaptor op(operands.getValues());
-  auto predType = cast<ShapedType>(op.getPred().getType());
   auto onTrueType = cast<ShapedType>(op.getOnTrue().getType());
   auto onFalseType = cast<ShapedType>(op.getOnFalse().getType());
 
@@ -407,12 +449,8 @@
   Type elementType = onTrueType.getElementType();
 
   // Compute the result shape as two binary broadcasts.
-  ShapedTypeComponents& components = inferredReturnShapes.emplace_back(
-      getBroadcastType(onTrueType, onFalseType, elementType, std::nullopt));
-  if (components.hasRank())
-    components = getBroadcastType(
-        RankedTensorType::get(components.getDims(), elementType), predType,
-        elementType, std::nullopt);
+  inferredReturnShapes.emplace_back(
+      getNumpyBroadcastType(llvm::to_vector(op.getOperands()), elementType));
   return success();
 }
 
diff --ruN a/stablehlo/stablehlo/dialect/StablehloOps.cpp b/stablehlo/stablehlo/dialect/StablehloOps.cpp
--- stablehlo/stablehlo/dialect/StablehloOps.cpp
+++ stablehlo/stablehlo/dialect/StablehloOps.cpp
@@ -1569,7 +1569,8 @@
 void ConvertOp::build(OpBuilder& builder, OperationState& result, Value operand,
                       Type resultElementTy) {
   auto rankedTy = cast<RankedTensorType>(operand.getType());
-  auto resultTy = RankedTensorType::get(rankedTy.getShape(), resultElementTy);
+  auto resultTy = RankedTensorType::get(rankedTy.getShape(), resultElementTy,
+                                        rankedTy.getEncoding());
   build(builder, result, resultTy, operand);
 }
 
diff --ruN a/stablehlo/stablehlo/dialect/TypeInference.cpp b/stablehlo/stablehlo/dialect/TypeInference.cpp
--- stablehlo/stablehlo/dialect/TypeInference.cpp
+++ stablehlo/stablehlo/dialect/TypeInference.cpp
@@ -2013,12 +2013,12 @@
     MLIRContext* context, std::optional<Location>, Value lhs,
     SmallVectorImpl<ShapedTypeComponents>& inferredReturnShapes) {
   // compare_c1
-  ShapedTypeComponents& components =
-      inferredReturnShapes.emplace_back(IntegerType::get(context, /*width=*/1));
-  auto argTy = cast<ShapedType>(lhs.getType());
+  ShapedTypeComponents& components = inferredReturnShapes.emplace_back();
+  auto argTy = cast<RankedTensorType>(lhs.getType());
+  auto resElementTy = IntegerType::get(context, /*width=*/1);
   // compare_c2
   components =
-      ShapedTypeComponents(argTy.getShape(), components.getElementType());
+      ShapedTypeComponents(argTy.getShape(), resElementTy, argTy.getEncoding());
   return success();
 }
 
@@ -2119,9 +2119,10 @@
 LogicalResult inferConvertOp(
     std::optional<Location> location, Value operand,
     SmallVectorImpl<ShapedTypeComponents>& inferredReturnShapes) {
-  auto operandType = cast<ShapedType>(operand.getType());
+  auto operandType = cast<RankedTensorType>(operand.getType());
   // convert_c1
-  inferredReturnShapes.emplace_back(operandType.getShape());
+  inferredReturnShapes.emplace_back(operandType.getShape(), nullptr,
+                                    operandType.getEncoding());
   return success();
 }
 
diff --ruN a/stablehlo/stablehlo/tests/chlo/chlo_legalize_to_stablehlo.mlir b/stablehlo/stablehlo/tests/chlo/chlo_legalize_to_stablehlo.mlir
--- stablehlo/stablehlo/tests/chlo/chlo_legalize_to_stablehlo.mlir
+++ stablehlo/stablehlo/tests/chlo/chlo_legalize_to_stablehlo.mlir
@@ -3913,6 +3913,149 @@
 
 // -----
 
+!bounded_type = tensor<?x16xf32, #stablehlo.bounds<16, ?>>
+// CHECK-LABEL:   func.func @erf_inv_bounded(
+// CHECK-SAME:      %[[ARG0:.*]]: tensor<?x16xf32, #stablehlo.bounds<16, ?>>) {
+// CHECK:           %[[NEGATE_0:.*]] = stablehlo.negate %[[ARG0]] : tensor<?x16xf32, #stablehlo.bounds<16, ?>>
+// CHECK:           %[[MULTIPLY_0:.*]] = stablehlo.multiply %[[ARG0]], %[[NEGATE_0]] : tensor<?x16xf32, #stablehlo.bounds<16, ?>>
+// CHECK:           %[[LOG_PLUS_ONE_0:.*]] = stablehlo.log_plus_one %[[MULTIPLY_0]] : tensor<?x16xf32, #stablehlo.bounds<16, ?>>
+// CHECK:           %[[NEGATE_1:.*]] = stablehlo.negate %[[LOG_PLUS_ONE_0]] : tensor<?x16xf32, #stablehlo.bounds<16, ?>>
+// CHECK:           %[[CONSTANT_0:.*]] = stablehlo.constant dense<5.000000e+00> : tensor<f32>
+// CHECK:           %[[BROADCAST_IN_DIM_0:.*]] = stablehlo.broadcast_in_dim %[[CONSTANT_0]], dims = [] : (tensor<f32>) -> tensor<16x16xf32>
+// CHECK:           %[[GET_DIMENSION_SIZE_0:.*]] = stablehlo.get_dimension_size %[[ARG0]], dim = 0 : (tensor<?x16xf32, #stablehlo.bounds<16, ?>>) -> tensor<i32>
+// CHECK:           %[[SET_DIMENSION_SIZE_0:.*]] = stablehlo.set_dimension_size %[[BROADCAST_IN_DIM_0]], %[[GET_DIMENSION_SIZE_0]], dim = 0 : (tensor<16x16xf32>, tensor<i32>) -> tensor<?x16xf32, #stablehlo.bounds<16, ?>>
+// CHECK:           %[[COMPARE_0:.*]] = stablehlo.compare  LT, %[[NEGATE_1]], %[[SET_DIMENSION_SIZE_0]] : (tensor<?x16xf32, #stablehlo.bounds<16, ?>>, tensor<?x16xf32, #stablehlo.bounds<16, ?>>) -> tensor<?x16xi1, #stablehlo.bounds<16, ?>>
+// CHECK:           %[[CONSTANT_1:.*]] = stablehlo.constant dense<2.500000e+00> : tensor<f32>
+// CHECK:           %[[BROADCAST_IN_DIM_1:.*]] = stablehlo.broadcast_in_dim %[[CONSTANT_1]], dims = [] : (tensor<f32>) -> tensor<16x16xf32>
+// CHECK:           %[[GET_DIMENSION_SIZE_1:.*]] = stablehlo.get_dimension_size %[[ARG0]], dim = 0 : (tensor<?x16xf32, #stablehlo.bounds<16, ?>>) -> tensor<i32>
+// CHECK:           %[[SET_DIMENSION_SIZE_1:.*]] = stablehlo.set_dimension_size %[[BROADCAST_IN_DIM_1]], %[[GET_DIMENSION_SIZE_1]], dim = 0 : (tensor<16x16xf32>, tensor<i32>) -> tensor<?x16xf32, #stablehlo.bounds<16, ?>>
+// CHECK:           %[[SUBTRACT_0:.*]] = stablehlo.subtract %[[NEGATE_1]], %[[SET_DIMENSION_SIZE_1]] : tensor<?x16xf32, #stablehlo.bounds<16, ?>>
+// CHECK:           %[[SQRT_0:.*]] = stablehlo.sqrt %[[NEGATE_1]] : tensor<?x16xf32, #stablehlo.bounds<16, ?>>
+// CHECK:           %[[CONSTANT_2:.*]] = stablehlo.constant dense<3.000000e+00> : tensor<f32>
+// CHECK:           %[[BROADCAST_IN_DIM_2:.*]] = stablehlo.broadcast_in_dim %[[CONSTANT_2]], dims = [] : (tensor<f32>) -> tensor<16x16xf32>
+// CHECK:           %[[GET_DIMENSION_SIZE_2:.*]] = stablehlo.get_dimension_size %[[ARG0]], dim = 0 : (tensor<?x16xf32, #stablehlo.bounds<16, ?>>) -> tensor<i32>
+// CHECK:           %[[SET_DIMENSION_SIZE_2:.*]] = stablehlo.set_dimension_size %[[BROADCAST_IN_DIM_2]], %[[GET_DIMENSION_SIZE_2]], dim = 0 : (tensor<16x16xf32>, tensor<i32>) -> tensor<?x16xf32, #stablehlo.bounds<16, ?>>
+// CHECK:           %[[SUBTRACT_1:.*]] = stablehlo.subtract %[[SQRT_0]], %[[SET_DIMENSION_SIZE_2]] : tensor<?x16xf32, #stablehlo.bounds<16, ?>>
+// CHECK:           %[[SELECT_0:.*]] = stablehlo.select %[[COMPARE_0]], %[[SUBTRACT_0]], %[[SUBTRACT_1]] : tensor<?x16xi1, #stablehlo.bounds<16, ?>>, tensor<?x16xf32, #stablehlo.bounds<16, ?>>
+// CHECK:           %[[CONSTANT_3:.*]] = stablehlo.constant dense<2.81022636E-8> : tensor<f32>
+// CHECK:           %[[BROADCAST_IN_DIM_3:.*]] = stablehlo.broadcast_in_dim %[[CONSTANT_3]], dims = [] : (tensor<f32>) -> tensor<16x16xf32>
+// CHECK:           %[[GET_DIMENSION_SIZE_3:.*]] = stablehlo.get_dimension_size %[[ARG0]], dim = 0 : (tensor<?x16xf32, #stablehlo.bounds<16, ?>>) -> tensor<i32>
+// CHECK:           %[[SET_DIMENSION_SIZE_3:.*]] = stablehlo.set_dimension_size %[[BROADCAST_IN_DIM_3]], %[[GET_DIMENSION_SIZE_3]], dim = 0 : (tensor<16x16xf32>, tensor<i32>) -> tensor<?x16xf32, #stablehlo.bounds<16, ?>>
+// CHECK:           %[[CONSTANT_4:.*]] = stablehlo.constant dense<-2.00214257E-4> : tensor<f32>
+// CHECK:           %[[BROADCAST_IN_DIM_4:.*]] = stablehlo.broadcast_in_dim %[[CONSTANT_4]], dims = [] : (tensor<f32>) -> tensor<16x16xf32>
+// CHECK:           %[[GET_DIMENSION_SIZE_4:.*]] = stablehlo.get_dimension_size %[[ARG0]], dim = 0 : (tensor<?x16xf32, #stablehlo.bounds<16, ?>>) -> tensor<i32>
+// CHECK:           %[[SET_DIMENSION_SIZE_4:.*]] = stablehlo.set_dimension_size %[[BROADCAST_IN_DIM_4]], %[[GET_DIMENSION_SIZE_4]], dim = 0 : (tensor<16x16xf32>, tensor<i32>) -> tensor<?x16xf32, #stablehlo.bounds<16, ?>>
+// CHECK:           %[[SELECT_1:.*]] = stablehlo.select %[[COMPARE_0]], %[[SET_DIMENSION_SIZE_3]], %[[SET_DIMENSION_SIZE_4]] : tensor<?x16xi1, #stablehlo.bounds<16, ?>>, tensor<?x16xf32, #stablehlo.bounds<16, ?>>
+// CHECK:           %[[CONSTANT_5:.*]] = stablehlo.constant dense<3.43273939E-7> : tensor<f32>
+// CHECK:           %[[BROADCAST_IN_DIM_5:.*]] = stablehlo.broadcast_in_dim %[[CONSTANT_5]], dims = [] : (tensor<f32>) -> tensor<16x16xf32>
+// CHECK:           %[[GET_DIMENSION_SIZE_5:.*]] = stablehlo.get_dimension_size %[[ARG0]], dim = 0 : (tensor<?x16xf32, #stablehlo.bounds<16, ?>>) -> tensor<i32>
+// CHECK:           %[[SET_DIMENSION_SIZE_5:.*]] = stablehlo.set_dimension_size %[[BROADCAST_IN_DIM_5]], %[[GET_DIMENSION_SIZE_5]], dim = 0 : (tensor<16x16xf32>, tensor<i32>) -> tensor<?x16xf32, #stablehlo.bounds<16, ?>>
+// CHECK:           %[[CONSTANT_6:.*]] = stablehlo.constant dense<1.00950558E-4> : tensor<f32>
+// CHECK:           %[[BROADCAST_IN_DIM_6:.*]] = stablehlo.broadcast_in_dim %[[CONSTANT_6]], dims = [] : (tensor<f32>) -> tensor<16x16xf32>
+// CHECK:           %[[GET_DIMENSION_SIZE_6:.*]] = stablehlo.get_dimension_size %[[ARG0]], dim = 0 : (tensor<?x16xf32, #stablehlo.bounds<16, ?>>) -> tensor<i32>
+// CHECK:           %[[SET_DIMENSION_SIZE_6:.*]] = stablehlo.set_dimension_size %[[BROADCAST_IN_DIM_6]], %[[GET_DIMENSION_SIZE_6]], dim = 0 : (tensor<16x16xf32>, tensor<i32>) -> tensor<?x16xf32, #stablehlo.bounds<16, ?>>
+// CHECK:           %[[SELECT_2:.*]] = stablehlo.select %[[COMPARE_0]], %[[SET_DIMENSION_SIZE_5]], %[[SET_DIMENSION_SIZE_6]] : tensor<?x16xi1, #stablehlo.bounds<16, ?>>, tensor<?x16xf32, #stablehlo.bounds<16, ?>>
+// CHECK:           %[[MULTIPLY_1:.*]] = stablehlo.multiply %[[SELECT_1]], %[[SELECT_0]] : tensor<?x16xf32, #stablehlo.bounds<16, ?>>
+// CHECK:           %[[ADD_0:.*]] = stablehlo.add %[[SELECT_2]], %[[MULTIPLY_1]] : tensor<?x16xf32, #stablehlo.bounds<16, ?>>
+// CHECK:           %[[CONSTANT_7:.*]] = stablehlo.constant dense<-3.5233877E-6> : tensor<f32>
+// CHECK:           %[[BROADCAST_IN_DIM_7:.*]] = stablehlo.broadcast_in_dim %[[CONSTANT_7]], dims = [] : (tensor<f32>) -> tensor<16x16xf32>
+// CHECK:           %[[GET_DIMENSION_SIZE_7:.*]] = stablehlo.get_dimension_size %[[ARG0]], dim = 0 : (tensor<?x16xf32, #stablehlo.bounds<16, ?>>) -> tensor<i32>
+// CHECK:           %[[SET_DIMENSION_SIZE_7:.*]] = stablehlo.set_dimension_size %[[BROADCAST_IN_DIM_7]], %[[GET_DIMENSION_SIZE_7]], dim = 0 : (tensor<16x16xf32>, tensor<i32>) -> tensor<?x16xf32, #stablehlo.bounds<16, ?>>
+// CHECK:           %[[CONSTANT_8:.*]] = stablehlo.constant dense<0.00134934322> : tensor<f32>
+// CHECK:           %[[BROADCAST_IN_DIM_8:.*]] = stablehlo.broadcast_in_dim %[[CONSTANT_8]], dims = [] : (tensor<f32>) -> tensor<16x16xf32>
+// CHECK:           %[[GET_DIMENSION_SIZE_8:.*]] = stablehlo.get_dimension_size %[[ARG0]], dim = 0 : (tensor<?x16xf32, #stablehlo.bounds<16, ?>>) -> tensor<i32>
+// CHECK:           %[[SET_DIMENSION_SIZE_8:.*]] = stablehlo.set_dimension_size %[[BROADCAST_IN_DIM_8]], %[[GET_DIMENSION_SIZE_8]], dim = 0 : (tensor<16x16xf32>, tensor<i32>) -> tensor<?x16xf32, #stablehlo.bounds<16, ?>>
+// CHECK:           %[[SELECT_3:.*]] = stablehlo.select %[[COMPARE_0]], %[[SET_DIMENSION_SIZE_7]], %[[SET_DIMENSION_SIZE_8]] : tensor<?x16xi1, #stablehlo.bounds<16, ?>>, tensor<?x16xf32, #stablehlo.bounds<16, ?>>
+// CHECK:           %[[MULTIPLY_2:.*]] = stablehlo.multiply %[[ADD_0]], %[[SELECT_0]] : tensor<?x16xf32, #stablehlo.bounds<16, ?>>
+// CHECK:           %[[ADD_1:.*]] = stablehlo.add %[[SELECT_3]], %[[MULTIPLY_2]] : tensor<?x16xf32, #stablehlo.bounds<16, ?>>
+// CHECK:           %[[CONSTANT_9:.*]] = stablehlo.constant dense<-4.39150654E-6> : tensor<f32>
+// CHECK:           %[[BROADCAST_IN_DIM_9:.*]] = stablehlo.broadcast_in_dim %[[CONSTANT_9]], dims = [] : (tensor<f32>) -> tensor<16x16xf32>
+// CHECK:           %[[GET_DIMENSION_SIZE_9:.*]] = stablehlo.get_dimension_size %[[ARG0]], dim = 0 : (tensor<?x16xf32, #stablehlo.bounds<16, ?>>) -> tensor<i32>
+// CHECK:           %[[SET_DIMENSION_SIZE_9:.*]] = stablehlo.set_dimension_size %[[BROADCAST_IN_DIM_9]], %[[GET_DIMENSION_SIZE_9]], dim = 0 : (tensor<16x16xf32>, tensor<i32>) -> tensor<?x16xf32, #stablehlo.bounds<16, ?>>
+// CHECK:           %[[CONSTANT_10:.*]] = stablehlo.constant dense<-0.00367342844> : tensor<f32>
+// CHECK:           %[[BROADCAST_IN_DIM_10:.*]] = stablehlo.broadcast_in_dim %[[CONSTANT_10]], dims = [] : (tensor<f32>) -> tensor<16x16xf32>
+// CHECK:           %[[GET_DIMENSION_SIZE_10:.*]] = stablehlo.get_dimension_size %[[ARG0]], dim = 0 : (tensor<?x16xf32, #stablehlo.bounds<16, ?>>) -> tensor<i32>
+// CHECK:           %[[SET_DIMENSION_SIZE_10:.*]] = stablehlo.set_dimension_size %[[BROADCAST_IN_DIM_10]], %[[GET_DIMENSION_SIZE_10]], dim = 0 : (tensor<16x16xf32>, tensor<i32>) -> tensor<?x16xf32, #stablehlo.bounds<16, ?>>
+// CHECK:           %[[SELECT_4:.*]] = stablehlo.select %[[COMPARE_0]], %[[SET_DIMENSION_SIZE_9]], %[[SET_DIMENSION_SIZE_10]] : tensor<?x16xi1, #stablehlo.bounds<16, ?>>, tensor<?x16xf32, #stablehlo.bounds<16, ?>>
+// CHECK:           %[[MULTIPLY_3:.*]] = stablehlo.multiply %[[ADD_1]], %[[SELECT_0]] : tensor<?x16xf32, #stablehlo.bounds<16, ?>>
+// CHECK:           %[[ADD_2:.*]] = stablehlo.add %[[SELECT_4]], %[[MULTIPLY_3]] : tensor<?x16xf32, #stablehlo.bounds<16, ?>>
+// CHECK:           %[[CONSTANT_11:.*]] = stablehlo.constant dense<2.1858087E-4> : tensor<f32>
+// CHECK:           %[[BROADCAST_IN_DIM_11:.*]] = stablehlo.broadcast_in_dim %[[CONSTANT_11]], dims = [] : (tensor<f32>) -> tensor<16x16xf32>
+// CHECK:           %[[GET_DIMENSION_SIZE_11:.*]] = stablehlo.get_dimension_size %[[ARG0]], dim = 0 : (tensor<?x16xf32, #stablehlo.bounds<16, ?>>) -> tensor<i32>
+// CHECK:           %[[SET_DIMENSION_SIZE_11:.*]] = stablehlo.set_dimension_size %[[BROADCAST_IN_DIM_11]], %[[GET_DIMENSION_SIZE_11]], dim = 0 : (tensor<16x16xf32>, tensor<i32>) -> tensor<?x16xf32, #stablehlo.bounds<16, ?>>
+// CHECK:           %[[CONSTANT_12:.*]] = stablehlo.constant dense<0.00573950773> : tensor<f32>
+// CHECK:           %[[BROADCAST_IN_DIM_12:.*]] = stablehlo.broadcast_in_dim %[[CONSTANT_12]], dims = [] : (tensor<f32>) -> tensor<16x16xf32>
+// CHECK:           %[[GET_DIMENSION_SIZE_12:.*]] = stablehlo.get_dimension_size %[[ARG0]], dim = 0 : (tensor<?x16xf32, #stablehlo.bounds<16, ?>>) -> tensor<i32>
+// CHECK:           %[[SET_DIMENSION_SIZE_12:.*]] = stablehlo.set_dimension_size %[[BROADCAST_IN_DIM_12]], %[[GET_DIMENSION_SIZE_12]], dim = 0 : (tensor<16x16xf32>, tensor<i32>) -> tensor<?x16xf32, #stablehlo.bounds<16, ?>>
+// CHECK:           %[[SELECT_5:.*]] = stablehlo.select %[[COMPARE_0]], %[[SET_DIMENSION_SIZE_11]], %[[SET_DIMENSION_SIZE_12]] : tensor<?x16xi1, #stablehlo.bounds<16, ?>>, tensor<?x16xf32, #stablehlo.bounds<16, ?>>
+// CHECK:           %[[MULTIPLY_4:.*]] = stablehlo.multiply %[[ADD_2]], %[[SELECT_0]] : tensor<?x16xf32, #stablehlo.bounds<16, ?>>
+// CHECK:           %[[ADD_3:.*]] = stablehlo.add %[[SELECT_5]], %[[MULTIPLY_4]] : tensor<?x16xf32, #stablehlo.bounds<16, ?>>
+// CHECK:           %[[CONSTANT_13:.*]] = stablehlo.constant dense<-0.00125372503> : tensor<f32>
+// CHECK:           %[[BROADCAST_IN_DIM_13:.*]] = stablehlo.broadcast_in_dim %[[CONSTANT_13]], dims = [] : (tensor<f32>) -> tensor<16x16xf32>
+// CHECK:           %[[GET_DIMENSION_SIZE_13:.*]] = stablehlo.get_dimension_size %[[ARG0]], dim = 0 : (tensor<?x16xf32, #stablehlo.bounds<16, ?>>) -> tensor<i32>
+// CHECK:           %[[SET_DIMENSION_SIZE_13:.*]] = stablehlo.set_dimension_size %[[BROADCAST_IN_DIM_13]], %[[GET_DIMENSION_SIZE_13]], dim = 0 : (tensor<16x16xf32>, tensor<i32>) -> tensor<?x16xf32, #stablehlo.bounds<16, ?>>
+// CHECK:           %[[CONSTANT_14:.*]] = stablehlo.constant dense<-0.0076224613> : tensor<f32>
+// CHECK:           %[[BROADCAST_IN_DIM_14:.*]] = stablehlo.broadcast_in_dim %[[CONSTANT_14]], dims = [] : (tensor<f32>) -> tensor<16x16xf32>
+// CHECK:           %[[GET_DIMENSION_SIZE_14:.*]] = stablehlo.get_dimension_size %[[ARG0]], dim = 0 : (tensor<?x16xf32, #stablehlo.bounds<16, ?>>) -> tensor<i32>
+// CHECK:           %[[SET_DIMENSION_SIZE_14:.*]] = stablehlo.set_dimension_size %[[BROADCAST_IN_DIM_14]], %[[GET_DIMENSION_SIZE_14]], dim = 0 : (tensor<16x16xf32>, tensor<i32>) -> tensor<?x16xf32, #stablehlo.bounds<16, ?>>
+// CHECK:           %[[SELECT_6:.*]] = stablehlo.select %[[COMPARE_0]], %[[SET_DIMENSION_SIZE_13]], %[[SET_DIMENSION_SIZE_14]] : tensor<?x16xi1, #stablehlo.bounds<16, ?>>, tensor<?x16xf32, #stablehlo.bounds<16, ?>>
+// CHECK:           %[[MULTIPLY_5:.*]] = stablehlo.multiply %[[ADD_3]], %[[SELECT_0]] : tensor<?x16xf32, #stablehlo.bounds<16, ?>>
+// CHECK:           %[[ADD_4:.*]] = stablehlo.add %[[SELECT_6]], %[[MULTIPLY_5]] : tensor<?x16xf32, #stablehlo.bounds<16, ?>>
+// CHECK:           %[[CONSTANT_15:.*]] = stablehlo.constant dense<-0.00417768164> : tensor<f32>
+// CHECK:           %[[BROADCAST_IN_DIM_15:.*]] = stablehlo.broadcast_in_dim %[[CONSTANT_15]], dims = [] : (tensor<f32>) -> tensor<16x16xf32>
+// CHECK:           %[[GET_DIMENSION_SIZE_15:.*]] = stablehlo.get_dimension_size %[[ARG0]], dim = 0 : (tensor<?x16xf32, #stablehlo.bounds<16, ?>>) -> tensor<i32>
+// CHECK:           %[[SET_DIMENSION_SIZE_15:.*]] = stablehlo.set_dimension_size %[[BROADCAST_IN_DIM_15]], %[[GET_DIMENSION_SIZE_15]], dim = 0 : (tensor<16x16xf32>, tensor<i32>) -> tensor<?x16xf32, #stablehlo.bounds<16, ?>>
+// CHECK:           %[[CONSTANT_16:.*]] = stablehlo.constant dense<0.00943887047> : tensor<f32>
+// CHECK:           %[[BROADCAST_IN_DIM_16:.*]] = stablehlo.broadcast_in_dim %[[CONSTANT_16]], dims = [] : (tensor<f32>) -> tensor<16x16xf32>
+// CHECK:           %[[GET_DIMENSION_SIZE_16:.*]] = stablehlo.get_dimension_size %[[ARG0]], dim = 0 : (tensor<?x16xf32, #stablehlo.bounds<16, ?>>) -> tensor<i32>
+// CHECK:           %[[SET_DIMENSION_SIZE_16:.*]] = stablehlo.set_dimension_size %[[BROADCAST_IN_DIM_16]], %[[GET_DIMENSION_SIZE_16]], dim = 0 : (tensor<16x16xf32>, tensor<i32>) -> tensor<?x16xf32, #stablehlo.bounds<16, ?>>
+// CHECK:           %[[SELECT_7:.*]] = stablehlo.select %[[COMPARE_0]], %[[SET_DIMENSION_SIZE_15]], %[[SET_DIMENSION_SIZE_16]] : tensor<?x16xi1, #stablehlo.bounds<16, ?>>, tensor<?x16xf32, #stablehlo.bounds<16, ?>>
+// CHECK:           %[[MULTIPLY_6:.*]] = stablehlo.multiply %[[ADD_4]], %[[SELECT_0]] : tensor<?x16xf32, #stablehlo.bounds<16, ?>>
+// CHECK:           %[[ADD_5:.*]] = stablehlo.add %[[SELECT_7]], %[[MULTIPLY_6]] : tensor<?x16xf32, #stablehlo.bounds<16, ?>>
+// CHECK:           %[[CONSTANT_17:.*]] = stablehlo.constant dense<0.246640727> : tensor<f32>
+// CHECK:           %[[BROADCAST_IN_DIM_17:.*]] = stablehlo.broadcast_in_dim %[[CONSTANT_17]], dims = [] : (tensor<f32>) -> tensor<16x16xf32>
+// CHECK:           %[[GET_DIMENSION_SIZE_17:.*]] = stablehlo.get_dimension_size %[[ARG0]], dim = 0 : (tensor<?x16xf32, #stablehlo.bounds<16, ?>>) -> tensor<i32>
+// CHECK:           %[[SET_DIMENSION_SIZE_17:.*]] = stablehlo.set_dimension_size %[[BROADCAST_IN_DIM_17]], %[[GET_DIMENSION_SIZE_17]], dim = 0 : (tensor<16x16xf32>, tensor<i32>) -> tensor<?x16xf32, #stablehlo.bounds<16, ?>>
+// CHECK:           %[[CONSTANT_18:.*]] = stablehlo.constant dense<1.00167406> : tensor<f32>
+// CHECK:           %[[BROADCAST_IN_DIM_18:.*]] = stablehlo.broadcast_in_dim %[[CONSTANT_18]], dims = [] : (tensor<f32>) -> tensor<16x16xf32>
+// CHECK:           %[[GET_DIMENSION_SIZE_18:.*]] = stablehlo.get_dimension_size %[[ARG0]], dim = 0 : (tensor<?x16xf32, #stablehlo.bounds<16, ?>>) -> tensor<i32>
+// CHECK:           %[[SET_DIMENSION_SIZE_18:.*]] = stablehlo.set_dimension_size %[[BROADCAST_IN_DIM_18]], %[[GET_DIMENSION_SIZE_18]], dim = 0 : (tensor<16x16xf32>, tensor<i32>) -> tensor<?x16xf32, #stablehlo.bounds<16, ?>>
+// CHECK:           %[[SELECT_8:.*]] = stablehlo.select %[[COMPARE_0]], %[[SET_DIMENSION_SIZE_17]], %[[SET_DIMENSION_SIZE_18]] : tensor<?x16xi1, #stablehlo.bounds<16, ?>>, tensor<?x16xf32, #stablehlo.bounds<16, ?>>
+// CHECK:           %[[MULTIPLY_7:.*]] = stablehlo.multiply %[[ADD_5]], %[[SELECT_0]] : tensor<?x16xf32, #stablehlo.bounds<16, ?>>
+// CHECK:           %[[ADD_6:.*]] = stablehlo.add %[[SELECT_8]], %[[MULTIPLY_7]] : tensor<?x16xf32, #stablehlo.bounds<16, ?>>
+// CHECK:           %[[CONSTANT_19:.*]] = stablehlo.constant dense<1.50140941> : tensor<f32>
+// CHECK:           %[[BROADCAST_IN_DIM_19:.*]] = stablehlo.broadcast_in_dim %[[CONSTANT_19]], dims = [] : (tensor<f32>) -> tensor<16x16xf32>
+// CHECK:           %[[GET_DIMENSION_SIZE_19:.*]] = stablehlo.get_dimension_size %[[ARG0]], dim = 0 : (tensor<?x16xf32, #stablehlo.bounds<16, ?>>) -> tensor<i32>
+// CHECK:           %[[SET_DIMENSION_SIZE_19:.*]] = stablehlo.set_dimension_size %[[BROADCAST_IN_DIM_19]], %[[GET_DIMENSION_SIZE_19]], dim = 0 : (tensor<16x16xf32>, tensor<i32>) -> tensor<?x16xf32, #stablehlo.bounds<16, ?>>
+// CHECK:           %[[CONSTANT_20:.*]] = stablehlo.constant dense<2.83297682> : tensor<f32>
+// CHECK:           %[[BROADCAST_IN_DIM_20:.*]] = stablehlo.broadcast_in_dim %[[CONSTANT_20]], dims = [] : (tensor<f32>) -> tensor<16x16xf32>
+// CHECK:           %[[GET_DIMENSION_SIZE_20:.*]] = stablehlo.get_dimension_size %[[ARG0]], dim = 0 : (tensor<?x16xf32, #stablehlo.bounds<16, ?>>) -> tensor<i32>
+// CHECK:           %[[SET_DIMENSION_SIZE_20:.*]] = stablehlo.set_dimension_size %[[BROADCAST_IN_DIM_20]], %[[GET_DIMENSION_SIZE_20]], dim = 0 : (tensor<16x16xf32>, tensor<i32>) -> tensor<?x16xf32, #stablehlo.bounds<16, ?>>
+// CHECK:           %[[SELECT_9:.*]] = stablehlo.select %[[COMPARE_0]], %[[SET_DIMENSION_SIZE_19]], %[[SET_DIMENSION_SIZE_20]] : tensor<?x16xi1, #stablehlo.bounds<16, ?>>, tensor<?x16xf32, #stablehlo.bounds<16, ?>>
+// CHECK:           %[[MULTIPLY_8:.*]] = stablehlo.multiply %[[ADD_6]], %[[SELECT_0]] : tensor<?x16xf32, #stablehlo.bounds<16, ?>>
+// CHECK:           %[[ADD_7:.*]] = stablehlo.add %[[SELECT_9]], %[[MULTIPLY_8]] : tensor<?x16xf32, #stablehlo.bounds<16, ?>>
+// CHECK:           %[[MULTIPLY_9:.*]] = stablehlo.multiply %[[ADD_7]], %[[ARG0]] : tensor<?x16xf32, #stablehlo.bounds<16, ?>>
+// CHECK:           %[[ABS_0:.*]] = stablehlo.abs %[[ARG0]] : tensor<?x16xf32, #stablehlo.bounds<16, ?>>
+// CHECK:           %[[CONSTANT_21:.*]] = stablehlo.constant dense<1.000000e+00> : tensor<f32>
+// CHECK:           %[[BROADCAST_IN_DIM_21:.*]] = stablehlo.broadcast_in_dim %[[CONSTANT_21]], dims = [] : (tensor<f32>) -> tensor<16x16xf32>
+// CHECK:           %[[GET_DIMENSION_SIZE_21:.*]] = stablehlo.get_dimension_size %[[ARG0]], dim = 0 : (tensor<?x16xf32, #stablehlo.bounds<16, ?>>) -> tensor<i32>
+// CHECK:           %[[SET_DIMENSION_SIZE_21:.*]] = stablehlo.set_dimension_size %[[BROADCAST_IN_DIM_21]], %[[GET_DIMENSION_SIZE_21]], dim = 0 : (tensor<16x16xf32>, tensor<i32>) -> tensor<?x16xf32, #stablehlo.bounds<16, ?>>
+// CHECK:           %[[COMPARE_1:.*]] = stablehlo.compare  EQ, %[[ABS_0]], %[[SET_DIMENSION_SIZE_21]] : (tensor<?x16xf32, #stablehlo.bounds<16, ?>>, tensor<?x16xf32, #stablehlo.bounds<16, ?>>) -> tensor<?x16xi1, #stablehlo.bounds<16, ?>>
+// CHECK:           %[[CONSTANT_22:.*]] = stablehlo.constant dense<0x7F800000> : tensor<f32>
+// CHECK:           %[[BROADCAST_IN_DIM_22:.*]] = stablehlo.broadcast_in_dim %[[CONSTANT_22]], dims = [] : (tensor<f32>) -> tensor<16x16xf32>
+// CHECK:           %[[GET_DIMENSION_SIZE_22:.*]] = stablehlo.get_dimension_size %[[ARG0]], dim = 0 : (tensor<?x16xf32, #stablehlo.bounds<16, ?>>) -> tensor<i32>
+// CHECK:           %[[SET_DIMENSION_SIZE_22:.*]] = stablehlo.set_dimension_size %[[BROADCAST_IN_DIM_22]], %[[GET_DIMENSION_SIZE_22]], dim = 0 : (tensor<16x16xf32>, tensor<i32>) -> tensor<?x16xf32, #stablehlo.bounds<16, ?>>
+// CHECK:           %[[MULTIPLY_10:.*]] = stablehlo.multiply %[[ARG0]], %[[SET_DIMENSION_SIZE_22]] : tensor<?x16xf32, #stablehlo.bounds<16, ?>>
+// CHECK:           %[[SELECT_10:.*]] = stablehlo.select %[[COMPARE_1]], %[[MULTIPLY_10]], %[[MULTIPLY_9]] : tensor<?x16xi1, #stablehlo.bounds<16, ?>>, tensor<?x16xf32, #stablehlo.bounds<16, ?>>
+// CHECK:           return
+// CHECK:         }
+func.func @erf_inv_bounded(%arg0 : !bounded_type) {
+  %0 = chlo.erf_inv %arg0 : !bounded_type -> !bounded_type
+  return
+}
+
+// -----
+
 // CHECK-LABEL:   @square_complex_f32(
 // CHECK-SAME:                                  %[[VAL_0:.*]]: tensor<complex<f32>>) -> tensor<complex<f32>> {
 // CHECK:           %[[VAL_1:.*]] = stablehlo.real %[[VAL_0]] : (tensor<complex<f32>>) -> tensor<f32>
diff --ruN a/stablehlo/stablehlo/tests/infer_chlo.mlir b/stablehlo/stablehlo/tests/infer_chlo.mlir
--- stablehlo/stablehlo/tests/infer_chlo.mlir
+++ stablehlo/stablehlo/tests/infer_chlo.mlir
@@ -239,3 +239,41 @@
   %r17 = "hlo_test_infer.get_return_types"(%17) : (tensor<2xf32>) -> tensor<2xf32>
   func.return %r17 : tensor<2xf32>
 }
+
+// -----
+
+/////
+// Bounded dynamic
+
+// [<=10] x [1] => [<=10]
+// CHECK-LABEL: @bounded_dynamic_broadcast_scalar
+func.func @bounded_dynamic_broadcast_scalar(%arg0: tensor<?xf64, #stablehlo.bounds<10>>, %arg1: tensor<f64>) -> tensor<?xf64, #stablehlo.bounds<10>> {
+  %0 = chlo.broadcast_add %arg0, %arg1 : (tensor<?xf64, #stablehlo.bounds<10>>, tensor<f64>) -> tensor<?xf64, #stablehlo.bounds<10>>
+  // CHECK: types0 = tensor<?xf64, #stablehlo.bounds<10>>
+  %1 = "hlo_test_infer.get_return_types"(%0) : (tensor<?xf64, #stablehlo.bounds<10>>) -> tensor<?xf64, #stablehlo.bounds<10>>
+  return %1 : tensor<?xf64, #stablehlo.bounds<10>>
+}
+
+// -----
+
+// [<=10] x [?] => [?]
+// CHECK-LABEL: @bounded_dynamic_broadcast_unbounded
+!bounded_type = tensor<?xf64, #stablehlo.bounds<10>>
+!unbounded_type = tensor<?xf64>
+func.func @bounded_dynamic_broadcast_unbounded(%arg0: !bounded_type, %arg1: !unbounded_type) -> !unbounded_type {
+  %0 = chlo.broadcast_add %arg0, %arg1 : (!bounded_type, !unbounded_type) -> !unbounded_type
+  // CHECK: types0 = tensor<?xf64>
+  %1 = "hlo_test_infer.get_return_types"(%0) : (!unbounded_type) -> !unbounded_type
+  return %1 : !unbounded_type
+}
+
+// -----
+
+// CHECK-LABEL: @broadcast_select_types_bounded
+!bounded_type = tensor<?xf64, #stablehlo.bounds<10>>
+func.func @broadcast_select_types_bounded(%arg0: tensor<i1>, %arg1: !bounded_type, %arg2: !bounded_type) -> !bounded_type {
+  %0 = "chlo.broadcast_select"(%arg0, %arg1, %arg2) : (tensor<i1>, !bounded_type, !bounded_type) -> !bounded_type
+  // CHECK: types0 = tensor<?xf64, #stablehlo.bounds<10>>
+  %1 = "hlo_test_infer.get_return_types"(%0) : (!bounded_type) -> !bounded_type
+  return %1: !bounded_type
+}
diff --ruN a/stablehlo/stablehlo/transforms/StablehloBroadcastLowering.cpp b/stablehlo/stablehlo/transforms/StablehloBroadcastLowering.cpp
--- stablehlo/stablehlo/transforms/StablehloBroadcastLowering.cpp
+++ stablehlo/stablehlo/transforms/StablehloBroadcastLowering.cpp
@@ -92,7 +92,6 @@
 
     // If both LHS and RHS are not 1, dim size must match.
     if (dim_a.size != dim_b.size) {
-      // FIXME
       return emitError(op.getLoc(), "incompatible shapes for broadcasting ")
              << dim_a.size << " and " << dim_b.size;
     }
@@ -157,11 +156,10 @@
   return mlir::RankedTensorType::get(shape, element_type, encoding);
 }
 
-FailureOr<Dimensions> getNumpyBroadcastShape(OpBuilder& builder,
+FailureOr<Dimensions> getNumpyBroadcastShape(Location loc,
                                              ArrayRef<Value> ops) {
   if (ops.empty())
-    return emitError(builder.getInsertionPoint()->getLoc(),
-                     "requires at least one operand to broadcast");
+    return emitError(loc, "requires at least one operand to broadcast");
 
   Value first = ops[0];
   auto bcastShapeOrFail = getDimensions(first);
@@ -197,7 +195,8 @@
 FailureOr<SmallVector<Value>> numpyBroadcastIfNeeded(OpBuilder& builder,
                                                      ArrayRef<Value> operands) {
   // Figure out the broadcast shape
-  auto bcastShapeOrFail = getNumpyBroadcastShape(builder, operands);
+  auto errLoc = builder.getInsertionPoint()->getLoc();
+  auto bcastShapeOrFail = getNumpyBroadcastShape(errLoc, operands);
   if (failed(bcastShapeOrFail)) return failure();
   Dimensions bcastShape = std::move(*bcastShapeOrFail);
 
diff --ruN a/stablehlo/stablehlo/transforms/StablehloBroadcastLowering.h b/stablehlo/stablehlo/transforms/StablehloBroadcastLowering.h
--- stablehlo/stablehlo/transforms/StablehloBroadcastLowering.h
+++ stablehlo/stablehlo/transforms/StablehloBroadcastLowering.h
@@ -22,6 +22,7 @@
 #include <string>
 
 #include "mlir/IR/Builders.h"
+#include "mlir/IR/Location.h"
 #include "mlir/IR/Value.h"
 #include "mlir/Support/LLVM.h"
 
@@ -57,8 +58,7 @@
 
 // Returns the common shape these ops would broadcast to, or an error if the
 // ops are not broadcastable.
-FailureOr<Dimensions> getNumpyBroadcastShape(OpBuilder& builder,
-                                             ArrayRef<Value> ops);
+FailureOr<Dimensions> getNumpyBroadcastShape(Location loc, ArrayRef<Value> ops);
 
 // Apply numpy broadcasting to the given operands, returning an error if any
 // operands are not broadcastable.

