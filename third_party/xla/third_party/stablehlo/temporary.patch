diff --ruN a/stablehlo/BUILD.bazel b/stablehlo/BUILD.bazel
--- stablehlo/BUILD.bazel
+++ stablehlo/BUILD.bazel
@@ -2000,6 +2000,7 @@
     deps = [
         ":attr_type_builder_util",
         ":mlir_builder",
+        ":stablehlo_broadcast_lowering",
         ":stablehlo_builder_inc",
         ":stablehlo_ops",
         ":stablehlo_type_inference",
diff --ruN a/stablehlo/stablehlo/dialect/ChloOps.cpp b/stablehlo/stablehlo/dialect/ChloOps.cpp
--- stablehlo/stablehlo/dialect/ChloOps.cpp
+++ stablehlo/stablehlo/dialect/ChloOps.cpp
@@ -781,6 +781,220 @@
   return success();
 }
 
+//===----------------------------------------------------------------------===//
+// ScanOp
+//===----------------------------------------------------------------------===//
+
+LogicalResult ScanOp::inferReturnTypeComponents(
+    MLIRContext*, std::optional<Location> location, ValueShapeRange operands,
+    DictionaryAttr attributes, OpaqueProperties properties, RegionRange regions,
+    SmallVectorImpl<ShapedTypeComponents>& inferredReturnShapes) {
+  ScanOp::Adaptor adaptor(operands, attributes, properties, regions);
+  if (regions.empty() || regions.front()->empty()) {
+    return emitOptionalError(location, "ScanOp region is empty");
+  }
+  auto* terminator = regions.front()->front().getTerminator();
+  size_t numCarries = adaptor.getInits().size();
+  if (terminator->getNumOperands() < numCarries) {
+    return emitOptionalError(location, "ScanOp body must return at least ",
+                             numCarries, " values (carries)");
+  }
+  size_t numOutputs = terminator->getNumOperands() - numCarries;
+
+  // Find the scan dimension size. If the scan dimension is dynamic, the
+  // output dimension size will be dynamic as well.
+  int64_t dim = adaptor.getDimension();
+  int64_t dimSize = ShapedType::kDynamic;
+  for (auto [i, type] : llvm::enumerate(adaptor.getInputs().getTypes())) {
+    auto inputType = dyn_cast<RankedTensorType>(type);
+    if (!inputType) {
+      return emitOptionalError(location, "operand ", i, " is not ranked");
+    }
+    if (dim >= inputType.getRank()) {
+      return emitOptionalError(location, "scan dimension of operand ", i,
+                               " is out of bounds");
+    }
+    dimSize = inputType.getDimSize(dim);
+    if (dimSize == ShapedType::kDynamic) {
+      break;
+    }
+  }
+
+  for (auto [i, type] : llvm::enumerate(terminator->getOperands().getTypes())) {
+    auto resultType = dyn_cast<RankedTensorType>(type);
+    if (!resultType) {
+      return emitOptionalError(location, "terminator operand ", i,
+                               " is not ranked");
+    }
+    SmallVector<int64_t> shape(resultType.getShape().begin(),
+                               resultType.getShape().end());
+    if (i < numOutputs) {
+      shape.insert(std::next(shape.begin(), dim), dimSize);
+    }
+    inferredReturnShapes.emplace_back(shape, resultType.getElementType());
+  }
+
+  return success();
+}
+
+LogicalResult ScanOp::reifyReturnTypeShapes(
+    OpBuilder& builder, ValueRange operands,
+    SmallVectorImpl<Value>& reifiedReturnShapes) {
+  ScanOp::Adaptor adaptor(operands, getOperation()->getAttrDictionary(),
+                          getOperation()->getPropertiesStorage());
+  auto inputs = adaptor.getInputs();
+  size_t k = adaptor.getInits().size();
+  size_t numResults = getOperation()->getNumResults();
+  size_t numOutputs = numResults - k;
+
+  for (size_t i = 0; i < numOutputs; ++i) {
+    size_t inputIdx = i;
+    Value inputVal = (inputIdx < inputs.size()) ? inputs[inputIdx] : inputs[0];
+    if (failed(hlo::deriveShapeFromOperand(&builder, getOperation(), inputVal,
+                                           &reifiedReturnShapes))) {
+      return failure();
+    }
+  }
+
+  for (auto init : adaptor.getInits()) {
+    if (failed(hlo::deriveShapeFromOperand(&builder, getOperation(), init,
+                                           &reifiedReturnShapes))) {
+      return failure();
+    }
+  }
+  return success();
+}
+
+LogicalResult ScanOp::verify() {
+  if (getInits().size() != getCarries().size()) {
+    return emitOpError() << "requires the number of inits ("
+                         << getInits().size() << ") and carries ("
+                         << getCarries().size() << ") to be equal";
+  }
+
+  // Check that the scan dimension is in bounds for all operands. Also check
+  // that all operands have the same scan dimension size.
+  int64_t dim = getDimension();
+  int64_t dimSize = ShapedType::kDynamic;
+  for (auto [i, type] : llvm::enumerate(getInputs().getTypes())) {
+    auto inputType = dyn_cast<RankedTensorType>(type);
+    if (!inputType) {
+      return emitOpError() << "operand " << i << " is not ranked";
+    }
+    if (dim >= inputType.getRank()) {
+      return emitOpError() << "scan dimension of operand " << i
+                           << " is out of bounds";
+    }
+    if (inputType.isDynamicDim(dim)) {
+      continue;
+    }
+    dimSize = inputType.getDimSize(dim);
+    if (dimSize != ShapedType::kDynamic &&
+        dimSize != inputType.getDimSize(dim)) {
+      return emitOpError() << "scan dimension size of operand " << i
+                           << " does not match previous operands";
+    }
+    dimSize = inputType.getDimSize(dim);
+  }
+
+  Block& bodyBlock = getBody().front();
+  if (bodyBlock.getNumArguments() != getNumOperands()) {
+    return emitOpError() << "expects " << getNumOperands()
+                         << " arguments in the body, but got "
+                         << bodyBlock.getNumArguments();
+  }
+
+  // Check that the operand types are compatible with the body arguments.
+  for (auto [i, type] : llvm::enumerate(getOperands().getTypes())) {
+    auto argType = dyn_cast<RankedTensorType>(type);
+    if (!argType) {
+      return emitOpError() << "operand " << i << " is not ranked";
+    }
+    if (i < getInputs().size()) {
+      auto argShape = llvm::to_vector(argType.getShape());
+      argShape.erase(std::next(argShape.begin(), dim));
+      argType = argType.clone(argShape);
+    }
+    if (!hlo::isCompatibleForHloTypeInference(
+            argType, bodyBlock.getArgument(i).getType())) {
+      return emitOpError() << "operand and body argument " << i
+                           << " are incompatible";
+    }
+  }
+
+  // Compatibility of terminator operands and result types is checked by
+  // InferTensorType trait.
+
+  return success();
+}
+
+ParseResult ScanOp::parse(OpAsmParser& parser, OperationState& result) {
+  SmallVector<OpAsmParser::UnresolvedOperand, 4> inputs, inits;
+  int64_t dimension = 0;
+  Region* body = result.addRegion();
+  FunctionType funcType;
+
+  if (parser.parseOperandList(inputs, OpAsmParser::Delimiter::Paren) ||
+      parser.parseKeyword("inits") ||
+      parser.parseOperandList(inits, OpAsmParser::Delimiter::Paren) ||
+      parser.parseKeyword("dimension") || parser.parseEqual() ||
+      parser.parseInteger(dimension) || parser.parseRegion(*body) ||
+      parser.parseOptionalAttrDict(result.attributes) ||
+      parser.parseColonType(funcType)) {
+    return failure();
+  }
+
+  size_t numInputs = inputs.size();
+  size_t numCarries = inits.size();
+  if (funcType.getInputs().size() != numInputs + numCarries) {
+    return parser.emitError(
+        parser.getNameLoc(),
+        "operand types must match the number of inputs and inits");
+  }
+  if (funcType.getResults().size() < numCarries) {
+    return parser.emitError(
+        parser.getNameLoc(),
+        "not enough result types to cover the required carries");
+  }
+
+  auto inputTypes = funcType.getInputs().take_front(numInputs);
+  auto initTypes = funcType.getInputs().take_back(numCarries);
+  if (parser.resolveOperands(inputs, inputTypes, parser.getNameLoc(),
+                             result.operands) ||
+      parser.resolveOperands(inits, initTypes, parser.getNameLoc(),
+                             result.operands)) {
+    return failure();
+  }
+  result.addTypes(funcType.getResults());
+
+  Builder& builder = parser.getBuilder();
+  result.addAttribute(ScanOp::getDimensionAttrName(result.name),
+                      builder.getI64IntegerAttr(dimension));
+  result.addAttribute(
+      ScanOp::getOperandSegmentSizeAttr(),
+      builder.getDenseI32ArrayAttr({(int32_t)numInputs, (int32_t)numCarries}));
+  size_t numOutputs = funcType.getNumResults() - numCarries;
+  result.addAttribute(
+      ScanOp::getResultSegmentSizeAttr(),
+      builder.getDenseI32ArrayAttr({(int32_t)numOutputs, (int32_t)numCarries}));
+
+  return success();
+}
+
+void ScanOp::print(OpAsmPrinter& p) {
+  p << "(";
+  p.printOperands(getInputs());
+  p << ") inits (";
+  p.printOperands(getInits());
+  p << ") dimension=" << getDimension() << " ";
+  p.printRegion(getBody(), /*printEntryBlockArgs=*/true);
+  p.printOptionalAttrDict(getOperation()->getAttrs(),
+                          /*elidedAttrs=*/{"dimension", "operandSegmentSizes",
+                                           "resultSegmentSizes"});
+  p << " : ";
+  p.printFunctionalType(*this);
+}
+
 }  // namespace chlo
 }  // namespace mlir
 
diff --ruN a/stablehlo/stablehlo/dialect/ChloOps.td b/stablehlo/stablehlo/dialect/ChloOps.td
--- stablehlo/stablehlo/dialect/ChloOps.td
+++ stablehlo/stablehlo/dialect/ChloOps.td
@@ -31,6 +31,7 @@
 #define STABLEHLO_DIALECT_CHLO_OPS
 
 include "mlir/IR/BuiltinAttributeInterfaces.td"
+include "mlir/IR/OpAsmInterface.td"
 include "mlir/IR/OpBase.td"
 include "mlir/Interfaces/ControlFlowInterfaces.td"
 include "mlir/Interfaces/InferTypeOpInterface.td"
@@ -934,4 +935,53 @@
   }];
 }
 
+def CHLO_ScanOp : CHLO_Op<"scan", [
+      AttrSizedOperandSegments,
+      AttrSizedResultSegments,
+      InferTensorTypeWithReify,
+      IsolatedFromAbove,
+      OpAsmOpInterface,
+      RecursiveMemoryEffects,
+    ]> {
+  string summary = "Scan operation";
+
+  string description = [{
+    Applies a reduction function `body` to `inputs` and `inits` along the
+    `dimension` and produces `results` (comprising `outputs` and `carries`).
+
+    If `is_reverse` is true, the scan is performed in reverse order.
+    `is_associative` indicates whether the reduction function is associative.
+
+    See: https://www.tensorflow.org/xla/operation_semantics#scan
+
+    ScanOp currently does not have a decomposition to StableHLO.
+  }];
+
+  let arguments = (ins
+    Variadic<HLO_AnyTensor>:$inputs,
+    Variadic<HLO_AnyTensor>:$inits,
+    ConfinedAttr<I64Attr, [IntNonNegative]>:$dimension,
+    DefaultValuedOptionalAttr<BoolAttr, "false">:$is_reverse,
+    OptionalAttr<BoolAttr>:$is_associative
+  );
+
+  let results = (outs
+    Variadic<HLO_AnyTensor>:$outputs,
+    Variadic<HLO_AnyTensor>:$carries
+  );
+
+  let regions = (region SizedRegion<1>:$body);
+
+  let extraClassDeclaration = [{
+    void getAsmBlockArgumentNames(Region &region, OpAsmSetValueNameFn setNameFn) {
+      for (size_t i = 0; i < region.getNumArguments(); ++i) {
+        setNameFn(region.getArgument(i), i < getInputs().size() ? "input" : "carry");
+      }
+    }
+  }];
+
+  let hasCustomAssemblyFormat = 1;
+  let hasVerifier = 1;
+}
+
 #endif  // STABLEHLO_DIALECT_CHLO_OPS
diff --ruN a/stablehlo/stablehlo/integrations/cpp/builder/StablehloBuilder.cpp b/stablehlo/stablehlo/integrations/cpp/builder/StablehloBuilder.cpp
--- stablehlo/stablehlo/integrations/cpp/builder/StablehloBuilder.cpp
+++ stablehlo/stablehlo/integrations/cpp/builder/StablehloBuilder.cpp
@@ -18,6 +18,7 @@
 #include <cstdint>
 #include <optional>
 
+#include "llvm/ADT/SmallVectorExtras.h"
 #include "llvm/Support/ErrorHandling.h"
 #include "mlir/IR/Attributes.h"
 #include "mlir/IR/BuiltinAttributes.h"
@@ -30,6 +31,7 @@
 #include "stablehlo/dialect/TypeInference.h"
 #include "stablehlo/integrations/cpp/builder/AttrTypeBuilderUtil.h"
 #include "stablehlo/integrations/cpp/builder/MlirBuilder.h"
+#include "stablehlo/transforms/StablehloBroadcastLowering.h"
 
 namespace mlir {
 namespace stablehlo {
@@ -94,6 +96,49 @@
       value));
 }
 
+
+MlirOp IotaLike(MlirOp input, int64_t dim, Type elementType) {
+  auto inputType = mlir::cast<RankedTensorType>(input.getType());
+  if (inputType.getRank() == 0) {
+    // Need to construct 1-D iota and reshape to 0-D.
+    auto iota = stablehlo::Iota(input.getBuilder(),
+                                inputType.clone({1}, elementType), dim);
+    return stablehlo::Reshape(iota, {});
+  }
+  if (inputType.hasStaticShape()) {
+    return stablehlo::Iota(input.getBuilder(), inputType.clone(elementType),
+                           dim);
+  }
+
+  // Use input's static shape and slice to the dynamic shape.
+  auto dims = mlir::stablehlo::getDimensions(input.getValue());
+  if (mlir::failed(dims)) llvm::report_fatal_error(
+      "failed to create dynamically shaped iota op, with MLIR error: ");
+
+  mlir::SmallVector<int64_t> iotaShape = llvm::map_to_vector(
+      *dims,
+      [&](mlir::stablehlo::DimensionInfo dim_size) { return dim_size.size; });
+  auto iotaType =
+      mlir::makeTensorType(input.getContext(), iotaShape, elementType);
+  mlir::MlirOp iota = mlir::stablehlo::Iota(input.getBuilder(), iotaType, dim);
+
+  // Slice bounded dimensions to the dynamic shape.
+  for (const mlir::stablehlo::DimensionInfo& dim : *dims) {
+    if (!dim.boundOp.has_value()) continue;
+
+    auto runtime_dim_size =
+        mlir::stablehlo::GetDimensionSize(input, dim.boundOpDim);
+    iota = mlir::stablehlo::SetDimensionSize(iota, runtime_dim_size,
+                                             dim.boundOpDim);
+  }
+  return iota;
+}
+
+MlirOp IotaLike(MlirOp input, int64_t dim, ElementType elementType) {
+  auto resultElementType = getElementType(input.getContext(), elementType);
+  return IotaLike(input, dim, resultElementType);
+}
+
 namespace {
 
 // Use preferred element type, if not use LHS element type.
diff --ruN a/stablehlo/stablehlo/integrations/cpp/builder/StablehloBuilder.h b/stablehlo/stablehlo/integrations/cpp/builder/StablehloBuilder.h
--- stablehlo/stablehlo/integrations/cpp/builder/StablehloBuilder.h
+++ stablehlo/stablehlo/integrations/cpp/builder/StablehloBuilder.h
@@ -58,6 +58,12 @@
 MlirOp Constant(MlirBuilder& builder, int64_t value);
 MlirOp Constant(MlirBuilder& builder, std::vector<int64_t> value);
 
+// IotaLike is a sugar API for iota that accounts for bounded dynamism in the
+// input tensor. Eventually this should be a chlo.iota_like op with a StableHLO
+// decomposition, but for now it will be housed as a builder API.
+MlirOp IotaLike(MlirOp input, int64_t dim, ElementType elementType);
+MlirOp IotaLike(MlirOp input, int64_t dim, Type elementType);
+
 // Better Dot / DotGeneral builders.
 // These ops don't support full type inference because the result element type
 // cannot be inferred from operands, however the result shape can be.
diff --ruN a/stablehlo/stablehlo/integrations/cpp/builder/StablehloBuilderTest.cpp b/stablehlo/stablehlo/integrations/cpp/builder/StablehloBuilderTest.cpp
--- stablehlo/stablehlo/integrations/cpp/builder/StablehloBuilderTest.cpp
+++ stablehlo/stablehlo/integrations/cpp/builder/StablehloBuilderTest.cpp
@@ -199,6 +199,79 @@
         &ctx, {Precision::HIGHEST, Precision::HIGHEST});
     auto dot = stablehlo::DotGeneral(arg0, arg1, dotDimsAttr, precision);
     func::Return(fb, dot);
+  }
+
+  OwningOpRef<ModuleOp> module = mb->build();
+  EXPECT_TRUE(succeeded(mlir::verify(*module)));
+  EXPECT_EQ(expected, debugString(*module));
+}
+
+TEST(MlirBuilderTest, IotaLikeStatic) {
+  std::string expected = R"mlir(module {
+  func.func @main(%arg0: tensor<2x3xi64>) -> tensor<2x3xi64> {
+    %0 = stablehlo.iota dim = 1 : tensor<2x3xi64>
+    return %0 : tensor<2x3xi64>
+  }
+})mlir";
+  StablehloModuleBuilder mb;
+  {  // Build Main Func
+    func::FunctionBuilder fb(mb.get(), "main");
+    auto& ctx = fb.getContext();
+    auto type2x3xi64 = makeTensorType(ctx, {2, 3}, ElementType::I64);
+    auto arg0 = func::Argument(fb, type2x3xi64);
+    auto iota = stablehlo::IotaLike(arg0, 1, type2x3xi64.getElementType());
+    func::Return(fb, iota);
+  }
+
+  OwningOpRef<ModuleOp> module = mb->build();
+  EXPECT_TRUE(succeeded(mlir::verify(*module)));
+  EXPECT_EQ(expected, debugString(*module));
+}
+
+TEST(MlirBuilderTest, IotaLikeScalar) {
+  std::string expected = R"mlir(module {
+  func.func @main(%arg0: tensor<i64>) -> tensor<i64> {
+    %0 = stablehlo.iota dim = 0 : tensor<1xi64>
+    %1 = stablehlo.reshape %0 : (tensor<1xi64>) -> tensor<i64>
+    return %1 : tensor<i64>
+  }
+})mlir";
+  StablehloModuleBuilder mb;
+  {  // Build Main Func
+    func::FunctionBuilder fb(mb.get(), "main");
+    auto& ctx = fb.getContext();
+    auto typei64 = makeTensorType(ctx, {}, ElementType::I64);
+    auto arg0 = func::Argument(fb, typei64);
+    auto iota = stablehlo::IotaLike(arg0, 0, typei64.getElementType());
+    func::Return(fb, iota);
+  }
+
+  OwningOpRef<ModuleOp> module = mb->build();
+  EXPECT_TRUE(succeeded(mlir::verify(*module)));
+  EXPECT_EQ(expected, debugString(*module));
+}
+
+TEST(MlirBuilderTest, IotaLikeDynamic) {
+  std::string expected = R"mlir(module {
+  func.func @main(%arg0: tensor<2x3xi64>, %arg1: tensor<i32>) -> tensor<?x3xi64, #stablehlo.bounds<2, ?>> {
+    %0 = stablehlo.set_dimension_size %arg0, %arg1, dim = 0 : (tensor<2x3xi64>, tensor<i32>) -> tensor<?x3xi64, #stablehlo.bounds<2, ?>>
+    %1 = stablehlo.iota dim = 1 : tensor<2x3xi64>
+    %2 = stablehlo.get_dimension_size %0, dim = 0 : (tensor<?x3xi64, #stablehlo.bounds<2, ?>>) -> tensor<i32>
+    %3 = stablehlo.set_dimension_size %1, %2, dim = 0 : (tensor<2x3xi64>, tensor<i32>) -> tensor<?x3xi64, #stablehlo.bounds<2, ?>>
+    return %3 : tensor<?x3xi64, #stablehlo.bounds<2, ?>>
+  }
+})mlir";
+  StablehloModuleBuilder mb;
+  {  // Build Main Func
+    func::FunctionBuilder fb(mb.get(), "main");
+    auto& ctx = fb.getContext();
+    auto type2x3xi64 = makeTensorType(ctx, {2, 3}, ElementType::I64);
+    auto typei32 = makeTensorType(ctx, {}, ElementType::I32);
+    auto arg0 = func::Argument(fb, type2x3xi64);
+    auto arg1 = func::Argument(fb, typei32);
+    auto sds = stablehlo::SetDimensionSize(arg0, arg1, 0);
+    auto iota = stablehlo::IotaLike(sds, 1, type2x3xi64.getElementType());
+    func::Return(fb, iota);
   }
 
   OwningOpRef<ModuleOp> module = mb->build();
diff --ruN a/stablehlo/stablehlo/tests/ops_chlo.mlir b/stablehlo/stablehlo/tests/ops_chlo.mlir
--- stablehlo/stablehlo/tests/ops_chlo.mlir
+++ stablehlo/stablehlo/tests/ops_chlo.mlir
@@ -417,3 +417,90 @@
   %0 = chlo.erf_inv %arg0 : tensor<16x16xf32> -> tensor<16x16xf32>
   return
 }
+
+// -----
+
+// CHECK-LABEL: func @scan
+func.func @scan(%arg0: tensor<2x3xf32>, %arg1: tensor<3xf32>) -> tensor<2x3xf32> {
+  // CHECK: chlo.scan
+  %0, %1 = chlo.scan (%arg0) inits (%arg1) dimension = 0 {
+  ^bb0(%input0: tensor<3xf32>, %carry0: tensor<3xf32>):
+    %2 = stablehlo.add %input0, %carry0 : tensor<3xf32>
+    stablehlo.return %2, %2 : tensor<3xf32>, tensor<3xf32>
+  } : (tensor<2x3xf32>, tensor<3xf32>) -> (tensor<2x3xf32>, tensor<3xf32>)
+  func.return %0 : tensor<2x3xf32>
+}
+
+// -----
+
+// CHECK-LABEL: func @scan_variadic
+func.func @scan_variadic(%arg0: tensor<2x3xf32>, %arg1: tensor<3xf32>, %arg2: tensor<2x3xi32>, %arg3: tensor<3xi32>) -> (tensor<2x3xf32>, tensor<2x3xi32>) {
+  // CHECK: chlo.scan
+  %0:4 = chlo.scan(%arg0, %arg2) inits (%arg1, %arg3) dimension = 0 {
+  ^bb0(%arg4: tensor<3xf32>, %arg5: tensor<3xi32>, %arg6: tensor<3xf32>, %arg7: tensor<3xi32>):
+    %1 = stablehlo.add %arg4, %arg6 : tensor<3xf32>
+    %2 = stablehlo.add %arg5, %arg7 : tensor<3xi32>
+    stablehlo.return %1, %2, %1, %2 : tensor<3xf32>, tensor<3xi32>, tensor<3xf32>, tensor<3xi32>
+  } : (tensor<2x3xf32>, tensor<2x3xi32>, tensor<3xf32>, tensor<3xi32>) -> (tensor<2x3xf32>, tensor<2x3xi32>, tensor<3xf32>, tensor<3xi32>)
+  func.return %0#0, %0#1 : tensor<2x3xf32>, tensor<2x3xi32>
+}
+
+// -----
+
+func.func @scan_size_mismatch(%arg0: tensor<2x3xf32>, %arg1: tensor<3xf32>) -> tensor<2x3xf32> {
+  // expected-error @+1 {{'chlo.scan' op expects 1 arguments in the body, but got 2}}
+  %0 = chlo.scan(%arg0) inits () dimension = 0 {
+  ^bb0(%arg2: tensor<3xf32>, %arg3: tensor<3xf32>):
+    %1 = stablehlo.add %arg2, %arg3 : tensor<3xf32>
+    stablehlo.return %1 : tensor<3xf32>
+  } : (tensor<2x3xf32>) -> tensor<2x3xf32>
+  func.return %0 : tensor<2x3xf32>
+}
+
+// -----
+
+func.func @scan_element_type_mismatch(%arg0: tensor<2x3xf32>, %arg1: tensor<3xi32>) -> tensor<2x3xf32> {
+  // expected-error @+1 {{'chlo.scan' op operand and body argument 1 are incompatible}}
+  %0:2 = chlo.scan(%arg0) inits (%arg1) dimension = 0 {
+  ^bb0(%arg2: tensor<3xf32>, %arg3: tensor<3xf32>):
+    // This body is invalid given the types but checking the verifier first.
+    stablehlo.return %arg2, %arg2 : tensor<3xf32>, tensor<3xf32>
+  } : (tensor<2x3xf32>, tensor<3xi32>) -> (tensor<2x3xf32>, tensor<3xf32>)
+  func.return %0#0 : tensor<2x3xf32>
+}
+
+// -----
+
+func.func @scan_dim_out_of_bounds(%arg0: tensor<2x3xf32>, %arg1: tensor<3xf32>) -> tensor<2x3xf32> {
+  // expected-error @+1 {{'chlo.scan' op scan dimension of operand 0 is out of bounds}}
+  %0:2 = chlo.scan(%arg0) inits (%arg1) dimension = 2 {
+  ^bb0(%arg2: tensor<3xf32>, %arg3: tensor<3xf32>):
+    %1 = stablehlo.add %arg2, %arg3 : tensor<3xf32>
+    stablehlo.return %1, %1 : tensor<3xf32>, tensor<3xf32>
+  } : (tensor<2x3xf32>, tensor<3xf32>) -> (tensor<2x3xf32>, tensor<3xf32>)
+  func.return %0#0 : tensor<2x3xf32>
+}
+
+// -----
+
+func.func @scan_init_rank_mismatch(%arg0: tensor<2x3xf32>, %arg1: tensor<2x3xf32>) -> tensor<2x3xf32> {
+  // expected-error @+1 {{'chlo.scan' op operand and body argument 1 are incompatible}}
+  %0:2 = chlo.scan(%arg0) inits (%arg1) dimension = 0 {
+  ^bb0(%arg2: tensor<3xf32>, %arg3: tensor<3xf32>):
+    %1 = stablehlo.add %arg2, %arg3 : tensor<3xf32>
+    stablehlo.return %1, %1 : tensor<3xf32>, tensor<3xf32>
+  } : (tensor<2x3xf32>, tensor<2x3xf32>) -> (tensor<2x3xf32>, tensor<2x3xf32>)
+  func.return %0#0 : tensor<2x3xf32>
+}
+
+// -----
+
+func.func @scan_init_shape_mismatch(%arg0: tensor<2x3xf32>, %arg1: tensor<2xf32>) -> tensor<2x3xf32> {
+  // expected-error @+1 {{'chlo.scan' op operand and body argument 1 are incompatible}}
+  %0:2 = chlo.scan(%arg0) inits (%arg1) dimension = 0 {
+  ^bb0(%arg2: tensor<3xf32>, %arg3: tensor<3xf32>):
+    %1 = stablehlo.add %arg2, %arg3 : tensor<3xf32>
+    stablehlo.return %1, %1 : tensor<3xf32>, tensor<3xf32>
+  } : (tensor<2x3xf32>, tensor<2xf32>) -> (tensor<2x3xf32>, tensor<2xf32>)
+  func.return %0#0 : tensor<2x3xf32>
+}
diff --ruN a/stablehlo/stablehlo/tests/transforms/stablehlo_aggressive_folder.mlir b/stablehlo/stablehlo/tests/transforms/stablehlo_aggressive_folder.mlir
--- stablehlo/stablehlo/tests/transforms/stablehlo_aggressive_folder.mlir
+++ stablehlo/stablehlo/tests/transforms/stablehlo_aggressive_folder.mlir
@@ -584,6 +584,56 @@
   %1 = stablehlo.divide %cst_1, %cst_1 : tensor<ui32>
   %2 = stablehlo.divide %cst_2, %cst_2 : tensor<f32>
   return %0, %1, %2 : tensor<i32>, tensor<ui32>, tensor<f32>
+}
+
+// CHECK-LABEL: @div_fold_cst_zero_nan
+func.func @div_fold_cst_zero_nan() -> (tensor<f32>) {
+  %cst = stablehlo.constant dense<3.000000e+00> : tensor<f32>
+  %cst_0 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
+  %0 = stablehlo.divide %cst, %cst_0 : tensor<f32>
+  // CHECK: stablehlo.constant dense<0x7F800000> : tensor<f32>
+  // CHECK-NOT: stablehlo.divide
+  return %0 : tensor<f32>
+}
+
+// CHECK-LABEL: @div_fold_cst_nan
+func.func @div_fold_cst_nan() -> (tensor<f32>) {
+  %cst = stablehlo.constant dense<3.000000e+00> : tensor<f32>
+  %cst_0 = stablehlo.constant dense<0x7FC00000> : tensor<f32>
+  %0 = stablehlo.divide %cst, %cst_0 : tensor<f32>
+  // CHECK: stablehlo.constant dense<0x7FC00000> : tensor<f32>
+  // CHECK-NOT: stablehlo.divide
+  return %0 : tensor<f32>
+}
+
+// -----
+
+////////
+// MaximumOp
+
+// CHECK-LABEL: @max_fold_cst_nan
+func.func @max_fold_cst_nan() -> (tensor<f32>) {
+  %cst = stablehlo.constant dense<3.000000e+00> : tensor<f32>
+  %cst_0 = stablehlo.constant dense<0x7FC00000> : tensor<f32>
+  %0 = stablehlo.maximum %cst, %cst_0 : tensor<f32>
+  // CHECK: stablehlo.constant dense<0x7FC00000> : tensor<f32>
+  // CHECK-NOT: stablehlo.maximum
+  return %0 : tensor<f32>
+}
+
+// -----
+
+////////
+// MinimumOp
+
+// CHECK-LABEL: @min_fold_cst_nan
+func.func @min_fold_cst_nan() -> (tensor<f32>) {
+  %cst = stablehlo.constant dense<3.000000e+00> : tensor<f32>
+  %cst_0 = stablehlo.constant dense<0x7FC00000> : tensor<f32>
+  %0 = stablehlo.minimum %cst, %cst_0 : tensor<f32>
+  // CHECK: stablehlo.constant dense<0x7FC00000> : tensor<f32>
+  // CHECK-NOT: stablehlo.minimum
+  return %0 : tensor<f32>
 }
 
 // -----
diff --ruN a/stablehlo/stablehlo/transforms/optimization/StablehloAggressiveFolder.cpp b/stablehlo/stablehlo/transforms/optimization/StablehloAggressiveFolder.cpp
--- stablehlo/stablehlo/transforms/optimization/StablehloAggressiveFolder.cpp
+++ stablehlo/stablehlo/transforms/optimization/StablehloAggressiveFolder.cpp
@@ -1058,14 +1058,14 @@
   std::function<APInt(APInt, APInt)> foldIntFn;
 
   APFloat operator()(APFloat lhs, APFloat rhs) {
-    return lhs >= rhs ? lhs : rhs;
+    return llvm::maximum(lhs, rhs);
   }
   APInt operator()(APInt lhs, APInt rhs) { return foldIntFn(lhs, rhs); }
   static APInt foldUint(APInt lhs, APInt rhs) {
-    return lhs.uge(rhs) ? lhs : rhs;
+    return llvm::APIntOps::umax(lhs, rhs);
   }
   static APInt foldSint(APInt lhs, APInt rhs) {
-    return lhs.sge(rhs) ? lhs : rhs;
+    return llvm::APIntOps::smax(lhs, rhs);
   }
 };
 
@@ -1075,14 +1075,14 @@
   std::function<APInt(APInt, APInt)> foldIntFn;
 
   APFloat operator()(APFloat lhs, APFloat rhs) {
-    return lhs <= rhs ? lhs : rhs;
+    return llvm::minimum(lhs, rhs);
   }
   APInt operator()(APInt lhs, APInt rhs) { return foldIntFn(lhs, rhs); }
   static APInt foldUint(APInt lhs, APInt rhs) {
-    return lhs.ule(rhs) ? lhs : rhs;
+    return llvm::APIntOps::umin(lhs, rhs);
   }
   static APInt foldSint(APInt lhs, APInt rhs) {
-    return lhs.sle(rhs) ? lhs : rhs;
+    return llvm::APIntOps::smin(lhs, rhs);
   }
 };
 
@@ -1533,7 +1533,9 @@
   using FoldUnaryOpPattern::FoldUnaryOpPattern;
 
   static std::optional<APInt> EvaluateOp(APInt operand) { return -operand; }
-  static std::optional<APFloat> EvaluateOp(APFloat operand) { return -operand; }
+  static std::optional<APFloat> EvaluateOp(APFloat operand) {
+    return llvm::neg(operand);
+  }
 };
 
 struct FoldNotOpPattern : public FoldUnaryOpPattern<FoldNotOpPattern, NotOp> {

