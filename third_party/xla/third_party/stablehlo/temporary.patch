diff --ruN a/stablehlo/stablehlo/conversions/linalg/tests/pointwise.mlir b/stablehlo/stablehlo/conversions/linalg/tests/pointwise.mlir
--- stablehlo/stablehlo/conversions/linalg/tests/pointwise.mlir
+++ stablehlo/stablehlo/conversions/linalg/tests/pointwise.mlir
@@ -1,5 +1,6 @@
 // RUN: stablehlo-opt %s --stablehlo-legalize-to-linalg --split-input-file --canonicalize | FileCheck %s
 // RUN: stablehlo-opt %s --stablehlo-legalize-to-linalg="enable-primitive-ops=true" --split-input-file --canonicalize | FileCheck %s --check-prefix=CHECK-PRIMITIVE
+// RUN: stablehlo-opt %s --stablehlo-legalize-to-linalg="capture-scalar-inputs=false" --split-input-file --canonicalize | FileCheck %s --check-prefix=CHECK-NO-CAPTURE
 
 // CHECK: #map = affine_map<(d0, d1) -> (d0, d1)>
 // CHECK-LABEL: func @float_add
@@ -534,6 +535,19 @@
   %0 = "stablehlo.sign"(%arg0) : (tensor<2x2xcomplex<f32>>)
                           -> tensor<2x2xcomplex<f32>>
   func.return %0 : tensor<2x2xcomplex<f32>>
+}
+
+// -----
+
+// CHECK-LABEL: func @float_tan
+// CHECK-PRIMITIVE-LABEL: func @float_tan
+func.func @float_tan(%arg0: tensor<2x2xf32>) -> tensor<2x2xf32> {
+  // CHECK: linalg.generic
+  // CHECK: tan
+  // CHECK-PRIMITIVE: linalg.map
+  // CHECK-PRIMITIVE: tan
+  %0 = "stablehlo.tan"(%arg0) : (tensor<2x2xf32>) -> tensor<2x2xf32>
+  func.return %0 : tensor<2x2xf32>
 }
 
 // -----
@@ -926,6 +940,23 @@
 // CHECK-PRIMITIVE:      (%[[LHS_:.*]]: f32, %[[RHS_:.*]]: f32) {
 // CHECK-PRIMITIVE:        %[[RES:.*]] = arith.select %[[PRED_ELEM]], %[[LHS_]], %[[RHS_]] : f32
 // CHECK-PRIMITIVE:        linalg.yield %[[RES]]
+
+// CHECK-NO-CAPTURE:      #[[SCALAR_MAP:.*]] = affine_map<(d0, d1) -> ()>
+// CHECK-NO-CAPTURE:      #[[ID_MAP:.*]] = affine_map<(d0, d1) -> (d0, d1)>
+// CHECK-NO-CAPTURE:      func @select_scalar_pred_dyn
+// CHECK-NO-CAPTURE-SAME:  (%[[PRED:.*]]: tensor<i1>, %[[LHS:.*]]: tensor<2x?xf32>, %[[RHS:.*]]: tensor<2x?xf32>)
+// CHECK-NO-CAPTURE-DAG:  %[[C1:.*]] = arith.constant 1
+// CHECK-NO-CAPTURE-DAG:  %[[DIM:.*]] =  tensor.dim %[[LHS]], %[[C1]]
+// CHECK-NO-CAPTURE-DAG:  %[[DST:.*]] = tensor.empty(%[[DIM]])
+// CHECK-NO-CAPTURE:      linalg.generic
+// CHECK-NO-CAPTURE-SAME:   indexing_maps = [#[[SCALAR_MAP]], #[[ID_MAP]], #[[ID_MAP]], #[[ID_MAP]]]
+// CHECK-NO-CAPTURE-SAME:   iterator_types = ["parallel", "parallel"]
+// CHECK-NO-CAPTURE-SAME:   ins(%[[PRED]], %[[LHS]], %[[RHS]] : tensor<i1>, tensor<2x?xf32>, tensor<2x?xf32>)
+// CHECK-NO-CAPTURE-SAME:   outs(%[[DST]] : tensor<2x?xf32>)
+// CHECK-NO-CAPTURE-SAME:   {someattr}
+// CHECK-NO-CAPTURE:      ^bb0(%[[PRED_:.*]]: i1, %[[LHS_:.*]]: f32, %[[RHS_:.*]]: f32, %{{.*}}: f32):
+// CHECK-NO-CAPTURE:        %[[RES:.*]] = arith.select %[[PRED_]], %[[LHS_]], %[[RHS_]] : f32
+// CHECK-NO-CAPTURE:        linalg.yield %[[RES]]
 
 // -----
 
diff --ruN a/stablehlo/stablehlo/conversions/linalg/transforms/LegalizeToLinalgUtils.cpp b/stablehlo/stablehlo/conversions/linalg/transforms/LegalizeToLinalgUtils.cpp
--- stablehlo/stablehlo/conversions/linalg/transforms/LegalizeToLinalgUtils.cpp
+++ stablehlo/stablehlo/conversions/linalg/transforms/LegalizeToLinalgUtils.cpp
@@ -140,12 +140,11 @@
   // (any sign-op, or an integral abs-op).
   // TODO(peiming, ajcbik): these all can potentially be optimized by applying
   // value transform on sparse_tenosr.value memref
-  if (isa<mlir::stablehlo::SignOp>(op) || isa<mlir::stablehlo::NegOp>(op) ||
+  if (isa<mlir::stablehlo::SignOp, mlir::stablehlo::NegOp,
+          mlir::stablehlo::TanOp>(op) ||
       (isa<mlir::stablehlo::AbsOp>(op) && hasIntegralShapeType(op)) ||
-      isa<chlo::AsinOp>(op) || isa<chlo::AsinhOp>(op) ||
-      isa<chlo::AtanOp>(op) || isa<chlo::AtanhOp>(op) ||
-      isa<chlo::BesselI1eOp>(op) || isa<chlo::SinhOp>(op) ||
-      isa<chlo::TanOp>(op)) {
+      isa<chlo::AsinOp, chlo::AsinhOp, chlo::AtanOp, chlo::AtanhOp,
+          chlo::BesselI1eOp, chlo::SinhOp, chlo::TanOp>(op)) {
     if (!sparse_tensor::getSparseTensorEncoding(op->getResult(0).getType()) &&
         !sparse_tensor::getSparseTensorEncoding(op->getOperand(0).getType()))
       return Value();
diff --ruN a/stablehlo/stablehlo/conversions/linalg/transforms/MapStablehloToScalarOp.h b/stablehlo/stablehlo/conversions/linalg/transforms/MapStablehloToScalarOp.h
--- stablehlo/stablehlo/conversions/linalg/transforms/MapStablehloToScalarOp.h
+++ stablehlo/stablehlo/conversions/linalg/transforms/MapStablehloToScalarOp.h
@@ -153,14 +153,11 @@
   using FOp = ::mlir::math::SinOp;
   using COp = ::mlir::complex::SinOp;
 };
-// FIXME(Jakub)
-/*
 template <>
 struct StablehloToScalarOp<stablehlo::TanOp> {
   using FOp = ::mlir::math::TanOp;
   using COp = ::mlir::complex::TanOp;
 };
-*/
 template <>
 struct StablehloToScalarOp<stablehlo::Atan2Op> {
   using FOp = ::mlir::math::Atan2Op;
diff --ruN a/stablehlo/stablehlo/conversions/linalg/transforms/Passes.td b/stablehlo/stablehlo/conversions/linalg/transforms/Passes.td
--- stablehlo/stablehlo/conversions/linalg/transforms/Passes.td
+++ stablehlo/stablehlo/conversions/linalg/transforms/Passes.td
@@ -39,7 +39,11 @@
                  Option<"enableSparseOps", "enable-sparse-ops", "bool",
                         /*default=*/"false",
                         "Lower to Sparse Tensor ops (sparse_tensor.concatenate)"
-                        "when possible, instead of linalg.generic">];
+                        "when possible, instead of linalg.generic">,
+                 Option<"captureScalarInputs", "capture-scalar-inputs", "bool",
+                        /*default=*/"true",
+                        "Capture scalar inputs in generic ops instead of"
+                        "passing as tensor-scalar argument.">];
 }
 
 #endif  // STABLEHLO_TO_LINALG_PASSES
diff --ruN a/stablehlo/stablehlo/conversions/linalg/transforms/Rewriters.h b/stablehlo/stablehlo/conversions/linalg/transforms/Rewriters.h
--- stablehlo/stablehlo/conversions/linalg/transforms/Rewriters.h
+++ stablehlo/stablehlo/conversions/linalg/transforms/Rewriters.h
@@ -26,11 +26,12 @@
 //===----------------------------------------------------------------------===//
 
 /// Populates the patterns that convert from StableHLO to Linalg on tensors.
-void populateStablehloToLinalgConversionPatterns(MLIRContext *context,
-                                                 TypeConverter &typeConverter,
-                                                 RewritePatternSet *patterns,
+void populateStablehloToLinalgConversionPatterns(MLIRContext* context,
+                                                 TypeConverter& typeConverter,
+                                                 RewritePatternSet* patterns,
                                                  bool enablePrimitiveOps,
-                                                 bool enableSparseOps);
+                                                 bool enableSparseOps,
+                                                 bool captureScalarInputs);
 
 //===----------------------------------------------------------------------===//
 // Fine-grained patterns used by the implementation.
@@ -39,8 +40,9 @@
 /// Populates the patterns that convert from elementwise StableHLO ops to Linalg
 /// on tensors.
 void populatePointwiseStablehloToLinalgConversionPatterns(
-    MLIRContext *context, TypeConverter &typeConverter,
-    RewritePatternSet *patterns, bool enablePrimitiveOps);
+    MLIRContext* context, TypeConverter& typeConverter,
+    RewritePatternSet* patterns, bool enablePrimitiveOps,
+    bool captureScalarInputs);
 
 /// Populates the patterns that convert from convolution StableHLO ops to Linalg
 /// on tensors.
diff --ruN a/stablehlo/stablehlo/conversions/linalg/transforms/StablehloLegalizeToLinalg.cpp b/stablehlo/stablehlo/conversions/linalg/transforms/StablehloLegalizeToLinalg.cpp
--- stablehlo/stablehlo/conversions/linalg/transforms/StablehloLegalizeToLinalg.cpp
+++ stablehlo/stablehlo/conversions/linalg/transforms/StablehloLegalizeToLinalg.cpp
@@ -2634,7 +2634,8 @@
 
     RewritePatternSet patterns_(context);
     populateStablehloToLinalgConversionPatterns(
-        context, converter, &patterns_, enablePrimitiveOps, enableSparseOps);
+        context, converter, &patterns_, enablePrimitiveOps, enableSparseOps,
+        captureScalarInputs);
     patterns = std::move(patterns_);
 
     return success();
@@ -2657,7 +2658,8 @@
                                                  TypeConverter& typeConverter,
                                                  RewritePatternSet* patterns,
                                                  bool enablePrimitiveOps,
-                                                 bool enableSparseOps) {
+                                                 bool enableSparseOps,
+                                                 bool captureScalarInputs) {
   // clang-format off
   patterns->add<ConcatenateConverter>(typeConverter, context,
                                       enablePrimitiveOps);
@@ -2680,7 +2682,8 @@
       >(typeConverter, context);
 
   detail::populatePointwiseStablehloToLinalgConversionPatterns(
-      context, typeConverter, patterns, enablePrimitiveOps);
+      context, typeConverter, patterns, enablePrimitiveOps,
+      captureScalarInputs);
 
   if (enableSparseOps) {
     patterns->add<SparseConcatenateConverter>(typeConverter, context);
diff --ruN a/stablehlo/stablehlo/conversions/linalg/transforms/StablehloToArith.cpp b/stablehlo/stablehlo/conversions/linalg/transforms/StablehloToArith.cpp
--- stablehlo/stablehlo/conversions/linalg/transforms/StablehloToArith.cpp
+++ stablehlo/stablehlo/conversions/linalg/transforms/StablehloToArith.cpp
@@ -145,6 +145,7 @@
       ScalarHloToArithmeticPattern<mlir::stablehlo::SineOp>,
       ScalarHloToArithmeticPattern<mlir::stablehlo::SqrtOp>,
       ScalarHloToArithmeticPattern<mlir::stablehlo::SubtractOp>,
+      ScalarHloToArithmeticPattern<mlir::stablehlo::TanOp>,
       ScalarHloToArithmeticPattern<mlir::stablehlo::TanhOp>,
       ScalarHloToArithmeticPattern<mlir::stablehlo::XorOp>>(typeConverter,
                                                             context, filterFn);
diff --ruN a/stablehlo/stablehlo/conversions/linalg/transforms/StablehloToLinalgPointwise.cpp b/stablehlo/stablehlo/conversions/linalg/transforms/StablehloToLinalgPointwise.cpp
--- stablehlo/stablehlo/conversions/linalg/transforms/StablehloToLinalgPointwise.cpp
+++ stablehlo/stablehlo/conversions/linalg/transforms/StablehloToLinalgPointwise.cpp
@@ -23,6 +23,7 @@
 
 #include "llvm/ADT/STLExtras.h"
 #include "llvm/ADT/SmallVector.h"
+#include "llvm/Support/Debug.h"
 #include "mlir/Dialect/Linalg/IR/Linalg.h"
 #include "mlir/Dialect/Tensor/IR/Tensor.h"
 #include "mlir/IR/AffineMap.h"
@@ -43,6 +44,8 @@
 #include "stablehlo/conversions/linalg/transforms/Rewriters.h"
 #include "stablehlo/dialect/StablehloOps.h"
 
+#define DEBUG_TYPE "stablehlo-conversions"
+
 namespace mlir::stablehlo {
 namespace {
 int64_t getRank(Value v) { return cast<ShapedType>(v.getType()).getRank(); }
@@ -142,6 +145,11 @@
 struct PointwiseToLinalgMapConverter : OpConversionPattern<OpTy> {
   using OpConversionPattern<OpTy>::OpConversionPattern;
   using OpAdaptor = typename OpTy::Adaptor;
+
+  PointwiseToLinalgMapConverter(TypeConverter& typeConverter,
+                                MLIRContext* context, bool captureScalarInputs)
+      : OpConversionPattern<OpTy>(typeConverter, context),
+        captureScalarInputs(captureScalarInputs) {}
 
   virtual FailureOr<Operation *> createLinalgOp(
       OpTy &op, ConversionPatternRewriter &rewriter,
@@ -190,8 +198,11 @@
             rewriter, loc, cast<TypedValue<ShapedType>>(input),
             cast<ShapedType>(emptyTensor.getType())));
         scalarInputs.push_back(nullptr);
+      } else if (captureScalarInputs) {
+        scalarInputs.push_back(rewriter.create<tensor::ExtractOp>(loc, input));
       } else {
-        scalarInputs.push_back(rewriter.create<tensor::ExtractOp>(loc, input));
+        mappedInputs.push_back(input);
+        scalarInputs.push_back(nullptr);
       }
     }
 
@@ -202,6 +213,8 @@
     rewriter.replaceOp(op, (*mapOp)->getResults());
     return success();
   }
+
+  bool captureScalarInputs;
 };
 
 /// Converts a HLO operation to a linalg.generic op that contains the
@@ -211,12 +224,12 @@
   using PointwiseToLinalgMapConverter<OpTy>::PointwiseToLinalgMapConverter;
   using OpAdaptor = typename OpTy::Adaptor;
 
-  FailureOr<Operation *> createLinalgOp(OpTy &op,
-                                        ConversionPatternRewriter &rewriter,
-                                        ArrayRef<Value> mappedInputs,
-                                        ArrayRef<Value> scalarVals,
-                                        Value emptyTensor,
-                                        int64_t maxRank) const override {
+  FailureOr<Operation*> createLinalgOp(OpTy& op,
+                                       ConversionPatternRewriter& rewriter,
+                                       ArrayRef<Value> mappedInputs,
+                                       ArrayRef<Value> scalarVals,
+                                       Value emptyTensor,
+                                       int64_t maxRank) const override {
     // Create indexing maps.
     AffineMap scalarMap = AffineMap::get(maxRank, 0, rewriter.getContext());
     AffineMap idMap = rewriter.getMultiDimIdentityMap(maxRank);
@@ -225,10 +238,10 @@
       maps.push_back(isScalar(v) ? scalarMap : idMap);
     maps.push_back(idMap);
     bool failed = false;
-    Operation *linalgOp = rewriter.create<linalg::GenericOp>(
+    Operation* linalgOp = rewriter.create<linalg::GenericOp>(
         op.getLoc(), emptyTensor.getType(), mappedInputs, emptyTensor, maps,
         getNParallelLoopsAttrs(maxRank),
-        [&](OpBuilder &nestedBuilder, Location /*nested_loc*/,
+        [&](OpBuilder& nestedBuilder, Location /*nested_loc*/,
             ValueRange args) {
           Type innerResultTy = getElementTypeOrSelf(emptyTensor);
           auto argvec =
@@ -253,8 +266,9 @@
 
 namespace detail {
 void populatePointwiseStablehloToLinalgConversionPatterns(
-    MLIRContext *context, TypeConverter &typeConverter,
-    RewritePatternSet *patterns, bool enablePrimitiveOps) {
+    MLIRContext* context, TypeConverter& typeConverter,
+    RewritePatternSet* patterns, bool enablePrimitiveOps,
+    bool captureScalarInputs) {
   if (enablePrimitiveOps) {
     patterns->add<
         PointwiseToLinalgMapConverter<mlir::stablehlo::AbsOp>,
@@ -301,12 +315,12 @@
         PointwiseToLinalgMapConverter<mlir::stablehlo::SineOp>,
         PointwiseToLinalgMapConverter<mlir::stablehlo::SqrtOp>,
         PointwiseToLinalgMapConverter<mlir::stablehlo::SubtractOp>,
+        PointwiseToLinalgMapConverter<mlir::stablehlo::TanOp>,
         PointwiseToLinalgMapConverter<mlir::stablehlo::TanhOp>,
-        PointwiseToLinalgMapConverter<mlir::stablehlo::XorOp>>(typeConverter,
-                                                               context);
+        PointwiseToLinalgMapConverter<mlir::stablehlo::XorOp>>(
+        typeConverter, context, captureScalarInputs);
     return;
   }
-
   patterns
       ->add<PointwiseToLinalgConverter<mlir::stablehlo::AbsOp>,
             PointwiseToLinalgConverter<mlir::stablehlo::AddOp>,
@@ -352,9 +366,10 @@
             PointwiseToLinalgConverter<mlir::stablehlo::SineOp>,
             PointwiseToLinalgConverter<mlir::stablehlo::SqrtOp>,
             PointwiseToLinalgConverter<mlir::stablehlo::SubtractOp>,
+            PointwiseToLinalgConverter<mlir::stablehlo::TanOp>,
             PointwiseToLinalgConverter<mlir::stablehlo::TanhOp>,
-            PointwiseToLinalgConverter<mlir::stablehlo::XorOp>>(typeConverter,
-                                                                context);
+            PointwiseToLinalgConverter<mlir::stablehlo::XorOp>>(
+          typeConverter, context, captureScalarInputs);
 }
 }  // namespace detail
 }  // namespace mlir::stablehlo
diff --ruN a/stablehlo/stablehlo/conversions/tosa/transforms/StablehloQuantLegalizeToTosaRescale.cpp b/stablehlo/stablehlo/conversions/tosa/transforms/StablehloQuantLegalizeToTosaRescale.cpp
--- stablehlo/stablehlo/conversions/tosa/transforms/StablehloQuantLegalizeToTosaRescale.cpp
+++ stablehlo/stablehlo/conversions/tosa/transforms/StablehloQuantLegalizeToTosaRescale.cpp
@@ -40,7 +40,7 @@
 
 namespace {
 
-Value buildRescaleMultiplier(bool scale32, OpBuilder& builder, Location loc,
+Value buildRescaleMultiplier(bool scale32, OpBuilder &builder, Location loc,
                              ArrayRef<int32_t> multipliers) {
   if (scale32) {
     return tosa::getConstTensorInt<int32_t>(builder, loc, multipliers);
@@ -51,7 +51,7 @@
 }
 
 // create a tosa rescale op and return its result value
-Value buildRescale(PatternRewriter& rewriter, Location loc,
+Value buildRescale(PatternRewriter &rewriter, Location loc,
                    ShapedType outputType, Value inputVal, int32_t multiplier,
                    int32_t shift, int64_t inputZp, int64_t outputZp,
                    bool doubleRound, bool scale32, bool perChannel) {
@@ -85,7 +85,7 @@
 }
 
 // Creates TOSA rescale op with int32 output
-Value buildRescaleToInt32(PatternRewriter& rewriter, Location loc,
+Value buildRescaleToInt32(PatternRewriter &rewriter, Location loc,
                           Value inputVal, double inputScale, int64_t inputZp) {
   auto inputType = cast<ShapedType>(inputVal.getType());
   auto outputType = inputType.clone(rewriter.getI32Type());
@@ -103,7 +103,7 @@
 }
 
 // Creates TOSA rescale op with int32 input
-Value buildRescaleFromInt32(PatternRewriter& rewriter, Location loc,
+Value buildRescaleFromInt32(PatternRewriter &rewriter, Location loc,
                             ShapedType outputType, Value inputVal,
                             double outputScale, int64_t outputZp) {
   // Input should be int32 type
@@ -124,14 +124,14 @@
 }
 
 using UnaryRescaleScalesFn =
-    void (*)(const quant::UniformQuantizedType& operandQType,
-             const quant::UniformQuantizedType& resultQType,
-             double& operandRescaleScale, double& resultRescaleScale);
-
-void GetUnaryRescaleScales(const quant::UniformQuantizedType& operandQType,
-                           const quant::UniformQuantizedType& resultQType,
-                           double& operandRescaleScale,
-                           double& resultRescaleScale) {
+    void (*)(const quant::UniformQuantizedType &operandQType,
+             const quant::UniformQuantizedType &resultQType,
+             double &operandRescaleScale, double &resultRescaleScale);
+
+void GetUnaryRescaleScales(const quant::UniformQuantizedType &operandQType,
+                           const quant::UniformQuantizedType &resultQType,
+                           double &operandRescaleScale,
+                           double &resultRescaleScale) {
   double operandScale = operandQType.getScale();
   double resultScale = resultQType.getScale();
 
@@ -145,7 +145,7 @@
 
 template <typename StablehloOp>
 LogicalResult matchAndRewriteUnaryOp(
-    StablehloOp op, PatternRewriter& rewriter,
+    StablehloOp op, PatternRewriter &rewriter,
     UnaryRescaleScalesFn rescaleScalesFn = GetUnaryRescaleScales) {
   Value operand = op.getOperand();
   Value result = op.getResult();
@@ -190,21 +190,21 @@
 }
 
 LogicalResult matchAndRewriteOp(stablehlo::AbsOp op,
-                                PatternRewriter& rewriter) {
+                                PatternRewriter &rewriter) {
   return matchAndRewriteUnaryOp(op, rewriter);
 }
 
 using BinaryRescaleScalesFn = void (*)(
-    const quant::UniformQuantizedType& lhsQType,
-    const quant::UniformQuantizedType& rhsQType,
-    const quant::UniformQuantizedType& resultQType, double& lhsRescaleScale,
-    double& rhsRescaleScale, double& resultRescaleScale);
-
-void GetAddSubRescaleScales(const quant::UniformQuantizedType& lhsQType,
-                            const quant::UniformQuantizedType& rhsQType,
-                            const quant::UniformQuantizedType& resultQType,
-                            double& lhsRescaleScale, double& rhsRescaleScale,
-                            double& resultRescaleScale) {
+    const quant::UniformQuantizedType &lhsQType,
+    const quant::UniformQuantizedType &rhsQType,
+    const quant::UniformQuantizedType &resultQType, double &lhsRescaleScale,
+    double &rhsRescaleScale, double &resultRescaleScale);
+
+void GetAddSubRescaleScales(const quant::UniformQuantizedType &lhsQType,
+                            const quant::UniformQuantizedType &rhsQType,
+                            const quant::UniformQuantizedType &resultQType,
+                            double &lhsRescaleScale, double &rhsRescaleScale,
+                            double &resultRescaleScale) {
   // 1. Rescale inputs to scale = 2.0 x max(lhs.scale, rhs.scale)
   // 2. Extra left shift to input to increase precision
   // Where input_shift = 20 if input is 8-bit
@@ -230,11 +230,11 @@
       maxScale2x / (resultScale * static_cast<double>(1 << inputShift));
 }
 
-void GetMulDivRescaleScales(const quant::UniformQuantizedType& lhsQType,
-                            const quant::UniformQuantizedType& rhsQType,
-                            const quant::UniformQuantizedType& resultQType,
-                            double& lhsRescaleScale, double& rhsRescaleScale,
-                            double& resultRescaleScale) {
+void GetMulDivRescaleScales(const quant::UniformQuantizedType &lhsQType,
+                            const quant::UniformQuantizedType &rhsQType,
+                            const quant::UniformQuantizedType &resultQType,
+                            double &lhsRescaleScale, double &rhsRescaleScale,
+                            double &resultRescaleScale) {
   double lhsScale = lhsQType.getScale();
   double rhsScale = rhsQType.getScale();
   double resultScale = resultQType.getScale();
@@ -248,11 +248,11 @@
   resultRescaleScale = lhsScale * rhsScale / resultScale;
 }
 
-void GetMinMaxRescaleScales(const quant::UniformQuantizedType& lhsQType,
-                            const quant::UniformQuantizedType& rhsQType,
-                            const quant::UniformQuantizedType& resultQType,
-                            double& lhsRescaleScale, double& rhsRescaleScale,
-                            double& resultRescaleScale) {
+void GetMinMaxRescaleScales(const quant::UniformQuantizedType &lhsQType,
+                            const quant::UniformQuantizedType &rhsQType,
+                            const quant::UniformQuantizedType &resultQType,
+                            double &lhsRescaleScale, double &rhsRescaleScale,
+                            double &resultRescaleScale) {
   // 1. Rescale inputs to scale = max(lhs.scale, rhs.scale)
   // 2. Extra left shift to input to increase precision
   // Where input_shift = 20 if input is 8-bit
@@ -280,7 +280,7 @@
 }
 
 template <typename StablehloOp>
-LogicalResult matchAndRewriteBinaryOp(StablehloOp op, PatternRewriter& rewriter,
+LogicalResult matchAndRewriteBinaryOp(StablehloOp op, PatternRewriter &rewriter,
                                       BinaryRescaleScalesFn rescaleScalesFn) {
   Value lhs = op.getLhs();
   Value rhs = op.getRhs();
@@ -339,37 +339,37 @@
 }
 
 LogicalResult matchAndRewriteOp(stablehlo::AddOp op,
-                                PatternRewriter& rewriter) {
+                                PatternRewriter &rewriter) {
   return matchAndRewriteBinaryOp(op, rewriter, GetAddSubRescaleScales);
 }
 
 LogicalResult matchAndRewriteOp(stablehlo::SubtractOp op,
-                                PatternRewriter& rewriter) {
+                                PatternRewriter &rewriter) {
   return matchAndRewriteBinaryOp(op, rewriter, GetAddSubRescaleScales);
 }
 
 LogicalResult matchAndRewriteOp(stablehlo::MulOp op,
-                                PatternRewriter& rewriter) {
+                                PatternRewriter &rewriter) {
   return matchAndRewriteBinaryOp(op, rewriter, GetMulDivRescaleScales);
 }
 
 LogicalResult matchAndRewriteOp(stablehlo::DivOp op,
-                                PatternRewriter& rewriter) {
+                                PatternRewriter &rewriter) {
   return matchAndRewriteBinaryOp(op, rewriter, GetMulDivRescaleScales);
 }
 
 LogicalResult matchAndRewriteOp(stablehlo::MinOp op,
-                                PatternRewriter& rewriter) {
+                                PatternRewriter &rewriter) {
   return matchAndRewriteBinaryOp(op, rewriter, GetMinMaxRescaleScales);
 }
 
 LogicalResult matchAndRewriteOp(stablehlo::MaxOp op,
-                                PatternRewriter& rewriter) {
+                                PatternRewriter &rewriter) {
   return matchAndRewriteBinaryOp(op, rewriter, GetMinMaxRescaleScales);
 }
 
 LogicalResult matchAndRewriteCompareOp(stablehlo::CompareOp op,
-                                       PatternRewriter& rewriter) {
+                                       PatternRewriter &rewriter) {
   Value lhs = op.getLhs();
   Value rhs = op.getRhs();
   Value result = op.getResult();
@@ -429,7 +429,7 @@
 }
 
 LogicalResult matchAndRewriteOp(stablehlo::CompareOp op,
-                                PatternRewriter& rewriter) {
+                                PatternRewriter &rewriter) {
   return matchAndRewriteCompareOp(op, rewriter);
 }
 
@@ -438,7 +438,7 @@
     : public OpRewritePattern<StablehloOpType> {
   using OpRewritePattern<StablehloOpType>::OpRewritePattern;
   LogicalResult matchAndRewrite(StablehloOpType op,
-                                PatternRewriter& rewriter) const override {
+                                PatternRewriter &rewriter) const override {
     return matchAndRewriteOp(op, rewriter);
   }
 };
@@ -446,7 +446,7 @@
 struct StablehloQuantLegalizeToTosaRescalePass
     : impl::StablehloQuantLegalizeToTosaRescalePassBase<
           StablehloQuantLegalizeToTosaRescalePass> {
-  LogicalResult initialize(MLIRContext* ctx) override {
+  LogicalResult initialize(MLIRContext *ctx) override {
     RewritePatternSet patternList(ctx);
     populateStablehloQuantLegalizeToTosaRescalePatterns(&patternList, ctx);
     patterns = std::move(patternList);
@@ -468,7 +468,7 @@
 }  // namespace
 
 void populateStablehloQuantLegalizeToTosaRescalePatterns(
-    RewritePatternSet* patterns, MLIRContext* context) {
+    RewritePatternSet *patterns, MLIRContext *context) {
   // unary ops
   patterns->addWithLabel<QuantizedStablehloOpConversion<stablehlo::AbsOp>>(
       {"StablehloQuantAbsOp"}, context);
diff --ruN a/stablehlo/stablehlo/integrations/cpp/builder/AttrTypeBuilderUtilTest.cpp b/stablehlo/stablehlo/integrations/cpp/builder/AttrTypeBuilderUtilTest.cpp
--- stablehlo/stablehlo/integrations/cpp/builder/AttrTypeBuilderUtilTest.cpp
+++ stablehlo/stablehlo/integrations/cpp/builder/AttrTypeBuilderUtilTest.cpp
@@ -20,7 +20,7 @@
 #include <utility>
 #include <vector>
 
-#include "gtest/gtest.h"
+#include "testing/base/public/gunit.h"
 #include "llvm/ADT/DenseMap.h"
 #include "mlir/IR/BuiltinTypeInterfaces.h"
 #include "mlir/IR/BuiltinTypes.h"
diff --ruN a/stablehlo/stablehlo/integrations/cpp/builder/MlirBuilderTest.cpp b/stablehlo/stablehlo/integrations/cpp/builder/MlirBuilderTest.cpp
--- stablehlo/stablehlo/integrations/cpp/builder/MlirBuilderTest.cpp
+++ stablehlo/stablehlo/integrations/cpp/builder/MlirBuilderTest.cpp
@@ -15,7 +15,7 @@
 
 #include <string>
 
-#include "gtest/gtest.h"
+#include "testing/base/public/gunit.h"
 #include "llvm/Support/raw_ostream.h"
 #include "mlir/Dialect/Func/IR/FuncOps.h"
 #include "mlir/IR/BuiltinOps.h"
diff --ruN a/stablehlo/stablehlo/integrations/cpp/builder/StablehloBuilderTest.cpp b/stablehlo/stablehlo/integrations/cpp/builder/StablehloBuilderTest.cpp
--- stablehlo/stablehlo/integrations/cpp/builder/StablehloBuilderTest.cpp
+++ stablehlo/stablehlo/integrations/cpp/builder/StablehloBuilderTest.cpp
@@ -17,7 +17,7 @@
 #include <cstdint>
 #include <string>
 
-#include "gtest/gtest.h"
+#include "testing/base/public/gunit.h"
 #include "mlir/IR/BuiltinAttributes.h"
 #include "mlir/IR/BuiltinOps.h"
 #include "mlir/IR/DialectRegistry.h"
diff --ruN a/stablehlo/stablehlo/tests/transforms/stablehlo_aggressive_folder.mlir b/stablehlo/stablehlo/tests/transforms/stablehlo_aggressive_folder.mlir
--- stablehlo/stablehlo/tests/transforms/stablehlo_aggressive_folder.mlir
+++ stablehlo/stablehlo/tests/transforms/stablehlo_aggressive_folder.mlir
@@ -529,28 +529,15 @@
 // IotaOp
 
 // CHECK-LABEL: func @eval_iota
-func.func @eval_iota() -> (tensor<3x4x5xi32>, tensor<3x4x5xi32>, tensor<3x4x5xi32>) {
-  // CHECK-NOT: stablehlo.iota
-  // CHECK: [[RESULT0:%.*]] = stablehlo.constant dense<
-  // CHECK-SAME: {{\[\[}}[0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0]],
-  // CHECK-SAME: {{\[}}[1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1]],
-  // CHECK-SAME: {{\[}}[2, 2, 2, 2, 2], [2, 2, 2, 2, 2], [2, 2, 2, 2, 2], [2, 2, 2, 2, 2]]]> : tensor<3x4x5xi32>
-
-  // CHECK: [[RESULT1:%.*]] = stablehlo.constant dense<
-  // CHECK-SAME: {{\[\[}}[0, 0, 0, 0, 0], [1, 1, 1, 1, 1], [2, 2, 2, 2, 2], [3, 3, 3, 3, 3]],
-  // CHECK-SAME: {{\[}}[0, 0, 0, 0, 0], [1, 1, 1, 1, 1], [2, 2, 2, 2, 2], [3, 3, 3, 3, 3]],
-  // CHECK-SAME: {{\[}}[0, 0, 0, 0, 0], [1, 1, 1, 1, 1], [2, 2, 2, 2, 2], [3, 3, 3, 3, 3]]]> : tensor<3x4x5xi32>
-
-  // CHECK: [[RESULT2:%.*]] = stablehlo.constant dense<
-  // CHECK-SAME: {{\[\[}}[0, 1, 2, 3, 4], [0, 1, 2, 3, 4], [0, 1, 2, 3, 4], [0, 1, 2, 3, 4]],
-  // CHECK-SAME: {{\[}}[0, 1, 2, 3, 4], [0, 1, 2, 3, 4], [0, 1, 2, 3, 4], [0, 1, 2, 3, 4]],
-  // CHECk-SAME: {{\[}}[0, 1, 2, 3, 4], [0, 1, 2, 3, 4], [0, 1, 2, 3, 4], [0, 1, 2, 3, 4]]]> : tensor<3x4x5xi32>
-
+func.func @eval_iota() -> (tensor<1xi32>, tensor<3x4x5xi32>, tensor<3x4x5xi32>) {
+  // CHECK:      [[RESULT0:%.*]] = stablehlo.constant dense<0> : tensor<1xi32>
+  // CHECK-NEXT: [[RESULT1:%.*]] = stablehlo.iota dim = 1 : tensor<3x4x5xi32>
+  // CHECK-NEXT: [[RESULT2:%.*]] = stablehlo.iota dim = 2 : tensor<3x4x5xi32>
   // CHECK: return [[RESULT0]], [[RESULT1]], [[RESULT2]]
-  %0 = stablehlo.iota dim = 0 : tensor<3x4x5xi32>
+  %0 = stablehlo.iota dim = 0 : tensor<1xi32>
   %1 = stablehlo.iota dim = 1 : tensor<3x4x5xi32>
   %2 = stablehlo.iota dim = 2 : tensor<3x4x5xi32>
-  func.return %0, %1, %2 : tensor<3x4x5xi32>, tensor<3x4x5xi32>, tensor<3x4x5xi32>
+  func.return %0, %1, %2 : tensor<1xi32>, tensor<3x4x5xi32>, tensor<3x4x5xi32>
 }
 
 // -----
@@ -596,6 +583,37 @@
   // CHECK-DAG:  [[CST2:%.+]] = stablehlo.constant dense<{{\[\[1, 2\], \[3, 4\]\]}}> : tensor<2x2xi32>
   // CHECK-NEXT: return [[CST1]], [[CST2]]
   return %0, %1 : tensor<1xi32>, tensor<2x2xi32>
+}
+
+// -----
+
+////////
+// SliceOp / DynamicSliceOp
+
+// CHECK-LABEL: @slice_fold
+func.func @slice_fold(%arg0: tensor<6x1xi32>) -> tensor<1x1xi32> {
+  %c = stablehlo.constant dense<[[0], [1], [2], [3], [4], [5]]> : tensor<6x1xi32>
+  %0 = stablehlo.slice %c [2:3, 0:1] : (tensor<6x1xi32>) -> tensor<1x1xi32>
+  // CHECK: stablehlo.constant dense<2> : tensor<1x1xi32>
+  return %0 : tensor<1x1xi32>
+}
+
+// CHECK-LABEL: @slice_fold_splat
+func.func @slice_fold_splat(%arg0: tensor<6x1xi32>) -> tensor<1x1xi32> {
+  %c = stablehlo.constant dense<1> : tensor<6x1xi32>
+  %0 = stablehlo.slice %c [2:3, 0:1] : (tensor<6x1xi32>) -> tensor<1x1xi32>
+  // CHECK: stablehlo.constant dense<1> : tensor<1x1xi32>
+  return %0 : tensor<1x1xi32>
+}
+
+// CHECK-LABEL: @dynamic_slice_fold
+func.func @dynamic_slice_fold(%arg0: tensor<i32>, %arg1: tensor<i32>) -> tensor<1x1xi32> {
+  %0 = stablehlo.constant dense<256> : tensor<6x1xi32>
+  %1 = "stablehlo.dynamic_slice"(%0, %arg0, %arg1) <{slice_sizes = array<i64: 1, 1>}> : (tensor<6x1xi32>, tensor<i32>, tensor<i32>) -> tensor<1x1xi32>
+
+  // CHECK: %[[RESULT:.*]] = stablehlo.constant dense<256> : tensor<1x1xi32>
+  // CHECK: return %[[RESULT]]
+  return %1 : tensor<1x1xi32>
 }
 
 // -----
diff --ruN a/stablehlo/stablehlo/transforms/ChloLegalizeToStablehlo.cpp b/stablehlo/stablehlo/transforms/ChloLegalizeToStablehlo.cpp
--- stablehlo/stablehlo/transforms/ChloLegalizeToStablehlo.cpp
+++ stablehlo/stablehlo/transforms/ChloLegalizeToStablehlo.cpp
@@ -73,7 +73,7 @@
 template <typename FromOpTy, typename ToOpTy>
 struct HloNaryElementwiseAdaptor {
   static ToOpTy createOp(FromOpTy fromOp, Type resultType,
-                         ValueRange broadcastedOperands, OpBuilder& builder) {
+                         ValueRange broadcastedOperands, OpBuilder &builder) {
     return builder.create<ToOpTy>(fromOp.getLoc(), resultType,
                                   broadcastedOperands);
   }
@@ -118,7 +118,7 @@
 struct HloCompareAdaptor {
   static mlir::stablehlo::CompareOp createOp(
       mlir::chlo::BroadcastCompareOp fromOp, Type resultType,
-      ValueRange broadcastedOperands, OpBuilder& builder) {
+      ValueRange broadcastedOperands, OpBuilder &builder) {
     auto chloDirection = fromOp.getComparisonDirection();
     auto hloDirection = toStableHloComparisonDirection(chloDirection);
     if (!hloDirection) return nullptr;
@@ -140,9 +140,9 @@
 // to take a ChloOpTy, NonBroadcastingOpTy, and an Adaptor as templated values.
 template <template <typename, typename, typename> typename Pattern,
           typename... ConstructorArgs>
-static void populateForBroadcastingBinaryOp(MLIRContext* context,
-                                            RewritePatternSet* patterns,
-                                            ConstructorArgs&&... args) {
+static void populateForBroadcastingBinaryOp(MLIRContext *context,
+                                            RewritePatternSet *patterns,
+                                            ConstructorArgs &&...args) {
 #define POPULATE_BCAST(ChloOp, HloOp)                                          \
   patterns                                                                     \
       ->add<Pattern<ChloOp, HloOp, HloNaryElementwiseAdaptor<ChloOp, HloOp>>>( \
@@ -179,21 +179,21 @@
       context, args...);
 }
 
-static Value getConstantLikeMaxFiniteValue(OpBuilder& b, Location loc,
+static Value getConstantLikeMaxFiniteValue(OpBuilder &b, Location loc,
                                            Value val) {
   auto ty = cast<FloatType>(getElementTypeOrSelf(val.getType()));
   return getConstantLike(
       b, loc, llvm::APFloat::getLargest(ty.getFloatSemantics()), val);
 }
 
-static Value getConstantLikeInfValue(OpBuilder& b, Location loc, Value val,
+static Value getConstantLikeInfValue(OpBuilder &b, Location loc, Value val,
                                      bool negative) {
   auto ty = cast<FloatType>(getElementTypeOrSelf(val.getType()));
   return getConstantLike(
       b, loc, llvm::APFloat::getInf(ty.getFloatSemantics(), negative), val);
 }
 
-static Value getConstantLikeSmallestNormalizedValue(OpBuilder& b, Location loc,
+static Value getConstantLikeSmallestNormalizedValue(OpBuilder &b, Location loc,
                                                     Value val) {
   auto ty = cast<FloatType>(getElementTypeOrSelf(val.getType()));
   return getConstantLike(
@@ -239,7 +239,7 @@
 
   LogicalResult matchAndRewrite(
       ChloOpTy op, typename ChloOpTy::Adaptor adaptor,
-      ConversionPatternRewriter& rewriter) const override {
+      ConversionPatternRewriter &rewriter) const override {
     // Only rewrite for statically determinable non-broadcasting cases.
     auto lhsType = dyn_cast<RankedTensorType>(adaptor.getLhs().getType());
     auto rhsType = dyn_cast<RankedTensorType>(adaptor.getRhs().getType());
@@ -329,7 +329,7 @@
 
   LogicalResult matchAndRewrite(
       ChloOpTy op, typename ChloOpTy::Adaptor adaptor,
-      ConversionPatternRewriter& rewriter) const override {
+      ConversionPatternRewriter &rewriter) const override {
     // Only support ranked operands.
     Value lhs = adaptor.getLhs();
     Value rhs = adaptor.getRhs();
@@ -413,7 +413,7 @@
 
   LogicalResult matchAndRewrite(
       mlir::chlo::ConstantLikeOp op, OpAdaptor adaptor,
-      ConversionPatternRewriter& rewriter) const override {
+      ConversionPatternRewriter &rewriter) const override {
     auto resultTy = cast<ShapedType>(op.getType());
 
     // Unranked uses are not supported.
@@ -445,7 +445,7 @@
 
   LogicalResult matchAndRewrite(
       mlir::chlo::BroadcastSelectOp op, OpAdaptor adaptor,
-      ConversionPatternRewriter& rewriter) const override {
+      ConversionPatternRewriter &rewriter) const override {
     // Only support ranked operands.
     Value pred = adaptor.getPred();
     Value onTrue = adaptor.getOnTrue();
@@ -533,7 +533,7 @@
 
   LogicalResult matchAndRewrite(
       mlir::chlo::ConstantOp op, OpAdaptor adaptor,
-      ConversionPatternRewriter& rewriter) const override {
+      ConversionPatternRewriter &rewriter) const override {
     rewriter.replaceOpWithNewOp<mlir::stablehlo::ConstantOp>(op, op.getValue());
     return success();
   }
@@ -541,7 +541,7 @@
 
 template <typename FTy>
 static Value materializeChebyshevPolynomialApproximation(
-    OpBuilder& rewriter, Location loc, Value x, ArrayRef<FTy> coefficients) {
+    OpBuilder &rewriter, Location loc, Value x, ArrayRef<FTy> coefficients) {
   Value b0 = getConstantLike(rewriter, loc, 0.0, x);
   Value b1 = getConstantLike(rewriter, loc, 0.0, x);
   Value b2 = getConstantLike(rewriter, loc, 0.0, x);
@@ -561,7 +561,7 @@
 }
 
 template <typename FTy>
-static Value materializeBesselI1eApproximation(OpBuilder& rewriter,
+static Value materializeBesselI1eApproximation(OpBuilder &rewriter,
                                                Location loc, Value x,
                                                ArrayRef<FTy> kI1eCoeffsA,
                                                ArrayRef<FTy> kI1eCoeffsB) {
@@ -594,7 +594,7 @@
       loc, rewriter.create<mlir::stablehlo::SignOp>(loc, x), select);
 }
 
-Value materializeBesselI1eApproximationF32(OpBuilder& rewriter, Location loc,
+Value materializeBesselI1eApproximationF32(OpBuilder &rewriter, Location loc,
                                            ValueRange args) {
   Value x = args.front();
   assert(cast<ShapedType>(x.getType()).getElementType().isF32() &&
@@ -620,7 +620,7 @@
                                                   kI1eCoeffsB);
 }
 
-static Value materializeBesselI1eApproximationF64(OpBuilder& rewriter,
+static Value materializeBesselI1eApproximationF64(OpBuilder &rewriter,
                                                   Location loc,
                                                   ValueRange args) {
   Value x = args.front();
@@ -663,10 +663,10 @@
                                                    kI1eCoeffsA, kI1eCoeffsB);
 }
 
-static Value materializeWithUpcast(ConversionPatternRewriter& rewriter,
+static Value materializeWithUpcast(ConversionPatternRewriter &rewriter,
                                    Location loc, ValueRange args,
                                    FloatType minPrecisionTy,
-                                   Value callback(OpBuilder&, Location,
+                                   Value callback(OpBuilder &, Location,
                                                   ValueRange)) {
   Type originalTy = getElementTypeOrSelf(args.front().getType());
   auto floatOriginalTy = dyn_cast<FloatType>(originalTy);
@@ -699,7 +699,7 @@
 
   LogicalResult matchAndRewrite(
       mlir::chlo::BesselI1eOp op, OpAdaptor adaptor,
-      ConversionPatternRewriter& rewriter) const override {
+      ConversionPatternRewriter &rewriter) const override {
     Location loc = op.getLoc();
     Value x = adaptor.getOperand();
     Type ty = cast<ShapedType>(x.getType()).getElementType();
@@ -725,7 +725,7 @@
 };
 
 template <typename FTy>
-static Value materializePolynomialApproximation(OpBuilder& rewriter,
+static Value materializePolynomialApproximation(OpBuilder &rewriter,
                                                 Location loc, Value x,
                                                 ArrayRef<FTy> coefficients) {
   if (coefficients.empty()) return getConstantLike(rewriter, loc, 0.0, x);
@@ -746,7 +746,7 @@
 // argument and derive the final approximation for all |x| >= 1.
 // This implementation is based on Cephes.
 static Value materializeErfcApproximationF64ForMagnituteGeOne(
-    ConversionPatternRewriter& rewriter, Location loc, ValueRange args) {
+    ConversionPatternRewriter &rewriter, Location loc, ValueRange args) {
   Value x = args.front();
   assert(cast<ShapedType>(x.getType()).getElementType().isF64() &&
          "expect f64 element type");
@@ -831,7 +831,7 @@
 // Precondition is |x| <= 1. Use erfc approximation, otherwise.
 // This implementation is based on Cephes.
 static Value materializeErfApproximationF64ForMagnituteLeOne(
-    ConversionPatternRewriter& rewriter, Location loc, ValueRange args) {
+    ConversionPatternRewriter &rewriter, Location loc, ValueRange args) {
   Value x = args.front();
   assert(cast<ShapedType>(x.getType()).getElementType().isF64() &&
          "expect f64 element type");
@@ -856,7 +856,7 @@
 }
 
 // This implementation is based on Cephes.
-static Value materializeErfApproximationF64(ConversionPatternRewriter& rewriter,
+static Value materializeErfApproximationF64(ConversionPatternRewriter &rewriter,
                                             Location loc, ValueRange args) {
   Value x = args.front();
   assert(cast<ShapedType>(x.getType()).getElementType().isF64() &&
@@ -884,7 +884,7 @@
 }
 
 static Value materializeErfcApproximationF64(
-    ConversionPatternRewriter& rewriter, Location loc, ValueRange args) {
+    ConversionPatternRewriter &rewriter, Location loc, ValueRange args) {
   Value x = args.front();
   assert(cast<ShapedType>(x.getType()).getElementType().isF64() &&
          "expect f64 element type");
@@ -916,7 +916,7 @@
 // argument and derive the final approximation for all |x| >= 1.
 // This implementation is based on Cephes.
 static Value materializeErfcApproximationF32ForMagnitudeGeOne(
-    OpBuilder& rewriter, Location loc, ValueRange args) {
+    OpBuilder &rewriter, Location loc, ValueRange args) {
   Value x = args.front();
   assert(cast<ShapedType>(x.getType()).getElementType().isF32() &&
          "expect f32 element type");
@@ -982,7 +982,7 @@
 // Precondition is |x| <= 1. Use erfc approximation, otherwise.
 // This implementation is based on Cephes.
 static Value materializeErfApproximationF32ForMagnitudeLeOne(
-    OpBuilder& rewriter, Location loc, ValueRange args) {
+    OpBuilder &rewriter, Location loc, ValueRange args) {
   Value x = args.front();
   assert(cast<ShapedType>(x.getType()).getElementType().isF32() &&
          "expect f32 element type");
@@ -1001,7 +1001,7 @@
 }
 
 // This is the same approximation as used in Eigen.
-static Value materializeErfApproximationF32(OpBuilder& rewriter, Location loc,
+static Value materializeErfApproximationF32(OpBuilder &rewriter, Location loc,
                                             ValueRange args) {
   Value x = args.front();
   assert(cast<ShapedType>(x.getType()).getElementType().isF32() &&
@@ -1038,7 +1038,7 @@
                                                    erf, ubErf);
 }
 
-static Value materializeErfcApproximationF32(OpBuilder& rewriter, Location loc,
+static Value materializeErfcApproximationF32(OpBuilder &rewriter, Location loc,
                                              ValueRange args) {
   Value x = args.front();
   assert(cast<ShapedType>(x.getType()).getElementType().isF32() &&
@@ -1070,7 +1070,7 @@
 
   LogicalResult matchAndRewrite(
       mlir::chlo::ErfOp op, OpAdaptor adaptor,
-      ConversionPatternRewriter& rewriter) const override {
+      ConversionPatternRewriter &rewriter) const override {
     Location loc = op.getLoc();
     Value x = adaptor.getOperand();
     Type ty = cast<ShapedType>(x.getType()).getElementType();
@@ -1098,7 +1098,7 @@
 
   LogicalResult matchAndRewrite(
       mlir::chlo::ErfcOp op, OpAdaptor adaptor,
-      ConversionPatternRewriter& rewriter) const override {
+      ConversionPatternRewriter &rewriter) const override {
     Location loc = op.getLoc();
     Value x = adaptor.getOperand();
     Type ty = cast<ShapedType>(x.getType()).getElementType();
@@ -1121,7 +1121,7 @@
   }
 };
 
-static Value erfInv32(OpBuilder& b, Location loc, ValueRange args) {
+static Value erfInv32(OpBuilder &b, Location loc, ValueRange args) {
   constexpr int kDegree = 9;
   constexpr std::array<float, 9> wLessThan5Constants = {
       2.81022636e-08f,  3.43273939e-07f, -3.5233877e-06f,
@@ -1178,7 +1178,7 @@
       result);
 }
 
-static Value erfInv64(ConversionPatternRewriter& b, Location loc,
+static Value erfInv64(ConversionPatternRewriter &b, Location loc,
                       ValueRange args) {
   constexpr std::array<double, 23> wLessThan625Constants = {
       -3.6444120640178196996e-21, -1.685059138182016589e-19,
@@ -1298,7 +1298,7 @@
 
   LogicalResult matchAndRewrite(
       mlir::chlo::ErfInvOp op, OpAdaptor adaptor,
-      ConversionPatternRewriter& rewriter) const override {
+      ConversionPatternRewriter &rewriter) const override {
     Location loc = op.getLoc();
     if (op.getType().getElementType().isF64()) {
       rewriter.replaceOp(op, erfInv64(rewriter, loc, adaptor.getOperands()));
@@ -1338,7 +1338,7 @@
 //   with   t(z) = z + kLanczosGamma + 1/2
 //          a(z) = kBaseLanczosCoeff
 //                   + sum(k = 1, n, kLanczosCoefficients[i] / (z + k))
-Value materializeLgamma(OpBuilder& rewriter, Location loc, ValueRange args) {
+Value materializeLgamma(OpBuilder &rewriter, Location loc, ValueRange args) {
   // If the input is less than 0.5 use Euler's reflection formula.
   //   gamma(x) = pi / (sin(pi * x) * gamma(1 - x))
   // Let z be
@@ -1485,7 +1485,7 @@
 // +/-89.4159851, due to rounding error when computing x +/- log(1/2).  The
 // correct answer of 3.40281961e+38 (0x7f7fffec) is very close to max-float, so
 // we deem this acceptable.
-static Value materializeCoshApproximation(OpBuilder& rewriter, Location loc,
+static Value materializeCoshApproximation(OpBuilder &rewriter, Location loc,
                                           ValueRange operands) {
   mlir::chlo::CoshOp::Adaptor transformed(operands);
   Value x = transformed.getOperand();
@@ -1504,7 +1504,7 @@
 
   LogicalResult matchAndRewrite(
       mlir::chlo::CoshOp op, OpAdaptor adaptor,
-      ConversionPatternRewriter& rewriter) const override {
+      ConversionPatternRewriter &rewriter) const override {
     rewriter.replaceOp(
         op, materializeWithUpcast(rewriter, op.getLoc(), adaptor.getOperands(),
                                   rewriter.getF32Type(),
@@ -1523,7 +1523,7 @@
 //          a(z) = kBaseLanczosCoeff
 //                   + sum(k = 1, n, kLanczosCoefficients[i] / (z + k))
 //          a'(z) = - sum(k = 1, n, kLanczosCoefficients[i] / (z + k) / (z + k))
-Value materializeDigamma(OpBuilder& rewriter, Location loc, ValueRange args) {
+Value materializeDigamma(OpBuilder &rewriter, Location loc, ValueRange args) {
   // If the input is less than 0.5 use Euler's reflection formula.
   //   digamma(x) = digamma(1 - x) - pi * cot(pi * x)
   // Let z be
@@ -1630,14 +1630,14 @@
 
 namespace {
 
-static Value getConstantLikeSmallestFiniteValue(OpBuilder& b, Location loc,
+static Value getConstantLikeSmallestFiniteValue(OpBuilder &b, Location loc,
                                                 Value val) {
   auto ty = cast<FloatType>(getElementTypeOrSelf(val.getType()));
   return getConstantLike(
       b, loc, llvm::APFloat::getSmallest(ty.getFloatSemantics()), val);
 }
 
-static Value materializeZeta(OpBuilder& rewriter, Location loc,
+static Value materializeZeta(OpBuilder &rewriter, Location loc,
                              ValueRange args) {
   // Implementation ported from:
   // https://github.com/openxla/xla/blob/7a067a7b88d2ffb15b1dc5e3c06f701a15f0391d/xla/client/lib/math.cc#L1912-L1917
@@ -1790,7 +1790,7 @@
 
 }  // namespace
 
-Value materializePolygamma(OpBuilder& rewriter, Location loc, ValueRange args) {
+Value materializePolygamma(OpBuilder &rewriter, Location loc, ValueRange args) {
   mlir::chlo::PolygammaOp::Adaptor transformed(args);
   Value n = transformed.getN();
   Value x = transformed.getX();
@@ -1840,7 +1840,7 @@
 
   LogicalResult matchAndRewrite(
       mlir::chlo::LgammaOp op, OpAdaptor adaptor,
-      ConversionPatternRewriter& rewriter) const override {
+      ConversionPatternRewriter &rewriter) const override {
     FloatType minPrecisionTy = rewriter.getF32Type();
     rewriter.replaceOp(
         op, materializeWithUpcast(rewriter, op.getLoc(), adaptor.getOperands(),
@@ -1854,7 +1854,7 @@
 
   LogicalResult matchAndRewrite(
       mlir::chlo::DigammaOp op, OpAdaptor adaptor,
-      ConversionPatternRewriter& rewriter) const override {
+      ConversionPatternRewriter &rewriter) const override {
     FloatType minPrecisionTy = rewriter.getF32Type();
     rewriter.replaceOp(
         op, materializeWithUpcast(rewriter, op.getLoc(), adaptor.getOperands(),
@@ -1863,7 +1863,7 @@
   }
 };
 
-static Value materializeNextAfter(ConversionPatternRewriter& rewriter,
+static Value materializeNextAfter(ConversionPatternRewriter &rewriter,
                                   Location loc, ValueRange operands) {
   mlir::chlo::NextAfterOp::Adaptor transformed(operands);
   Value x = transformed.getX();
@@ -1957,7 +1957,7 @@
 
   LogicalResult matchAndRewrite(
       mlir::chlo::NextAfterOp op, OpAdaptor adaptor,
-      ConversionPatternRewriter& rewriter) const override {
+      ConversionPatternRewriter &rewriter) const override {
     rewriter.replaceOp(
         op, materializeNextAfter(rewriter, op.getLoc(), adaptor.getOperands()));
     return success();
@@ -1969,7 +1969,7 @@
 
   LogicalResult matchAndRewrite(
       mlir::chlo::PolygammaOp op, OpAdaptor adaptor,
-      ConversionPatternRewriter& rewriter) const override {
+      ConversionPatternRewriter &rewriter) const override {
     Location loc = op.getLoc();
     FloatType minPrecisionTy = rewriter.getF32Type();
     rewriter.replaceOp(
@@ -1989,7 +1989,7 @@
 // +/-89.4159851, due to rounding error when computing x +/- log(1/2).  The
 // correct answer of 3.40281961e+38 (0x7f7fffec) is very close to max-float, so
 // we deem this acceptable.
-static Value materializeSinhApproximationForLargeX(OpBuilder& rewriter,
+static Value materializeSinhApproximationForLargeX(OpBuilder &rewriter,
                                                    Location loc,
                                                    ValueRange operands) {
   mlir::chlo::SinhOp::Adaptor transformed(operands);
@@ -2007,7 +2007,7 @@
 // Express `sinh` as
 //   sinh(x) = (e^x - e^-x) / 2                     if |x| < 1
 //           = e^(x + log(1/2)) - e^(-x + log(1/2)) otherwise.
-static Value materializeSinhApproximation(OpBuilder& rewriter, Location loc,
+static Value materializeSinhApproximation(OpBuilder &rewriter, Location loc,
                                           ValueRange operands) {
   Value largeSinhResult =
       materializeSinhApproximationForLargeX(rewriter, loc, operands);
@@ -2043,7 +2043,7 @@
 namespace {
 
 ArrayAttr convertPrecisionConfig(mlir::ArrayAttr precisionConfig,
-                                 ConversionPatternRewriter& rewriter) {
+                                 ConversionPatternRewriter &rewriter) {
   std::vector<Attribute> precisions;
   for (Attribute precision : precisionConfig.getValue()) {
     switch (dyn_cast<mlir::chlo::PrecisionAttr>(precision).getValue()) {
@@ -2077,7 +2077,7 @@
 // In this implementation, the IR size increases by a factor of g. If this
 // becomes a problem, we can try adding stablehlo.while to reduce the IR size.
 LogicalResult handleRaggedDotMode1(mlir::chlo::RaggedDotOp op,
-                                   ConversionPatternRewriter& rewriter) {
+                                   ConversionPatternRewriter &rewriter) {
   Value lhs = op.getLhs();
   Value rhs = op.getRhs();
   chlo::RaggedDotDimensionNumbersAttr raggedDotDimensionNumbers =
@@ -2231,7 +2231,7 @@
 //   group_sizes : [g]
 //   result : [g, b, m, n]
 LogicalResult handleRaggedDotMode2(mlir::chlo::RaggedDotOp op,
-                                   ConversionPatternRewriter& rewriter) {
+                                   ConversionPatternRewriter &rewriter) {
   return failure();
 }
 
@@ -2241,7 +2241,7 @@
 //   group_sizes : [g]
 //   result : [b, m, n]
 LogicalResult handleRaggedDotMode3(mlir::chlo::RaggedDotOp op,
-                                   ConversionPatternRewriter& rewriter) {
+                                   ConversionPatternRewriter &rewriter) {
   return failure();
 }
 
@@ -2254,7 +2254,7 @@
   // dimension.
   LogicalResult matchAndRewrite(
       mlir::chlo::RaggedDotOp op, OpAdaptor,
-      ConversionPatternRewriter& rewriter) const override {
+      ConversionPatternRewriter &rewriter) const override {
     if (op.getLhs().getType().getRank() < op.getRhs().getType().getRank()) {
       return handleRaggedDotMode1(op, rewriter);
     } else if (op.getLhs().getType().getRank() <
@@ -2271,7 +2271,7 @@
 
   LogicalResult matchAndRewrite(
       mlir::chlo::SinhOp op, OpAdaptor adaptor,
-      ConversionPatternRewriter& rewriter) const override {
+      ConversionPatternRewriter &rewriter) const override {
     Value x = adaptor.getOperand();
     if (isa<ComplexType>(cast<ShapedType>(x.getType()).getElementType())) {
       rewriter.replaceOp(op, materializeSinhApproximationForLargeX(
@@ -2321,7 +2321,7 @@
 
   LogicalResult matchAndRewrite(
       mlir::chlo::TopKOp op, OpAdaptor /*adaptor*/,
-      ConversionPatternRewriter& rewriter) const override {
+      ConversionPatternRewriter &rewriter) const override {
     auto operandType = dyn_cast<RankedTensorType>(op.getOperand().getType());
     if (!operandType) return failure();
     int64_t operandRank = operandType.getRank();
@@ -2436,7 +2436,7 @@
 
   LogicalResult matchAndRewrite(
       mlir::chlo::ZetaOp op, OpAdaptor adaptor,
-      ConversionPatternRewriter& rewriter) const override {
+      ConversionPatternRewriter &rewriter) const override {
     Location loc = op.getLoc();
     FloatType minPrecisionTy = rewriter.getF32Type();
     rewriter.replaceOp(
@@ -2452,7 +2452,7 @@
 
 struct ChloLegalizeToStablehloPass final
     : impl::ChloLegalizeToStablehloPassBase<ChloLegalizeToStablehloPass> {
-  LogicalResult initialize(MLIRContext* context) override {
+  LogicalResult initialize(MLIRContext *context) override {
     target = std::make_shared<ConversionTarget>(*context);
     target->addIllegalDialect<chlo::ChloDialect>();
     target->addLegalDialect<mlir::stablehlo::StablehloDialect,
@@ -2482,8 +2482,8 @@
 }  // namespace
 
 namespace {
-static void populateChloBroadcastingPatterns(MLIRContext* context,
-                                             RewritePatternSet* patterns) {
+static void populateChloBroadcastingPatterns(MLIRContext *context,
+                                             RewritePatternSet *patterns) {
   // Instantiate conversion templates for conforming binary elementwise ops
   // that do not have different dtypes between operands and results and do
   // not have special attributes that need to be preserved.
@@ -2496,8 +2496,8 @@
   patterns->add<ConvertConstantLikeOp, ConvertSelectOp>(context);
 }
 
-static void populateChloDecompositionPatterns(MLIRContext* context,
-                                              RewritePatternSet* patterns) {
+static void populateChloDecompositionPatterns(MLIRContext *context,
+                                              RewritePatternSet *patterns) {
   populateWithGenerated(*patterns);
   patterns
       ->add<ConvertConstantOp, ConvertBesselI1eOp, ConvertCoshOp,
@@ -2508,8 +2508,8 @@
 }
 }  // namespace
 
-void populateChloToStablehloPatterns(MLIRContext* context,
-                                     RewritePatternSet* patterns) {
+void populateChloToStablehloPatterns(MLIRContext *context,
+                                     RewritePatternSet *patterns) {
   populateChloBroadcastingPatterns(context, patterns);
   populateChloDecompositionPatterns(context, patterns);
 }
diff --ruN a/stablehlo/stablehlo/transforms/optimization/Passes.td b/stablehlo/stablehlo/transforms/optimization/Passes.td
--- stablehlo/stablehlo/transforms/optimization/Passes.td
+++ stablehlo/stablehlo/transforms/optimization/Passes.td
@@ -23,14 +23,14 @@
          "explicit MLIR `MemoryEffects`. Notably, this means `func.call` ops "
          "will be assumed pure.">,
   Option<"foldOpElementLimit", "fold-op-element-limit", "int64_t",
-         /*default=*/"1",
+         /*default=*/"65536",
          "Folding an op into a constant can sometimes come at the cost of "
          "memory overhead. (This occurs if the op's inputs are reused, meaning "
          "that they can't be deleted after the op is folded to a constant, or "
-         "when folding operations like `iota` whose outputs take up more "
+         "when folding operations like `concat` whose outputs take up more "
          "memory than their inputs.) In such cases, this config option sets an "
          "upper limit on how many elements an op's result may have before the "
-         "op is no longer folded.">,
+         "op is no longer folded. Splat folds are exempt from this limit.">,
   Option<"optimizeFloat", "optimize-float", "bool", /*default=*/"true",
          "Allow float optimizations that, though mathematically equivalent, "
          "may result in slightly different quantization of floating-point "
diff --ruN a/stablehlo/stablehlo/transforms/optimization/StablehloAggressiveFolder.cpp b/stablehlo/stablehlo/transforms/optimization/StablehloAggressiveFolder.cpp
--- stablehlo/stablehlo/transforms/optimization/StablehloAggressiveFolder.cpp
+++ stablehlo/stablehlo/transforms/optimization/StablehloAggressiveFolder.cpp
@@ -74,12 +74,39 @@
 
 static constexpr StablehloAggressiveFolderPassOptions kDefaultOptions;
 
+APSInt getAPSInt(Type type, uint64_t value) {
+  unsigned numBits;
+  bool isUnsigned;
+  if (auto integerType = dyn_cast<IntegerType>(type)) {
+    numBits = integerType.getWidth();
+    // Signless types are treated as signed, per StableHLO convention.
+    isUnsigned = integerType.isUnsignedInteger();
+  } else {
+    llvm::report_fatal_error("expected integer type");
+  }
+  return APSInt(
+      {/*numBits=*/numBits, value, /*isSigned=*/false, /*implicitTrunc=*/true},
+      /*isUnsigned=*/isUnsigned);
+}
+
 template <typename T>
 APSInt getAPSInt(unsigned bitWidth, T value, bool isSigned) {
   return APSInt({/*numBits=*/bitWidth, static_cast<uint64_t>(value),
                  /*isSigned=*/isSigned,
                  /*implicitTrunc=*/true},
                 /*isUnsigned=*/!isSigned);
+}
+
+APFloat getAPFloat(
+    Type type, double value,
+    llvm::RoundingMode roundingMode = llvm::RoundingMode::NearestTiesToEven) {
+  auto floatType = dyn_cast<FloatType>(type);
+  if (!floatType) llvm::report_fatal_error("expected float type");
+
+  APFloat result(value);
+  bool unusedLosesInfo = false;
+  result.convert(floatType.getFloatSemantics(), roundingMode, &unusedLosesInfo);
+  return result;
 }
 
 LogicalResult validateStaticShapeResult(PatternRewriter& rewriter,
@@ -1256,21 +1283,48 @@
       return rewriter.notifyMatchFailure(
           op, "expected operand with static ranked tensor type");
 
-    ElementsAttr els;
+    DenseElementsAttr els;
     if (!matchPattern(operand, m_Constant(&els)))
       return rewriter.notifyMatchFailure(
           op, "expected constant integer or float operand");
 
+    // Short circuit on splat resizes
+    if (els.isSplat()) {
+      rewriter.replaceOpWithNewOp<ConstantOp>(op, els.resizeSplat(resultType));
+      return success();
+    }
+
     DenseElementsAttr resAttr;
-    if (auto data = els.tryGetValues<APInt>())
+    if (auto data = els.tryGetValues<APInt>(); succeeded(data))
       resAttr = sliceType(op, *data);
-    else if (auto data = els.tryGetValues<APFloat>())
+    else if (auto data = els.tryGetValues<APFloat>(); succeeded(data))
       resAttr = sliceType(op, *data);
     else
       return rewriter.notifyMatchFailure(op.getLoc(),
                                          "unsupported element type");
 
     rewriter.replaceOpWithNewOp<ConstantOp>(op, resAttr);
+    return success();
+  }
+};
+
+// Pattern: dynamic_slice(splat_cst, start, end) -> resized_splat_cst
+struct FoldDynamicSliceOpPattern : public FoldOpRewritePattern<DynamicSliceOp> {
+  using FoldOpRewritePattern::FoldOpRewritePattern;
+
+  LogicalResult matchAndRewrite(DynamicSliceOp op,
+                                PatternRewriter& rewriter) const override {
+    auto resultType = op.getType();
+    if (failed(validateStaticShapeResult(rewriter, op, resultType)))
+      return failure();
+
+    SplatElementsAttr inputSplatAttr;
+    if (!matchPattern(op.getOperand(), m_Constant(&inputSplatAttr)) ||
+        !inputSplatAttr)
+      return rewriter.notifyMatchFailure(op, "Input must be a splat constant.");
+
+    rewriter.replaceOpWithNewOp<ConstantOp>(
+        op, inputSplatAttr.resizeSplat(resultType));
     return success();
   }
 };
@@ -1482,6 +1536,14 @@
       rewriter.replaceOpWithNewOp<ConstantOp>(
           op, DenseIntElementsAttr::get(resultType, values));
       return success();
+    }
+
+    // TODO: Support more iota folding, but doing so currently causes OOMs,
+    // so this pattern needs to be enabled more carefully.
+    if (outputSize != 1) {
+      return rewriter.notifyMatchFailure(
+          op, "expected output size to be 1, but got: " +
+                  std::to_string(outputSize));
     }
 
     int64_t sequences = 1;
@@ -1881,6 +1943,7 @@
   patterns->add<FoldConcatenateOpPattern>(context, options, benefit);
   patterns->add<FoldConvertOpPattern>(context, options, benefit);
   patterns->add<FoldDivOpPattern>(context, options, benefit);
+  patterns->add<FoldDynamicSliceOpPattern>(context, options, benefit);
   patterns->add<FoldGetDimensionSizeOpPattern>(context, options, benefit);
   patterns->add<FoldMaxOpPattern>(context, options, benefit);
   patterns->add<FoldMinOpPattern>(context, options, benefit);
diff --ruN a/stablehlo/stablehlo/transforms/optimization/StablehloAggressiveSimplification.cpp b/stablehlo/stablehlo/transforms/optimization/StablehloAggressiveSimplification.cpp
--- stablehlo/stablehlo/transforms/optimization/StablehloAggressiveSimplification.cpp
+++ stablehlo/stablehlo/transforms/optimization/StablehloAggressiveSimplification.cpp
@@ -331,7 +331,7 @@
 DenseI64ArrayAttr getInvertedBroadcastDimensions(OpBuilder& b,
                                                  ArrayRef<int64_t> dims) {
   SmallVector<int64_t> permutation(dims.size());
-  for (size_t i = 0; i < dims.size(); ++i) {
+  for (auto i = 0; i < dims.size(); ++i) {
     permutation[dims[i]] = i;
   }
   return b.getDenseI64ArrayAttr(permutation);

