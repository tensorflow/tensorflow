diff --ruN a/stablehlo/BUILD.bazel b/stablehlo/BUILD.bazel
--- stablehlo/BUILD.bazel
+++ stablehlo/BUILD.bazel
@@ -842,6 +842,7 @@
     "stablehlo/integrations/c/StablehloDialect.cpp",
     "stablehlo/integrations/c/StablehloDialectApi.cpp",
     "stablehlo/integrations/c/StablehloTypes.cpp",
+    "stablehlo/integrations/c/InterpreterDialect.cpp",
 ]
 
 STABLEHLO_DIALECT_CAPI_HEADERS = [
@@ -849,6 +850,7 @@
     "stablehlo/integrations/c/StablehloDialect.h",
     "stablehlo/integrations/c/StablehloDialectApi.h",
     "stablehlo/integrations/c/StablehloTypes.h",
+    "stablehlo/integrations/c/InterpreterDialect.h",
 ]
 
 cc_library(
@@ -857,6 +859,7 @@
     hdrs = STABLEHLO_DIALECT_CAPI_HEADERS,
     strip_include_prefix = ".",
     deps = [
+        ":interpreter_ops",
         ":stablehlo_ops",
         ":stablehlo_portable_api",
         ":stablehlo_serialization",
@@ -885,6 +888,7 @@
     hdrs = STABLEHLO_DIALECT_CAPI_HEADERS,
     strip_include_prefix = ".",
     deps = [
+        ":interpreter_ops",
         ":stablehlo_ops",
         ":stablehlo_portable_api",
         ":stablehlo_serialization",
@@ -909,6 +913,7 @@
     "stablehlo/integrations/c/StablehloDialectApi.h",
     "stablehlo/integrations/c/StablehloUnifiedApi.h",
     "stablehlo/integrations/c/StablehloTypes.h",
+    "stablehlo/integrations/c/InterpreterDialect.h",
 ]
 
 cc_library(
diff --ruN a/stablehlo/stablehlo/conversions/linalg/transforms/MapStablehloToScalarOp.h b/stablehlo/stablehlo/conversions/linalg/transforms/MapStablehloToScalarOp.h
--- stablehlo/stablehlo/conversions/linalg/transforms/MapStablehloToScalarOp.h
+++ stablehlo/stablehlo/conversions/linalg/transforms/MapStablehloToScalarOp.h
@@ -499,7 +499,7 @@
   expBitsMask = ((expBitsMask << srcExponentBits) - 1) << srcMantissaBits;
 
   auto createConstant = [&](const APInt &v) {
-    return b.create<arith::ConstantIntOp>(v.getZExtValue(), intType)
+    return b.create<arith::ConstantIntOp>(intType, v.getZExtValue())
         .getResult();
   };
 
@@ -520,7 +520,7 @@
     APInt baseRoundingBias = lastMantissaBitMask.lshr(1) - 1;
 
     Value mantissaDiff = b.create<arith::ConstantIntOp>(
-        srcMantissaBits - destMantissaBits, intType);
+        intType, srcMantissaBits - destMantissaBits);
     Value highestMantissaMaskVal = createConstant(lastMantissaBitMask);
     Value baseRoundingBiasVal = createConstant(baseRoundingBias);
     Value xLastMantissaBit = b.create<arith::ShRUIOp>(
diff --ruN a/stablehlo/stablehlo/conversions/linalg/transforms/StablehloToLinalgConvolution.cpp b/stablehlo/stablehlo/conversions/linalg/transforms/StablehloToLinalgConvolution.cpp
--- stablehlo/stablehlo/conversions/linalg/transforms/StablehloToLinalgConvolution.cpp
+++ stablehlo/stablehlo/conversions/linalg/transforms/StablehloToLinalgConvolution.cpp
@@ -579,8 +579,9 @@
                 /*bodyBuild=*/
                 [&](OpBuilder &nestedBuilder, Location nestedLoc, ValueRange) {
                   ImplicitLocOpBuilder builder(nestedLoc, nestedBuilder);
-                  linalg::Conv2DOp::regionBuilder(
-                      builder, *builder.getInsertionBlock(), {});
+                  linalg::Conv2DOp::regionBuilder(builder,
+                                                  *builder.getInsertionBlock(),
+                                                  {}, /*emitError=*/{});
                 },
                 linalg::getPrunedAttributeList(op))
             .getResult(0);
diff --ruN a/stablehlo/stablehlo/conversions/linalg/transforms/StablehloToLinalgDotProduct.cpp b/stablehlo/stablehlo/conversions/linalg/transforms/StablehloToLinalgDotProduct.cpp
--- stablehlo/stablehlo/conversions/linalg/transforms/StablehloToLinalgDotProduct.cpp
+++ stablehlo/stablehlo/conversions/linalg/transforms/StablehloToLinalgDotProduct.cpp
@@ -299,7 +299,8 @@
             /*nReduction=*/numContracting),
         [](OpBuilder &b, Location loc, ValueRange) {
           ImplicitLocOpBuilder builder(loc, b);
-          linalg::MatmulOp::regionBuilder(builder, *b.getInsertionBlock(), {});
+          linalg::MatmulOp::regionBuilder(builder, *b.getInsertionBlock(), {},
+                                          /*emitError=*/{});
         },
         linalg::getPrunedAttributeList(op));
 
diff --ruN a/stablehlo/stablehlo/dialect/AssemblyFormat.cpp b/stablehlo/stablehlo/dialect/AssemblyFormat.cpp
--- stablehlo/stablehlo/dialect/AssemblyFormat.cpp
+++ stablehlo/stablehlo/dialect/AssemblyFormat.cpp
@@ -655,7 +655,7 @@
   }
   p.printOptionalAttrDictWithKeyword(op->getAttrs());
   p.printNewline();
-  p << " cond ";
+  p << "cond ";
   p.printRegion(cond, /*printEntryBlockArgs=*/false);
   p << " do ";
   p.printRegion(body, /*printEntryBlockArgs=*/false);
diff --ruN a/stablehlo/stablehlo/dialect/StablehloOps.cpp b/stablehlo/stablehlo/dialect/StablehloOps.cpp
--- stablehlo/stablehlo/dialect/StablehloOps.cpp
+++ stablehlo/stablehlo/dialect/StablehloOps.cpp
@@ -2201,14 +2201,14 @@
   locs.reserve(numValues);
   for (auto i : inputs) {
     auto iType = cast<ShapedType>(i.getType());
-    blockArgTypes.push_back(iType.cloneWith(
-        llvm::ArrayRef<int64_t>(std::nullopt), iType.getElementType()));
+    blockArgTypes.push_back(
+        iType.cloneWith(llvm::ArrayRef<int64_t>(), iType.getElementType()));
     locs.push_back(i.getLoc());
   }
   for (auto i : init_values) {
     auto iType = cast<ShapedType>(i.getType());
-    blockArgTypes.push_back(iType.cloneWith(
-        llvm::ArrayRef<int64_t>(std::nullopt), iType.getElementType()));
+    blockArgTypes.push_back(
+        iType.cloneWith(llvm::ArrayRef<int64_t>(), iType.getElementType()));
     locs.push_back(i.getLoc());
   }
 
diff --ruN a/stablehlo/stablehlo/dialect/TypeInference.cpp b/stablehlo/stablehlo/dialect/TypeInference.cpp
--- stablehlo/stablehlo/dialect/TypeInference.cpp
+++ stablehlo/stablehlo/dialect/TypeInference.cpp
@@ -1147,7 +1147,7 @@
       *paddingOrErr,
       /*lhsDilation=*/baseDilations.value_or(SmallVector<int64_t, 0>{}),
       /*rhsDilation=*/windowDilations.value_or(SmallVector<int64_t, 0>{}),
-      /*windowReversal=*/std::nullopt, location);
+      /*windowReversal=*/{}, location);
   if (failed(windowOrErr)) return failure();
 
   windowDims.append(windowDimensions.begin(), windowDimensions.end());
@@ -2248,6 +2248,22 @@
   return success();
 }
 
+namespace {
+
+// Infer dim sizes with bounds accounted for
+void pushDimensionAndBoundSize(SmallVector<int64_t>& inferredSizes,
+                               SmallVector<int64_t>& inferredBounds,
+                               int64_t dimension, ShapedType type,
+                               ArrayRef<int64_t> bounds) {
+  inferredSizes.push_back(type.getDimSize(dimension));
+
+  // Has bounds and is bounded
+  auto bound = bounds.empty() ? ShapedType::kDynamic : bounds[dimension];
+  inferredBounds.push_back(bound);
+}
+
+}  // namespace
+
 LogicalResult inferDotOp(
     std::optional<Location> location, RankedTensorType lhsType,
     RankedTensorType rhsType, std::optional<ArrayAttr> precisionConfig,
@@ -2256,6 +2272,9 @@
     return failure();
 
   SmallVector<int64_t> dimensions;
+  SmallVector<int64_t> bounds;
+  auto lhsBounds = to_vector(encodingToBounds(lhsType.getEncoding()));
+  auto rhsBounds = to_vector(encodingToBounds(rhsType.getEncoding()));
   if (1 == lhsType.getRank() && 1 == rhsType.getRank() &&
       // vector dot vector
       verifyCompatibleDims(lhsType.getDimSize(0), rhsType.getDimSize(0))) {
@@ -2263,25 +2282,29 @@
              verifyCompatibleDims(lhsType.getDimSize(1),
                                   rhsType.getDimSize(0))) {
     // matrix dot vector
-    dimensions.push_back(lhsType.getDimSize(0));
+    pushDimensionAndBoundSize(dimensions, bounds, 0, lhsType, lhsBounds);
   } else if (1 == lhsType.getRank() && 2 == rhsType.getRank() &&
              verifyCompatibleDims(lhsType.getDimSize(0),
                                   rhsType.getDimSize(0))) {
     // vector dot matrix
-    dimensions.push_back(rhsType.getDimSize(1));
+    pushDimensionAndBoundSize(dimensions, bounds, 1, rhsType, rhsBounds);
   } else if (2 == lhsType.getRank() && 2 == rhsType.getRank() &&
              verifyCompatibleDims(lhsType.getDimSize(1),
                                   rhsType.getDimSize(0))) {
     // matrix dot matrix
-    dimensions.push_back(lhsType.getDimSize(0));
-    dimensions.push_back(rhsType.getDimSize(1));
+    pushDimensionAndBoundSize(dimensions, bounds, 0, lhsType, lhsBounds);
+    pushDimensionAndBoundSize(dimensions, bounds, 1, rhsType, rhsBounds);
   } else {
     return emitOptionalError(location,
                              "expected both lhs/rhs ranks to be "
                              "either 1 or 2");
   }
 
-  inferredReturnShapes.emplace_back(dimensions);
+  auto encoding =
+      lhsType.getEncoding() ? lhsType.getEncoding() : rhsType.getEncoding();
+  auto boundsAttr = boundsToEncoding(encoding, bounds);
+  inferredReturnShapes.emplace_back(dimensions, /*elementType=*/nullptr,
+                                    boundsAttr);
   return success();
 }
 
diff --ruN a/stablehlo/stablehlo/dialect/Version.cpp b/stablehlo/stablehlo/dialect/Version.cpp
--- stablehlo/stablehlo/dialect/Version.cpp
+++ stablehlo/stablehlo/dialect/Version.cpp
@@ -83,7 +83,7 @@
     case CompatibilityRequirement::NONE:
       return Version::getCurrentVersion();
     case CompatibilityRequirement::WEEK_4:
-      return Version(1, 10, 9);  // WEEK_4 ANCHOR: DO NOT MODIFY
+      return Version(1, 11, 0);  // WEEK_4 ANCHOR: DO NOT MODIFY
     case CompatibilityRequirement::WEEK_12:
       return Version(1, 10, 3);  // WEEK_12 ANCHOR: DO NOT MODIFY
     case CompatibilityRequirement::MAX:
diff --ruN a/stablehlo/stablehlo/integrations/c/CMakeLists.txt b/stablehlo/stablehlo/integrations/c/CMakeLists.txt
--- stablehlo/stablehlo/integrations/c/CMakeLists.txt
+++ stablehlo/stablehlo/integrations/c/CMakeLists.txt
@@ -38,6 +38,7 @@
   StablehloTypes.cpp
   StablehloDialectApi.cpp
   StablehloUnifiedApi.cpp
+  InterpretDialect.cpp
 
   LINK_LIBS PUBLIC
   MLIRCAPIIR
@@ -50,6 +51,7 @@
   StablehloReferenceConfiguration
   StablehloSerialization
   Version
+  InterpreterOps
 )
 
 add_mlir_public_c_api_library(VhloCAPI
diff --ruN a/stablehlo/stablehlo/integrations/c/InterpreterDialect.cpp b/stablehlo/stablehlo/integrations/c/InterpreterDialect.cpp
--- stablehlo/stablehlo/integrations/c/InterpreterDialect.cpp
+++ stablehlo/stablehlo/integrations/c/InterpreterDialect.cpp
@@ -0,0 +1,20 @@
+/* Copyright 2021 The TensorFlow Authors. All Rights Reserved.
+   Copyright 2022 The StableHLO Authors.
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+    http://www.apache.org/licenses/LICENSE-2.0
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+==============================================================================*/
+
+#include "stablehlo/integrations/c/InterpreterDialect.h"
+
+#include "mlir/CAPI/Registration.h"
+#include "stablehlo/reference/InterpreterOps.h"
+
+MLIR_DEFINE_CAPI_DIALECT_REGISTRATION(
+    Interpreter, interpreter, mlir::stablehlo::interpreter::InterpreterDialect)
diff --ruN a/stablehlo/stablehlo/integrations/c/InterpreterDialect.h b/stablehlo/stablehlo/integrations/c/InterpreterDialect.h
--- stablehlo/stablehlo/integrations/c/InterpreterDialect.h
+++ stablehlo/stablehlo/integrations/c/InterpreterDialect.h
@@ -0,0 +1,30 @@
+/* Copyright 2021 The TensorFlow Authors. All Rights Reserved.
+   Copyright 2022 The StableHLO Authors.
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+    http://www.apache.org/licenses/LICENSE-2.0
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+==============================================================================*/
+
+#ifndef STABLEHLO_INTEGRATIONS_C_INTERPRETER_DIALECT_H
+#define STABLEHLO_INTEGRATIONS_C_INTERPRETER_DIALECT_H
+
+#include "mlir-c/IR.h"
+#include "mlir-c/RegisterEverything.h"
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+MLIR_DECLARE_CAPI_DIALECT_REGISTRATION(Interpreter, interpreter);
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif  // STABLEHLO_INTEGRATIONS_C_INTERPRETER_DIALECT_H
diff --ruN a/stablehlo/stablehlo/integrations/c/StablehloUnifiedApi.cpp b/stablehlo/stablehlo/integrations/c/StablehloUnifiedApi.cpp
--- stablehlo/stablehlo/integrations/c/StablehloUnifiedApi.cpp
+++ stablehlo/stablehlo/integrations/c/StablehloUnifiedApi.cpp
@@ -32,13 +32,16 @@
 #include "stablehlo/reference/Configuration.h"
 
 MlirAttribute stablehloEvalModule(MlirModule module, int nArgs,
-                                  MlirAttribute const *args, int *errorCode) {
+                                  MlirAttribute const *args,
+                                  const char* const probeInstrumentationDir,
+                                  int *errorCode) {
   std::vector<mlir::DenseElementsAttr> inputs;
   inputs.reserve(nArgs);
   for (int i = 0; i < nArgs; ++i) {
     inputs.push_back(llvm::cast<mlir::DenseElementsAttr>(unwrap(args[i])));
   }
   mlir::stablehlo::InterpreterConfiguration config;
+  config.probeInstrumentationDir = probeInstrumentationDir;
   mlir::FailureOr<llvm::SmallVector<mlir::DenseElementsAttr>> results =
       mlir::stablehlo::evalModule(unwrap(module), inputs, config);
   if (mlir::failed(results)) {
diff --ruN a/stablehlo/stablehlo/integrations/c/StablehloUnifiedApi.h b/stablehlo/stablehlo/integrations/c/StablehloUnifiedApi.h
--- stablehlo/stablehlo/integrations/c/StablehloUnifiedApi.h
+++ stablehlo/stablehlo/integrations/c/StablehloUnifiedApi.h
@@ -26,10 +26,9 @@
 // Entrypoint for calling the StableHLO reference interpreter.
 // Returns an array attribute of dense element attributes for results.
 // Sets error code to non-zero on failure.
-MLIR_CAPI_EXPORTED MlirAttribute stablehloEvalModule(MlirModule module,
-                                                     int nArgs,
-                                                     MlirAttribute const* args,
-                                                     int* errorCode);
+MLIR_CAPI_EXPORTED MlirAttribute
+stablehloEvalModule(MlirModule module, int nArgs, MlirAttribute const* args,
+                    const char* probeInstrumentationDir, int* errorCode);
 
 #ifdef __cplusplus
 }
diff --ruN a/stablehlo/stablehlo/integrations/python/StablehloApi.cpp b/stablehlo/stablehlo/integrations/python/StablehloApi.cpp
--- stablehlo/stablehlo/integrations/python/StablehloApi.cpp
+++ stablehlo/stablehlo/integrations/python/StablehloApi.cpp
@@ -146,8 +146,9 @@
   //
   m.def(
       "eval_module",
-      [](MlirModule module,
-         std::vector<MlirAttribute> &args) -> std::vector<MlirAttribute> {
+      [](MlirModule module, std::vector<MlirAttribute> &args,
+         const std::string &probe_instrumentation_dir)
+          -> std::vector<MlirAttribute> {
         for (auto arg : args) {
           if (!mlirAttributeIsADenseElements(arg)) {
             throw nb::value_error("input args must be DenseElementsAttr");
@@ -156,7 +157,8 @@
 
         int errorCode(0);
         MlirAttribute resultArrayAttr =
-            stablehloEvalModule(module, args.size(), args.data(), &errorCode);
+            stablehloEvalModule(module, args.size(), args.data(),
+                                probe_instrumentation_dir.c_str(), &errorCode);
 
         if (errorCode != 0) {
           throw nb::value_error("interpreter failed");
@@ -168,7 +170,8 @@
         }
         return pyResults;
       },
-      nb::arg("module"), nb::arg("args"));
+      nb::arg("module"), nb::arg("args"),
+      nb::arg("probe_instrumentation_dir") = "");
 }
 
 void AddPortableApi(nb::module_ &m) {
diff --ruN a/stablehlo/stablehlo/integrations/python/StablehloModule.cpp b/stablehlo/stablehlo/integrations/python/StablehloModule.cpp
--- stablehlo/stablehlo/integrations/python/StablehloModule.cpp
+++ stablehlo/stablehlo/integrations/python/StablehloModule.cpp
@@ -19,6 +19,7 @@
 #include "nanobind/nanobind.h"
 #include "nanobind/stl/string.h"
 #include "nanobind/stl/vector.h"
+#include "stablehlo/integrations/c/InterpreterDialect.h"
 #include "stablehlo/integrations/c/StablehloAttributes.h"
 #include "stablehlo/integrations/c/StablehloDialect.h"
 #include "stablehlo/integrations/c/StablehloPasses.h"
@@ -59,6 +60,17 @@
       "register_dialect",
       [](MlirContext context, bool load) {
         MlirDialectHandle dialect = mlirGetDialectHandle__stablehlo__();
+        mlirDialectHandleRegisterDialect(dialect, context);
+        if (load) {
+          mlirDialectHandleLoadDialect(dialect, context);
+        }
+      },
+      nb::arg("context"), nb::arg("load") = true);
+
+  m.def(
+      "register_interpreter_dialect",
+      [](MlirContext context, bool load) {
+        MlirDialectHandle dialect = mlirGetDialectHandle__interpreter__();
         mlirDialectHandleRegisterDialect(dialect, context);
         if (load) {
           mlirDialectHandleLoadDialect(dialect, context);
diff --ruN a/stablehlo/stablehlo/integrations/python/mlir/dialects/InterpreterOps.td b/stablehlo/stablehlo/integrations/python/mlir/dialects/InterpreterOps.td
--- stablehlo/stablehlo/integrations/python/mlir/dialects/InterpreterOps.td
+++ stablehlo/stablehlo/integrations/python/mlir/dialects/InterpreterOps.td
@@ -0,0 +1,22 @@
+/* Copyright 2021 The TensorFlow Authors. All Rights Reserved.
+   Copyright 2022 The StableHLO Authors.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+==============================================================================*/
+
+#ifndef STABLEHLO_INTEGRATIONS_PYTHON_INTERPRETER_OPS
+#define STABLEHLO_INTEGRATIONS_PYTHON_INTERPRETER_OPS
+
+include "third_party/stablehlo/stablehlo/reference/InterpreterOps.h"
+
+#endif
diff --ruN a/stablehlo/stablehlo/integrations/python/tests/stablehlo.py b/stablehlo/stablehlo/integrations/python/tests/stablehlo.py
--- stablehlo/stablehlo/integrations/python/tests/stablehlo.py
+++ stablehlo/stablehlo/integrations/python/tests/stablehlo.py
@@ -18,7 +18,9 @@
 # pylint: disable=wildcard-import,undefined-variable
 
 import io
+import os
 import re
+import tempfile
 from mlir import ir
 from mlir import passmanager as pm
 from mlir.dialects import stablehlo
@@ -28,6 +30,7 @@
 def run(f):
   with ir.Context() as context:
     stablehlo.register_dialect(context)
+    stablehlo.register_interpreter_dialect(context)
     f()
   return f
 
@@ -44,7 +47,7 @@
 def test_comparison_direction_attr():
   attr = stablehlo.ComparisonDirectionAttr.get("EQ")
   assert attr is not None
-  assert str(attr) == ("#stablehlo<comparison_direction EQ>")
+  assert str(attr) == "#stablehlo<comparison_direction EQ>"
   assert attr.value == "EQ"
 
 
@@ -52,7 +55,7 @@
 def test_comparison_type_attr():
   attr = stablehlo.ComparisonTypeAttr.get("FLOAT")
   assert attr is not None
-  assert str(attr) == ("#stablehlo<comparison_type FLOAT>")
+  assert str(attr) == "#stablehlo<comparison_type FLOAT>"
   assert attr.value == "FLOAT"
 
 
@@ -67,9 +70,11 @@
       kernel_spatial_dimensions=[2, 3],
       output_batch_dimension=0,
       output_feature_dimension=1,
-      output_spatial_dimensions=[2, 3])
-  assert str(attr) == ("#stablehlo.conv<[b, f, 0, 1, 2]x[i, o, 0, 1]->"
-                       "[b, f, 0, 1]>")
+      output_spatial_dimensions=[2, 3],
+  )
+  assert str(attr) == (
+      "#stablehlo.conv<[b, f, 0, 1, 2]x[i, o, 0, 1]->[b, f, 0, 1]>"
+  )
   assert attr is not None
   assert attr.input_batch_dimension == 0
   assert attr.input_feature_dimension == 1
@@ -92,13 +97,16 @@
       lhs_component_count=1,
       rhs_component_count=1,
       num_primitive_operations=3,
-      allow_imprecise_accumulation=False)
-  assert attr is not None
-  assert str(attr) == ("#stablehlo.dot_algorithm<lhs_precision_type = bf16, "
-                       "rhs_precision_type = bf16, accumulation_type = f32, "
-                       "lhs_component_count = 1, rhs_component_count = 1, "
-                       "num_primitive_operations = 3, "
-                       "allow_imprecise_accumulation = false>")
+      allow_imprecise_accumulation=False,
+  )
+  assert attr is not None
+  assert str(attr) == (
+      "#stablehlo.dot_algorithm<lhs_precision_type = bf16, "
+      "rhs_precision_type = bf16, accumulation_type = f32, "
+      "lhs_component_count = 1, rhs_component_count = 1, "
+      "num_primitive_operations = 3, "
+      "allow_imprecise_accumulation = false>"
+  )
   assert isinstance(attr.lhs_precision_type, ir.BF16Type)
   assert isinstance(attr.rhs_precision_type, ir.BF16Type)
   assert isinstance(attr.accumulation_type, ir.F32Type)
@@ -114,12 +122,15 @@
       lhs_batching_dimensions=[0, 1],
       rhs_batching_dimensions=[2, 3],
       lhs_contracting_dimensions=[4, 5],
-      rhs_contracting_dimensions=[6, 7])
-  assert attr is not None
-  assert str(attr) == ("#stablehlo.dot<lhs_batching_dimensions = [0, 1], "
-                       "rhs_batching_dimensions = [2, 3], "
-                       "lhs_contracting_dimensions = [4, 5], "
-                       "rhs_contracting_dimensions = [6, 7]>")
+      rhs_contracting_dimensions=[6, 7],
+  )
+  assert attr is not None
+  assert str(attr) == (
+      "#stablehlo.dot<lhs_batching_dimensions = [0, 1], "
+      "rhs_batching_dimensions = [2, 3], "
+      "lhs_contracting_dimensions = [4, 5], "
+      "rhs_contracting_dimensions = [6, 7]>"
+  )
   assert attr.lhs_batching_dimensions == [0, 1]
   assert attr.rhs_batching_dimensions == [2, 3]
   assert attr.lhs_contracting_dimensions == [4, 5]
@@ -130,7 +141,7 @@
 def test_fft_type_attr():
   attr = stablehlo.FftTypeAttr.get("FFT")
   assert attr is not None
-  assert str(attr) == ("#stablehlo<fft_type FFT>")
+  assert str(attr) == "#stablehlo<fft_type FFT>"
   assert attr.value == "FFT"
 
 
@@ -164,13 +175,14 @@
 @run
 def test_output_operand_alias():
   attr = stablehlo.OutputOperandAlias.get(
-      output_tuple_indices=[0],
-      operand_index=0,
-      operand_tuple_indices=[1])
-  assert attr is not None
-  assert str(attr) == ("#stablehlo.output_operand_alias<output_tuple_indices = [0], "
-                       "operand_index = 0, "
-                       "operand_tuple_indices = [1]>")
+      output_tuple_indices=[0], operand_index=0, operand_tuple_indices=[1]
+  )
+  assert attr is not None
+  assert str(attr) == (
+      "#stablehlo.output_operand_alias<output_tuple_indices = [0], "
+      "operand_index = 0, "
+      "operand_tuple_indices = [1]>"
+  )
   assert attr.output_tuple_indices == [0]
   assert attr.operand_index == 0
   assert attr.operand_tuple_indices == [1]
@@ -180,7 +192,7 @@
 def test_precision_attr():
   attr = stablehlo.PrecisionAttr.get("DEFAULT")
   assert attr is not None
-  assert str(attr) == ("#stablehlo<precision DEFAULT>")
+  assert str(attr) == "#stablehlo<precision DEFAULT>"
   assert attr.value == "DEFAULT"
 
 
@@ -188,7 +200,7 @@
 def test_rng_algorithm_attr():
   attr = stablehlo.RngAlgorithmAttr.get("DEFAULT")
   assert attr is not None
-  assert str(attr) == ("#stablehlo<rng_algorithm DEFAULT>")
+  assert str(attr) == "#stablehlo<rng_algorithm DEFAULT>"
   assert attr.value == "DEFAULT"
 
 
@@ -196,7 +208,7 @@
 def test_rng_distribution_attr():
   attr = stablehlo.RngDistributionAttr.get("UNIFORM")
   assert attr is not None
-  assert str(attr) == ("#stablehlo<rng_distribution UNIFORM>")
+  assert str(attr) == "#stablehlo<rng_distribution UNIFORM>"
   assert attr.value == "UNIFORM"
 
 
@@ -231,7 +243,7 @@
 def test_transpose_attr():
   attr = stablehlo.TransposeAttr.get("TRANSPOSE")
   assert attr is not None
-  assert str(attr) == ("#stablehlo<transpose TRANSPOSE>")
+  assert str(attr) == "#stablehlo<transpose TRANSPOSE>"
   assert attr.value == "TRANSPOSE"
 
 
@@ -293,24 +305,32 @@
 }}
 """
 
+_ASM_FORMAT_WITH_PROBE = r"""
+func.func @test(%arg0: tensor<{0}>) -> tensor<{0}> {{
+  %0 = stablehlo.add %arg0, %arg0 : (tensor<{0}>, tensor<{0}>) -> tensor<{0}>
+  %1 = interpreter.probe %0, probe_id = "probe0" : tensor<{0}>
+  func.return %1 : tensor<{0}>
+}}
+"""
+
 
 @run
 def test_reference_api():
   # Formatted as (tensor_type, np_value)
   # Program runs arg + arg, which is used for expected value
   tests = [
-    # No numpy types for f8 - skipping fp8 tests
-    ("f16", np.asarray(1, np.float16)),
-    ("f32", np.asarray(2, np.float32)),
-    ("f64", np.asarray(3, np.double)),
-    ("1xi8", np.asarray([4], np.int8)),
-    ("1xi16", np.asarray([5], np.int16)),
-    ("1xi32", np.asarray([-6], np.int32)),
-    # Numpy's uint treated as int by DenseElementsAttr, skipping np.uint tests
-    ("2x2xf16", np.asarray([1, 2, 3, 4], np.float16).reshape(2,2)),
-    ("2x1x2xf16", np.asarray([1, 2, 3, 4], np.float16).reshape(2,1,2)),
-    ("?x?xf16", np.asarray([1, 2, 3, 4], np.float16).reshape(2,2)),
-    ("?x2xf16", np.asarray([1, 2, 3, 4], np.float16).reshape(2,2)),
+      # No numpy types for f8 - skipping fp8 tests
+      ("f16", np.asarray(1, np.float16)),
+      ("f32", np.asarray(2, np.float32)),
+      ("f64", np.asarray(3, np.double)),
+      ("1xi8", np.asarray([4], np.int8)),
+      ("1xi16", np.asarray([5], np.int16)),
+      ("1xi32", np.asarray([-6], np.int32)),
+      # Numpy's uint treated as int by DenseElementsAttr, skipping np.uint tests
+      ("2x2xf16", np.asarray([1, 2, 3, 4], np.float16).reshape(2, 2)),
+      ("2x1x2xf16", np.asarray([1, 2, 3, 4], np.float16).reshape(2, 1, 2)),
+      ("?x?xf16", np.asarray([1, 2, 3, 4], np.float16).reshape(2, 2)),
+      ("?x2xf16", np.asarray([1, 2, 3, 4], np.float16).reshape(2, 2)),
   ]
   for test in tests:
     tensor_type, arg = test
@@ -390,20 +410,45 @@
 
 @run
 def test_result_accuracy_attr_default():
-  attr = stablehlo.ResultAccuracyAttr.get(atol=0, rtol=0, ulps=0, mode="DEFAULT")
+  attr = stablehlo.ResultAccuracyAttr.get(
+      atol=0, rtol=0, ulps=0, mode="DEFAULT"
+  )
   assert attr is not None
   assert attr.mode == "DEFAULT"
   assert attr.atol == 0
   assert attr.rtol == 0
   assert attr.ulps == 0
 
+
 @run
 def test_result_accuracy_attr_tolerance():
-  attr = stablehlo.ResultAccuracyAttr.get(atol=1e-5, rtol=1.0,
-                                          ulps=2, mode="TOLERANCE")
+  attr = stablehlo.ResultAccuracyAttr.get(
+      atol=1e-5, rtol=1.0, ulps=2, mode="TOLERANCE"
+  )
   assert attr is not None
   assert attr.mode == "TOLERANCE"
   assert attr.atol == 1e-5
   assert attr.rtol == 1.0
   assert attr.ulps == 2
 
+
+@run
+def test_reference_api_with_probe():
+  """Tests that probe files are created in the specified directory."""
+  test_tmpdir_base = os.environ.get("TEST_TMPDIR")
+  with tempfile.TemporaryDirectory(dir=test_tmpdir_base) as tmpdir:
+    tensor_type = "f32"
+    arg = np.asarray(2, np.float32)
+    m = ir.Module.parse(_ASM_FORMAT_WITH_PROBE.format(tensor_type))
+    args = [ir.DenseElementsAttr.get(arg)]
+
+    # Call eval_module, directing probe outputs to the temporary directory.
+    stablehlo.eval_module(m, args, probe_instrumentation_dir=tmpdir)
+
+    # Verify that the expected probe files were created.
+    probe_file = os.path.join(tmpdir, "probe1.npy")
+    metadata_file = os.path.join(tmpdir, "index.csv")
+    assert os.path.exists(probe_file), f"Probe file not found: {probe_file}"
+    assert os.path.exists(
+        metadata_file
+    ), f"Metadata file not found: {metadata_file}"
diff --ruN a/stablehlo/stablehlo/tests/infer_stablehlo.mlir b/stablehlo/stablehlo/tests/infer_stablehlo.mlir
--- stablehlo/stablehlo/tests/infer_stablehlo.mlir
+++ stablehlo/stablehlo/tests/infer_stablehlo.mlir
@@ -1804,6 +1804,15 @@
 
 // -----
 
+// CHECK-LABEL: func @dot_bounds
+func.func @dot_bounds(%arg0: tensor<?x12xf32, #stablehlo.bounds<64, ?>>, %arg1: tensor<12x?xf32, #stablehlo.bounds<?, 64>>) -> tensor<?x?xf32, #stablehlo.bounds<64, 64>> {
+  %0 = stablehlo.dot %arg0, %arg1, precision = [HIGHEST, HIGHEST] : (tensor<?x12xf32, #stablehlo.bounds<64, ?>>, tensor<12x?xf32, #stablehlo.bounds<?, 64>>) -> tensor<?x?xf32, #stablehlo.bounds<64, 64>>
+  // CHECK: return {{.*}} : tensor<?x?xf32, #stablehlo.bounds<64, 64>>
+  return %0 : tensor<?x?xf32, #stablehlo.bounds<64, 64>>
+}
+
+// -----
+
 // CHECK-LABEL: func @dot_general_c12
 // CHECK-SAME: (%[[ARG0:.*]]: tensor<?x?x?xf32>, %[[ARG1:.*]]: tensor<?x?x?xf32>
 func.func @dot_general_c12(%arg0: tensor<?x?x?xf32>, %arg1: tensor<?x?x?xf32>) -> tensor<3xindex> {
diff --ruN a/stablehlo/stablehlo/tests/transforms/stablehlo_aggressive_folder.mlir b/stablehlo/stablehlo/tests/transforms/stablehlo_aggressive_folder.mlir
--- stablehlo/stablehlo/tests/transforms/stablehlo_aggressive_folder.mlir
+++ stablehlo/stablehlo/tests/transforms/stablehlo_aggressive_folder.mlir
@@ -246,6 +246,9 @@
 
 // -----
 
+////////
+// ConvertOp
+
 // CHECK-LABEL: func @eval_convert_f32_to_i64
 func.func @eval_convert_f32_to_i64() -> tensor<2xi64> {
   // CHECK-NOT: stablehlo.convert
@@ -254,6 +257,42 @@
   %0 = stablehlo.constant dense<[1.0, 2.0]> : tensor<2xf32>
   %1 = stablehlo.convert %0 : (tensor<2xf32>) -> tensor<2xi64>
   func.return %1 : tensor<2xi64>
+}
+
+// CHECK-LABEL: func @eval_convert_bool_f32
+func.func @eval_convert_bool_f32() -> tensor<2xf32> {
+  // CHECK-NEXT: [[CST:%.+]] = stablehlo.constant dense<[0.000000e+00, 1.000000e+00]> : tensor<2xf32>
+  %cst = stablehlo.constant dense<[0, 1]> : tensor<2xi1>
+  %0 = stablehlo.convert %cst : (tensor<2xi1>) -> tensor<2xf32>
+  // CHECK-NEXT: return [[CST]]
+  func.return %0 : tensor<2xf32>
+}
+
+// CHECK-LABEL: func @eval_convert_bool_i32
+func.func @eval_convert_bool_i32() -> tensor<2xi32> {
+  // CHECK-NEXT: [[CST:%.+]] = stablehlo.constant dense<[0, 1]> : tensor<2xi32>
+  %cst = stablehlo.constant dense<[0, 1]> : tensor<2xi1>
+  %0 = stablehlo.convert %cst : (tensor<2xi1>) -> tensor<2xi32>
+  // CHECK-NEXT: return [[CST]]
+  func.return %0 : tensor<2xi32>
+}
+
+// CHECK-LABEL: func @eval_convert_i32_bool
+func.func @eval_convert_i32_bool() -> tensor<3xi1> {
+  // CHECK-NEXT: [[CST:%.+]] = stablehlo.constant dense<[false, true, true]> : tensor<3xi1>
+  %cst = stablehlo.constant dense<[0, 1, 10]> : tensor<3xi32>
+  %0 = stablehlo.convert %cst : (tensor<3xi32>) -> tensor<3xi1>
+  // CHECK-NEXT: return [[CST]]
+  func.return %0 : tensor<3xi1>
+}
+
+// CHECK-LABEL: func @eval_convert_f32_bool
+func.func @eval_convert_f32_bool() -> tensor<4xi1> {
+  // CHECK-NEXT: [[CST:%.+]] = stablehlo.constant dense<[true, false, true, true]> : tensor<4xi1>
+  %cst = stablehlo.constant dense<[-1.0, 0.0, 1.0, 10.0]> : tensor<4xf32>
+  %0 = stablehlo.convert %cst : (tensor<4xf32>) -> tensor<4xi1>
+  // CHECK-NEXT: return [[CST]]
+  func.return %0 : tensor<4xi1>
 }
 
 // -----
diff --ruN a/stablehlo/stablehlo/transforms/optimization/StablehloAggressiveFolder.cpp b/stablehlo/stablehlo/transforms/optimization/StablehloAggressiveFolder.cpp
--- stablehlo/stablehlo/transforms/optimization/StablehloAggressiveFolder.cpp
+++ stablehlo/stablehlo/transforms/optimization/StablehloAggressiveFolder.cpp
@@ -200,8 +200,11 @@
   auto newType = getElementTypeOrSelf(resultType);
   size_t newBitWidth = newType.getIntOrFloatBitWidth();
 
-  bool isOldTypeUnsigned = oldType.isInteger(1) || oldType.isUnsignedInteger();
-  bool isNewTypeUnsigned = newType.isInteger(1) || newType.isUnsignedInteger();
+  bool isOldTypeUnsigned =
+      oldType.isSignlessInteger(1) || oldType.isUnsignedInteger();
+  bool isNewTypeUnsigned =
+      newType.isSignlessInteger(1) || newType.isUnsignedInteger();
+  bool isNewTypeBoolean = newType.isSignlessInteger(1);
 
   if (isa<FloatType>(oldType)) {
     if (auto newFloatType = dyn_cast<FloatType>(newType)) {
@@ -217,6 +220,16 @@
                                           llvm::RoundingMode::NearestTiesToEven,
                                           &losesInfo);
             return newValue;
+          });
+    }
+
+    // Float -> Boolean
+    if (isNewTypeBoolean) {
+      return foldConvertHelper<FloatAttr, IntegerAttr>(
+          rewriter, op, elements, resultType,
+          [newBitWidth](const APFloat& operand, bool& /*castStatus*/) {
+            APInt resVal(1, operand.isZero() ? 0 : 1);
+            return resVal.sextOrTrunc(newBitWidth);
           });
     }
 
@@ -249,6 +262,16 @@
           apf.convertFromAPInt(operand, !isOldTypeUnsigned,
                                APFloat::rmNearestTiesToEven);
           return apf;
+        });
+  }
+
+  // Int -> Boolean
+  if (isNewTypeBoolean) {
+    return foldConvertHelper<IntegerAttr, IntegerAttr>(
+        rewriter, op, elements, resultType,
+        [newBitWidth](const APInt& operand, bool& /*castStatus*/) {
+          APInt resVal(1, operand.isZero() ? 0 : 1);
+          return resVal.sextOrTrunc(newBitWidth);
         });
   }
 

