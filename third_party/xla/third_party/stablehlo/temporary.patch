diff --ruN a/stablehlo/stablehlo/conversions/linalg/transforms/MapStablehloToScalarOp.h b/stablehlo/stablehlo/conversions/linalg/transforms/MapStablehloToScalarOp.h
--- stablehlo/stablehlo/conversions/linalg/transforms/MapStablehloToScalarOp.h
+++ stablehlo/stablehlo/conversions/linalg/transforms/MapStablehloToScalarOp.h
@@ -499,7 +499,7 @@
   expBitsMask = ((expBitsMask << srcExponentBits) - 1) << srcMantissaBits;
 
   auto createConstant = [&](const APInt &v) {
-    return b.create<arith::ConstantIntOp>(v.getZExtValue(), intType)
+    return b.create<arith::ConstantIntOp>(intType, v.getZExtValue())
         .getResult();
   };
 
@@ -520,7 +520,7 @@
     APInt baseRoundingBias = lastMantissaBitMask.lshr(1) - 1;
 
     Value mantissaDiff = b.create<arith::ConstantIntOp>(
-        srcMantissaBits - destMantissaBits, intType);
+        intType, srcMantissaBits - destMantissaBits);
     Value highestMantissaMaskVal = createConstant(lastMantissaBitMask);
     Value baseRoundingBiasVal = createConstant(baseRoundingBias);
     Value xLastMantissaBit = b.create<arith::ShRUIOp>(
diff --ruN a/stablehlo/stablehlo/conversions/linalg/transforms/StablehloToLinalgConvolution.cpp b/stablehlo/stablehlo/conversions/linalg/transforms/StablehloToLinalgConvolution.cpp
--- stablehlo/stablehlo/conversions/linalg/transforms/StablehloToLinalgConvolution.cpp
+++ stablehlo/stablehlo/conversions/linalg/transforms/StablehloToLinalgConvolution.cpp
@@ -579,8 +579,9 @@
                 /*bodyBuild=*/
                 [&](OpBuilder &nestedBuilder, Location nestedLoc, ValueRange) {
                   ImplicitLocOpBuilder builder(nestedLoc, nestedBuilder);
-                  linalg::Conv2DOp::regionBuilder(
-                      builder, *builder.getInsertionBlock(), {});
+                  linalg::Conv2DOp::regionBuilder(builder,
+                                                  *builder.getInsertionBlock(),
+                                                  {}, /*emitError=*/{});
                 },
                 linalg::getPrunedAttributeList(op))
             .getResult(0);
diff --ruN a/stablehlo/stablehlo/conversions/linalg/transforms/StablehloToLinalgDotProduct.cpp b/stablehlo/stablehlo/conversions/linalg/transforms/StablehloToLinalgDotProduct.cpp
--- stablehlo/stablehlo/conversions/linalg/transforms/StablehloToLinalgDotProduct.cpp
+++ stablehlo/stablehlo/conversions/linalg/transforms/StablehloToLinalgDotProduct.cpp
@@ -299,7 +299,8 @@
             /*nReduction=*/numContracting),
         [](OpBuilder &b, Location loc, ValueRange) {
           ImplicitLocOpBuilder builder(loc, b);
-          linalg::MatmulOp::regionBuilder(builder, *b.getInsertionBlock(), {});
+          linalg::MatmulOp::regionBuilder(builder, *b.getInsertionBlock(), {},
+                                          /*emitError=*/{});
         },
         linalg::getPrunedAttributeList(op));
 
diff --ruN a/stablehlo/stablehlo/dialect/StablehloAttrs.td b/stablehlo/stablehlo/dialect/StablehloAttrs.td
--- stablehlo/stablehlo/dialect/StablehloAttrs.td
+++ stablehlo/stablehlo/dialect/StablehloAttrs.td
@@ -222,6 +222,15 @@
   let hasCustomAssemblyFormat = 1;
   let genVerifyDecl = 1;
   let constBuilderCall = "::mlir::stablehlo::ResultAccuracyAttr::get($_builder.getContext(), APFloat(0.0), APFloat(0.0), 0, ::mlir::stablehlo::ResultAccuracyModeAttr::get($_builder.getContext(), $0))";
+  let builders = [
+    AttrOrTypeBuilder<(ins)>,
+    AttrOrTypeBuilder<(ins
+      "mlir::stablehlo::ResultAccuracyMode":$mode)>,
+    AttrOrTypeBuilder<(ins
+      "APFloat":$atol,
+      "APFloat":$rtol,
+      "int64_t":$ulps)>
+  ];
 }
 
 #endif // STABLEHLO_DIALECT_STABLEHLO_ATTRS
diff --ruN a/stablehlo/stablehlo/dialect/StablehloOps.cpp b/stablehlo/stablehlo/dialect/StablehloOps.cpp
--- stablehlo/stablehlo/dialect/StablehloOps.cpp
+++ stablehlo/stablehlo/dialect/StablehloOps.cpp
@@ -129,6 +129,36 @@
       getBounds(), RankedTensorType::get(shape, elementType), emitError);
 }
 
+ArrayAttr PrecisionConfigAttr::get(MLIRContext* context,
+                                   ArrayRef<Precision> precisions) {
+  SmallVector<Attribute> precisionAttrs =
+      llvm::map_to_vector(precisions, [&](Precision precision) -> Attribute {
+        return PrecisionAttr::get(context, precision);
+      });
+  return ArrayAttr::get(context, precisionAttrs);
+}
+
+//===----------------------------------------------------------------------===//
+// Attributes
+//===----------------------------------------------------------------------===//
+
+ResultAccuracyAttr ResultAccuracyAttr::get(MLIRContext* context) {
+  return get(context, ResultAccuracyMode::DEFAULT);
+}
+
+ResultAccuracyAttr ResultAccuracyAttr::get(MLIRContext* context,
+                                           ResultAccuracyMode mode) {
+  auto modeAttr = ResultAccuracyModeAttr::get(context, mode);
+  return get(context, APFloat(0.0), APFloat(0.0), 0, modeAttr);
+}
+
+ResultAccuracyAttr ResultAccuracyAttr::get(MLIRContext* context, APFloat atol,
+                                           APFloat rtol, int64_t ulps) {
+  auto modeAttr =
+      ResultAccuracyModeAttr::get(context, ResultAccuracyMode::TOLERANCE);
+  return get(context, atol, rtol, ulps, modeAttr);
+}
+
 //===----------------------------------------------------------------------===//
 // ReduceScatterOp
 //===----------------------------------------------------------------------===//
diff --ruN a/stablehlo/stablehlo/dialect/StablehloOps.h b/stablehlo/stablehlo/dialect/StablehloOps.h
--- stablehlo/stablehlo/dialect/StablehloOps.h
+++ stablehlo/stablehlo/dialect/StablehloOps.h
@@ -40,6 +40,7 @@
 #include "mlir/IR/Types.h"
 #include "mlir/Interfaces/InferTypeOpInterface.h"
 #include "mlir/Interfaces/SideEffectInterfaces.h"
+#include "mlir/Support/LLVM.h"
 #include "mlir/Support/LogicalResult.h"
 #include "stablehlo/dialect/Base.h"
 #include "stablehlo/dialect/Version.h"
@@ -179,7 +180,8 @@
 template <typename OpTy>
 void buildReduceBody(Type elementType, Region &body, OpBuilder &builder) {
   OpBuilder::InsertionGuard guard(builder);
-  Block *block = builder.createBlock(&body);
+  if (body.getBlocks().empty()) builder.createBlock(&body);
+  Block *block = &body.getBlocks().front();
 
   // Block arguments are scalars of the given element type.
   Type type = RankedTensorType::get(/*shape=*/{}, elementType);
@@ -191,6 +193,13 @@
   builder.create<stablehlo::ReturnOp>(loc, reducer.getResult());
 }
 
+// PrecisionConfigAttr is a constraint attribute on ArrayAttrs.
+// Create this class to allow for building this attr similar to other
+// attributes.
+struct PrecisionConfigAttr : public ArrayAttr {
+  static ArrayAttr get(MLIRContext *context, ArrayRef<Precision> precisions);
+};
+
 }  // end namespace stablehlo
 }  // end namespace mlir
 
diff --ruN a/stablehlo/stablehlo/dialect/TypeInference.cpp b/stablehlo/stablehlo/dialect/TypeInference.cpp
--- stablehlo/stablehlo/dialect/TypeInference.cpp
+++ stablehlo/stablehlo/dialect/TypeInference.cpp
@@ -957,12 +957,12 @@
 
 // Returns the types of the terminator arguments of the input  mlir::Block
 // 'block'.
-FailureOr<SmallVector<ShapedType>> getAccumulatorTypes(
-    std::optional<Location> loc, Region& region) {
-  if (region.empty()) {
-    return emitOptionalError(
-        loc, "Expects non-empty reduction block for type inference");
-  }
+// Falls back to using the input types if the region is not set.
+// If different precision body is required, don't use TypeInference APIs.
+SmallVector<ShapedType> getAccumulatorTypesOrInputTypes(
+    std::optional<Location> loc, Region& region,
+    ArrayRef<ShapedType> inputTypes) {
+  if (region.empty()) return llvm::to_vector(inputTypes);
 
   Block& block = region.front();
   return llvm::map_to_vector(
@@ -1894,12 +1894,11 @@
   auto inputArgTensorTypes = llvm::map_to_vector(
       inputTypes, [](Type t) { return cast<ShapedType>(t); });
   // all_reduce_c6, all_reduce_c7
-  auto accumulatorTypesOrErr = getAccumulatorTypes(location, computation);
-  if (failed(accumulatorTypesOrErr)) return failure();
+  auto accumulatorTypes = getAccumulatorTypesOrInputTypes(location, computation,
+                                                          inputArgTensorTypes);
   for (size_t inputIdx = 0; inputIdx < inputTypes.size(); ++inputIdx) {
-    inferredReturnShapes.emplace_back(
-        getSameShapeTensorType(inputArgTensorTypes[inputIdx],
-                               (*accumulatorTypesOrErr)[0].getElementType()));
+    inferredReturnShapes.emplace_back(getSameShapeTensorType(
+        inputArgTensorTypes[inputIdx], accumulatorTypes[0].getElementType()));
   }
 
   return success();
@@ -3089,10 +3088,10 @@
           location, inputArgTensorTypes, dimensions, newDimensions, encoding)))
     return failure();
   // reduce_c3, reduce_c7, reduce_c8
-  auto accumulatorTypesOrErr = getAccumulatorTypes(location, body);
-  if (failed(accumulatorTypesOrErr)) return failure();
+  auto accumulatorTypes =
+      getAccumulatorTypesOrInputTypes(location, body, inputArgTensorTypes);
   for (uint64_t inputIdx = 0; inputIdx < inputTypes.size(); ++inputIdx) {
-    Type elementType = (*accumulatorTypesOrErr)[inputIdx].getElementType();
+    Type elementType = accumulatorTypes[inputIdx].getElementType();
     inferredReturnShapes.emplace_back(newDimensions, elementType, encoding);
   }
 
@@ -3122,20 +3121,20 @@
     return failure();
 
   // reduce_window_c1, reduce_window_c14...reduce_window_c16
-  auto accumulatorTypesOrErr = getAccumulatorTypes(location, body);
-  if (failed(accumulatorTypesOrErr)) return failure();
+  auto accumulatorTypes =
+      getAccumulatorTypesOrInputTypes(location, body, inputTypes);
   for (size_t i = 0; i < inputTypes.size(); ++i) {
     auto inputRankedType = cast<RankedTensorType>(inputs[i].getType());
     auto resultShape =
         inferWindowOutputShape(inputTypes[i].getShape(), inferredWindow);
     auto inputBounds = encodingToBounds(inputRankedType.getEncoding());
     if (inputBounds.empty()) {
-      inferredReturnShapes.emplace_back(
-          resultShape, (*accumulatorTypesOrErr)[i].getElementType());
+      inferredReturnShapes.emplace_back(resultShape,
+                                        accumulatorTypes[i].getElementType());
     } else {
       auto resultBounds = inferWindowOutputShape(inputBounds, inferredWindow);
       inferredReturnShapes.emplace_back(
-          resultShape, (*accumulatorTypesOrErr)[i].getElementType(),
+          resultShape, accumulatorTypes[i].getElementType(),
           boundsToEncoding(inputRankedType.getEncoding(), resultBounds));
     }
   }
@@ -3196,12 +3195,14 @@
                              ValueRange inputs, Region& updateComputation,
                              SmallVectorImpl<Type>& inferredReturnTypes) {
   // scatter_c24, scatter_c25
-  auto accumulatorTypesOrErr = getAccumulatorTypes(location, updateComputation);
-  if (failed(accumulatorTypesOrErr)) return failure();
+  auto inputTypes = llvm::map_to_vector(
+      inputs.getTypes(), [](Type t) { return cast<ShapedType>(t); });
+  auto accumulatorTypes =
+      getAccumulatorTypesOrInputTypes(location, updateComputation, inputTypes);
   for (uint64_t inputIdx = 0; inputIdx < inputs.size(); ++inputIdx) {
     auto inputShapedTy = cast<ShapedType>(inputs[inputIdx].getType());
     inferredReturnTypes.push_back(getSameShapeTensorType(
-        inputShapedTy, (*accumulatorTypesOrErr)[inputIdx].getElementType()));
+        inputShapedTy, accumulatorTypes[inputIdx].getElementType()));
   }
   return success();
 }
@@ -3235,11 +3236,12 @@
     std::optional<Location> location, Value operand, Region& scatter,
     SmallVectorImpl<Type>& inferredReturnTypes) {
   // select_and_scatter_c11, select_and_scatter_c12
-  auto accumulatorTypesOrErr = getAccumulatorTypes(location, scatter);
-  if (failed(accumulatorTypesOrErr)) return failure();
+  auto inputType = cast<ShapedType>(operand.getType());
+  auto accumulatorTypes =
+      getAccumulatorTypesOrInputTypes(location, scatter, {inputType});
   auto operandShapedTy = cast<ShapedType>(operand.getType());
   inferredReturnTypes.push_back(getSameShapeTensorType(
-      operandShapedTy, (*accumulatorTypesOrErr)[0].getElementType()));
+      operandShapedTy, accumulatorTypes[0].getElementType()));
   return success();
 }
 
@@ -4618,13 +4620,12 @@
   }
 
   // reduce_scatter_c9
-  auto accumulatorTypesOrErr = getAccumulatorTypes(location, computation);
-  if (failed(accumulatorTypesOrErr)) return failure();
-  if (resultType.getElementType() !=
-      (*accumulatorTypesOrErr)[0].getElementType()) {
+  auto accumulatorTypes =
+      getAccumulatorTypesOrInputTypes(location, computation, {operandType});
+  if (resultType.getElementType() != accumulatorTypes[0].getElementType()) {
     return emitOptionalError(location, "result element-type is expected to be ",
-                             (*accumulatorTypesOrErr)[0].getElementType(),
-                             ", but got ", resultType.getElementType());
+                             accumulatorTypes[0].getElementType(), ", but got ",
+                             resultType.getElementType());
   }
 
   return success();

