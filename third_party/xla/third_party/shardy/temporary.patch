diff --git a/docs/sharding_representation.md b/docs/sharding_representation.md
index 6d727b2..6617aaa 100644
--- a/docs/sharding_representation.md
+++ b/docs/sharding_representation.md
@@ -78,10 +78,8 @@ features.
 ```c++
 @mesh_xy = <["x"=2, "y"=4, "z"=2]>
 
-// The 1st tensor dimension is sharded along axis "x" and the 2nd tensor
-// dimension is sharded along axis "z" then further along axis "y".
-// The local shape of this tensor (i.e. the shape on a single device),
-// would be tensor<2x1xf32>.
+// The 1st tensor dimension is sharded along axis "x" and the 2nd tensor dimension is
+// sharded along axis "z" then further along axis "y". The local shape of this tensor (i.e. the shape on a single device), would be tensor<2x1xf32>.
 sharding<@mesh_xy, [{"x"}, {"z", "y"}]> : tensor<4x8xf32>
 ```
 
@@ -373,11 +371,11 @@ For example:
 ```
 
 Priorities give users more fine grained control over propagation, e.g., batch
-parallelism first, then [megatron](https://arxiv.org/abs/1909.08053),
-and finally [ZeRO](https://arxiv.org/abs/1910.02054) sharding. This allows
-for strong guarantees about what's partitioned and allows for better
-debuggability by having more fine grained sharding strategies (can see how the
-program looks after just megatron in isolation).
+parallelism first, then [megatron](arxiv.org/abs/1909.08053), and finally
+[ZeRO](https://arxiv.org/abs/1910.02054) sharding. This allows for strong
+guarantees about what's partitioned and allows for better debuggability by
+having more fine grained sharding strategies (can see how the program looks
+after just megatron in isolation).
 
 We allow attaching a priority to each dimension sharding (0 by default), which
 indicates that all shardings with priority `<i` will be propagated to the entire
diff --git a/shardy/dialect/sdy/ir/ops.td b/shardy/dialect/sdy/ir/ops.td
index 61085a2..80db1cc 100644
--- a/shardy/dialect/sdy/ir/ops.td
+++ b/shardy/dialect/sdy/ir/ops.td
@@ -178,19 +178,6 @@ def Sdy_ManualComputationOp : Sdy_Op<"manual_computation",
   let hasVerifier = 1;
   let hasCanonicalizer = 1;
 
-  let builders = [
-    OpBuilder<(ins "TypeRange":$results, "ValueRange":$tensors,
-                   "ArrayRef<TensorShardingAttr>":$in_shardings,
-                   "ArrayRef<TensorShardingAttr>":$out_shardings,
-                   "ArrayRef<StringAttr>":$manual_axes), [{
-      MLIRContext* ctx = $_builder.getContext();
-      return build($_builder, $_state, results, tensors,
-                   TensorShardingPerValueAttr::get(ctx, in_shardings),
-                   TensorShardingPerValueAttr::get(ctx, out_shardings),
-                   manual_axes);
-    }]>,
-  ];
-
   let extraClassDeclaration = [{
     TensorShardingAttr getInSharding(int64_t operandIndex) {
       return getInShardings().getSharding(operandIndex);
diff --git a/shardy/dialect/sdy/ir/test/tensor_sharding_verification.mlir b/shardy/dialect/sdy/ir/test/tensor_sharding_verification.mlir
index 198fe64..a465552 100644
--- a/shardy/dialect/sdy/ir/test/tensor_sharding_verification.mlir
+++ b/shardy/dialect/sdy/ir/test/tensor_sharding_verification.mlir
@@ -130,6 +130,62 @@ func.func @num_shardings_does_not_match_num_results(%arg0: tensor<2x64x13xf32>,
 
 // -----
 
+sdy.mesh @mesh1 = <["a"=2]>
+sdy.mesh @mesh2 = <["b"=2]>
+
+// CHECK-LABEL: func @op_shardings_refer_to_different_meshes
+func.func @op_shardings_refer_to_different_meshes(%arg0: tensor<2x64x13xf32>, %arg1: tensor<2x64x13xf32>) -> (tensor<2x13xf32>, tensor<2x13xf32>) {
+  %0 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
+   // expected-error @+1 {{op result shardings can only be bound to the same mesh or an empty mesh}}
+  %1:2 = stablehlo.reduce(%arg0 init: %0), (%arg1 init: %0) across dimensions = [1]
+    {sdy.sharding=#sdy.sharding_per_value<[<@mesh1, [{"a"}, {}]>, <@mesh2, [{"b"}, {}]>]>} :
+    (tensor<2x64x13xf32>, tensor<2x64x13xf32>, tensor<f32>, tensor<f32>) -> (tensor<2x13xf32>, tensor<2x13xf32>)
+    reducer(%arg2: tensor<f32>, %arg4: tensor<f32>) (%arg3: tensor<f32>, %arg5: tensor<f32>)  {
+      %2 = stablehlo.add %arg2, %arg4 : tensor<f32>
+      %3 = stablehlo.add %arg3, %arg5 : tensor<f32>
+      stablehlo.return %2, %3 : tensor<f32>, tensor<f32>
+    }
+  return %1#0, %1#1 : tensor<2x13xf32>, tensor<2x13xf32>
+}
+
+// -----
+
+// CHECK-LABEL: func @op_shardings_bound_to_different_inlined_meshes
+func.func @op_shardings_bound_to_different_inlined_meshes(%arg0: tensor<2x64x13xf32>, %arg1: tensor<2x64x13xf32>) -> (tensor<2x13xf32>, tensor<2x13xf32>) {
+  %0 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
+   // expected-error @+1 {{op result shardings can only be bound to the same mesh or an empty mesh}}
+  %1:2 = stablehlo.reduce(%arg0 init: %0), (%arg1 init: %0) across dimensions = [1]
+    {sdy.sharding=#sdy.sharding_per_value<[<mesh<["a"=2]>, [{"a"}, {}]>, <mesh<["b"=2]>, [{"b"}, {}]>]>} :
+    (tensor<2x64x13xf32>, tensor<2x64x13xf32>, tensor<f32>, tensor<f32>) -> (tensor<2x13xf32>, tensor<2x13xf32>)
+    reducer(%arg2: tensor<f32>, %arg4: tensor<f32>) (%arg3: tensor<f32>, %arg5: tensor<f32>)  {
+      %2 = stablehlo.add %arg2, %arg4 : tensor<f32>
+      %3 = stablehlo.add %arg3, %arg5 : tensor<f32>
+      stablehlo.return %2, %3 : tensor<f32>, tensor<f32>
+    }
+  return %1#0, %1#1 : tensor<2x13xf32>, tensor<2x13xf32>
+}
+
+// -----
+
+sdy.mesh @mesh2 = <["b"=2]>
+
+// CHECK-LABEL: func @op_shardings_bound_to_different_inlined_and_referenced_meshes
+func.func @op_shardings_bound_to_different_inlined_and_referenced_meshes(%arg0: tensor<2x64x13xf32>, %arg1: tensor<2x64x13xf32>) -> (tensor<2x13xf32>, tensor<2x13xf32>) {
+  %0 = stablehlo.constant dense<0.000000e+00> : tensor<f32>
+   // expected-error @+1 {{op result shardings can only be bound to the same mesh or an empty mesh}}
+  %1:2 = stablehlo.reduce(%arg0 init: %0), (%arg1 init: %0) across dimensions = [1]
+    {sdy.sharding=#sdy.sharding_per_value<[<mesh<["a"=2]>, [{"a"}, {}]>, <@mesh2, [{"b"}, {}]>]>} :
+    (tensor<2x64x13xf32>, tensor<2x64x13xf32>, tensor<f32>, tensor<f32>) -> (tensor<2x13xf32>, tensor<2x13xf32>)
+    reducer(%arg2: tensor<f32>, %arg4: tensor<f32>) (%arg3: tensor<f32>, %arg5: tensor<f32>)  {
+      %2 = stablehlo.add %arg2, %arg4 : tensor<f32>
+      %3 = stablehlo.add %arg3, %arg5 : tensor<f32>
+      stablehlo.return %2, %3 : tensor<f32>, tensor<f32>
+    }
+  return %1#0, %1#1 : tensor<2x13xf32>, tensor<2x13xf32>
+}
+
+// -----
+
 sdy.mesh @mesh = <["a"=2]>
 
 // The purpose of this test is to check the error msg prefix for a func arg.
diff --git a/shardy/dialect/sdy/ir/verifiers.cc b/shardy/dialect/sdy/ir/verifiers.cc
index 08ddde3..4334626 100644
--- a/shardy/dialect/sdy/ir/verifiers.cc
+++ b/shardy/dialect/sdy/ir/verifiers.cc
@@ -403,12 +403,14 @@ LogicalResult verifyTensorShardingAttr(TensorShardingAttr shardingAttr,
 //
 // - The number of tensor shardings is equal to the number of tensors (size of
 //   `types`).
+// - All shardings must have the same mesh if `verifyCommonMesh` is true.
 // - All shardings are valid (see `verifyTensorShardingAttr`).
 // TODO(bartchr): relax this to allow different meshes when the op is a dataflow
 // op
 LogicalResult verifyTensorShardingPerValueAttr(
     TensorShardingPerValueAttr shardingPerValueAttr, TypeRange types,
-    Operation* op, EmitErrorFn emitError, const SymbolTable& symbolTable) {
+    Operation* op, EmitErrorFn emitError, const SymbolTable& symbolTable,
+    bool verifyCommonMesh = true) {
   ArrayRef<TensorShardingAttr> shardingsPerValue =
       shardingPerValueAttr.getShardings();
   if (types.empty() && shardingsPerValue.size() == 1) {
@@ -435,6 +437,17 @@ LogicalResult verifyTensorShardingPerValueAttr(
                                         symbolTable, valueEmitError))) {
       return failure();
     }
+
+    // We verify a common mesh here so an invalid mesh name reference will be
+    // caught before.
+    if (verifyCommonMesh) {
+      MeshAttr commonMesh = getCommonMesh(shardingsPerValue,
+                                          /*resultsShardings=*/{}, symbolTable);
+      if (!commonMesh) {
+        return emitError(
+            "shardings can only be bound to the same mesh or an empty mesh");
+      }
+    }
   }
 
   return success();
@@ -830,7 +843,7 @@ LogicalResult verifyManualComputationValue(
           [op, valueKindStr](StringRef msg) {
             return op->emitOpError(valueKindStr) << " " << msg;
           },
-          symbolTable))) {
+          symbolTable, /*verifyCommonMesh=*/false))) {
     return failure();
   }
 
diff --git a/shardy/dialect/sdy/transforms/export/explicit_reshards_util.cc b/shardy/dialect/sdy/transforms/export/explicit_reshards_util.cc
index c07be7b..eaadc07 100644
--- a/shardy/dialect/sdy/transforms/export/explicit_reshards_util.cc
+++ b/shardy/dialect/sdy/transforms/export/explicit_reshards_util.cc
@@ -928,7 +928,7 @@ SmallVector<int64_t> getTensorSizes(Operation* op) {
        llvm::concat<Type>(op->getOperandTypes(), op->getResultTypes())) {
     ShapedType shapedType = dynCastStaticShapedType(type);
     // Assign zero as the tensor size for dynamically shaped types.
-    tensorSizes.push_back(shapedType ? shapedType.getNumElements() : 0);
+    tensorSizes.push_back(shapedType? shapedType.getNumElements(): 0);
   }
   return tensorSizes;
 }
@@ -982,8 +982,7 @@ void insertExplicitReshardsOnOp(Operation* op, IRRewriter& rewriter,
   if (isa<stablehlo::ReduceWindowOp, stablehlo::ScatterOp,
           stablehlo::SelectAndScatterOp, stablehlo::GatherOp,
           stablehlo::AllReduceOp, stablehlo::AllGatherOp, stablehlo::AllToAllOp,
-          stablehlo::CollectivePermuteOp, stablehlo::CollectiveBroadcastOp>(
-          op)) {
+          stablehlo::CollectivePermuteOp>(op)) {
     return;
   }
 
diff --git a/shardy/dialect/sdy/transforms/propagation/aggressive_factor_propagation.cc b/shardy/dialect/sdy/transforms/propagation/aggressive_factor_propagation.cc
index 7eb1849..0a09170 100644
--- a/shardy/dialect/sdy/transforms/propagation/aggressive_factor_propagation.cc
+++ b/shardy/dialect/sdy/transforms/propagation/aggressive_factor_propagation.cc
@@ -26,6 +26,7 @@ limitations under the License.
 #include "mlir/IR/Value.h"
 #include "mlir/Support/LLVM.h"
 #include "shardy/dialect/sdy/ir/dialect.h"
+#include "shardy/dialect/sdy/transforms/common/op_properties.h"
 #include "shardy/dialect/sdy/transforms/propagation/factor_propagation.h"
 #include "shardy/dialect/sdy/transforms/propagation/sharding_projection.h"
 
@@ -83,6 +84,19 @@ SmallVector<TensorIndexSize> getFactorToSourceTensor(
   return factorToSourceTensor;
 }
 
+// Returns if `factorSharding` has a factor at `factorIndex` which is the
+// strict prefix of `shardingAxes`.
+bool isStrictPrefixOfFactorSharding(const TensorFactorShardings& factorSharding,
+                                    int64_t factorIndex,
+                                    ArrayRef<AxisRefAttr> shardingAxes) {
+  if (auto it = factorSharding.factorIndexToSharding.find(factorIndex);
+      it != factorSharding.factorIndexToSharding.end()) {
+    return isAxisListPrefixOf(it->getSecond().axisRefs, shardingAxes) ==
+           PrefixStatus::STRICT_PREFIX;
+  }
+  return false;
+}
+
 }  // namespace
 
 SmallVector<AxisRefAttr>
@@ -169,12 +183,8 @@ UpdateTensorShardings AggressiveFactorPropagation::propagateFactorShardings(
                                  factorToSourceTensor[j].index, j);
   });
 
-  // The propagation on each tensor is independent. This strategy can propagate
-  // different shardings to different tensors along the same factor. Examples
-  // are provided in the docstring of this class.
   for (const auto& [tensorIndex, tensorFactorShardings] :
-       llvm::enumerate(llvm::concat<const TensorFactorShardings>(
-           projection.getOperands(), projection.getResults()))) {
+       llvm::enumerate(projection.getResults())) {
     const FactorIndexToSharding& factorIndexToSharding =
         tensorFactorShardings.factorIndexToSharding;
 
@@ -188,18 +198,57 @@ UpdateTensorShardings AggressiveFactorPropagation::propagateFactorShardings(
       if (newAxes.empty()) {
         continue;
       }
-      tensorUpdated |=
-          expandTensorSharding(projection, tensorIndex, factorIndex, newAxes);
+      tensorUpdated |= expandTensorSharding(
+          projection, tensorIndex + projection.getNumOperands(), factorIndex,
+          newAxes);
     }
+    result.updateResults[tensorIndex] = tensorUpdated;
+  }
 
-    if (tensorIndex < projection.getNumOperands()) {
-      result.updateOperands[tensorIndex] = tensorUpdated;
-    } else {
-      result.updateResults[tensorIndex - projection.getNumOperands()] =
-          tensorUpdated;
+  for (const auto& [tensorIndex, tensorFactorShardings] :
+       llvm::enumerate(projection.getOperands())) {
+    const FactorIndexToSharding& factorIndexToSharding =
+        tensorFactorShardings.factorIndexToSharding;
+
+    // Propagate the axes got in Step 1, resolving conflicts between factors by
+    // following the order of preference in  `sortedFactorIndices`.
+    bool tensorUpdated = false;
+    for (int64_t factorIndex : sortedFactorIndices) {
+      SmallVector<AxisRefAttr> newAxes = getPropagatedFactorSharding(
+          factorIndex, tensorFactorShardings, factorIndexToSharding,
+          axesPerFactor, mesh, conservativePropagation, factorSizes);
+      if (newAxes.empty()) {
+        continue;
+      }
+
+      // Only propagate sideways through operands the factors that are also
+      // used in at least one result We want to avoid the following situation
+      // which can happen when a `sharding_constraint` is added onto the operand
+      // during Shardy import:
+      // ```
+      // %arg0: [{"a", ?}]
+      // %arg1: [{?}]
+      // %0 = add %arg0, %arg1 : [{}]
+      // ```
+      // We don't want to do an all-gather on both %arg0 and %arg1 due to "a"
+      // propagating sideways. Instead with the code below, since "a" can't
+      // propagate to `%0`, we will only do an all-gather on %arg0.
+      //
+      // TODO(b/396642774): Long term we should undo this and allow sideways
+      // propagation, but have our explicit reshard pass make sure the result is
+      // all-gathered instead of both operands.
+      if (op && isElementwise(op)) {
+        for (const TensorFactorShardings& result : projection.getResults()) {
+          if (isStrictPrefixOfFactorSharding(result, factorIndex, newAxes)) {
+            newAxes = result.factorIndexToSharding.at(factorIndex).axisRefs;
+          }
+        }
+      }
+      tensorUpdated |=
+          expandTensorSharding(projection, tensorIndex, factorIndex, newAxes);
     }
+    result.updateOperands[tensorIndex] = tensorUpdated;
   }
-
   return result;
 }
 
diff --git a/shardy/dialect/sdy/transforms/propagation/test/aggressive_propagation.mlir b/shardy/dialect/sdy/transforms/propagation/test/aggressive_propagation.mlir
index 14c1349..c0f54c3 100644
--- a/shardy/dialect/sdy/transforms/propagation/test/aggressive_propagation.mlir
+++ b/shardy/dialect/sdy/transforms/propagation/test/aggressive_propagation.mlir
@@ -153,11 +153,11 @@ func.func @multiple_conflicts_across_factors(
 }
 
 
-// CHECK-LABEL: func @sideways_propagation_if_result_is_closed_empty(
+// CHECK-LABEL: func @avoid_sideways_propagation_if_result_is_closed_empty(
 // CHECK-SAME:      %arg0: tensor<8xf32> {sdy.sharding = #sdy.sharding<@mesh_a_2_b_2, [{"a"}]>},
-// CHECK-SAME:      %arg1: tensor<8xf32> {sdy.sharding = #sdy.sharding<@mesh_a_2_b_2, [{"a", ?}]>})
+// CHECK-SAME:      %arg1: tensor<8xf32> {sdy.sharding = #sdy.sharding<@mesh_a_2_b_2, [{?}]>})
 // CHECK-SAME:  -> tensor<8xf32>
-func.func @sideways_propagation_if_result_is_closed_empty(
+func.func @avoid_sideways_propagation_if_result_is_closed_empty(
     %arg0: tensor<8xf32> {sdy.sharding = #sdy.sharding<@mesh_a_2_b_2, [{"a"}]>},
     %arg1: tensor<8xf32> {sdy.sharding = #sdy.sharding<@mesh_a_2_b_2, [{?}]>})
     -> tensor<8xf32> {
@@ -179,11 +179,11 @@ func.func @allow_sideways_propagation_if_result_is_open_empty(
   return %0 : tensor<8xf32>
 }
 
-// CHECK-LABEL: func @sideways_propagation_if_result_is_closed_sub_axis(
+// CHECK-LABEL: func @avoid_sideways_propagation_if_result_is_closed_sub_axis(
 // CHECK-SAME:      %arg0: tensor<8xf32> {sdy.sharding = #sdy.sharding<@mesh_a_4, [{"a"}]>},
-// CHECK-SAME:      %arg1: tensor<8xf32> {sdy.sharding = #sdy.sharding<@mesh_a_4, [{"a", ?}]>})
+// CHECK-SAME:      %arg1: tensor<8xf32> {sdy.sharding = #sdy.sharding<@mesh_a_4, [{"a":(1)2, ?}]>})
 // CHECK-SAME:  -> (tensor<8xf32> {sdy.sharding = #sdy.sharding<@mesh_a_4, [{"a":(1)2, ?}]>})
-func.func @sideways_propagation_if_result_is_closed_sub_axis(
+func.func @avoid_sideways_propagation_if_result_is_closed_sub_axis(
     %arg0: tensor<8xf32> {sdy.sharding = #sdy.sharding<@mesh_a_4, [{"a"}]>},
     %arg1: tensor<8xf32> {sdy.sharding = #sdy.sharding<@mesh_a_4, [{?}]>})
     -> tensor<8xf32> {
@@ -194,7 +194,7 @@ func.func @sideways_propagation_if_result_is_closed_sub_axis(
 
 // CHECK-LABEL: func @allow_partial_sideways_propagation_if_conflicting_with_result(
 // CHECK-SAME:      %arg0: tensor<8xf32> {sdy.sharding = #sdy.sharding<@mesh_a_2_b_2, [{"a", "b"}]>},
-// CHECK-SAME:      %arg1: tensor<8xf32> {sdy.sharding = #sdy.sharding<@mesh_a_2_b_2, [{"a", "b", ?}]>})
+// CHECK-SAME:      %arg1: tensor<8xf32> {sdy.sharding = #sdy.sharding<@mesh_a_2_b_2, [{"a", ?}]>})
 // CHECK-SAME:  -> (tensor<8xf32> {sdy.sharding = #sdy.sharding<@mesh_a_2_b_2, [{"a", ?}]>})
 func.func @allow_partial_sideways_propagation_if_conflicting_with_result(
     %arg0: tensor<8xf32> {sdy.sharding = #sdy.sharding<@mesh_a_2_b_2, [{"a", "b"}]>},
diff --git a/shardy/dialect/sdy/transforms/propagation/test/basic_propagation.mlir b/shardy/dialect/sdy/transforms/propagation/test/basic_propagation.mlir
index 0bc7d22..f812145 100644
--- a/shardy/dialect/sdy/transforms/propagation/test/basic_propagation.mlir
+++ b/shardy/dialect/sdy/transforms/propagation/test/basic_propagation.mlir
@@ -848,3 +848,5 @@ func.func @propagate_to_empty_mesh_with_partially_open_sharding(%arg0: tensor<8x
   %0 = stablehlo.add %arg0, %arg1 {sdy.sharding = #sdy.sharding_per_value<[<@empty_mesh, [{?}, {}]>]>} : tensor<8x8xf32>
   return %0: tensor<8x8xf32>
 }
+
+
diff --git a/shardy/dialect/sdy/transforms/propagation/test/user_priority_propagation.mlir b/shardy/dialect/sdy/transforms/propagation/test/user_priority_propagation.mlir
index 2d97877..5558e19 100644
--- a/shardy/dialect/sdy/transforms/propagation/test/user_priority_propagation.mlir
+++ b/shardy/dialect/sdy/transforms/propagation/test/user_priority_propagation.mlir
@@ -53,7 +53,7 @@ func.func @arg_lower_priority_than_return_value(
 // CHECK-SAME:      %arg0: tensor<8x8xf32> {sdy.sharding = #sdy.sharding<@mesh, [{"a"}, {"b"}]>},
 // CHECK-SAME:      %arg1: tensor<8x8xf32> {sdy.sharding = #sdy.sharding<@mesh, [{"c", ?}, {"b", ?}]>},
 // CHECK-SAME:      %arg2: tensor<8x8xf32> {sdy.sharding = #sdy.sharding<@mesh, [{"c", ?}, {"b", ?}]>},
-// CHECK-SAME:      %arg3: tensor<8x8xf32> {sdy.sharding = #sdy.sharding<@mesh, [{"c", ?}, {"b", ?}]>})
+// CHECK-SAME:      %arg3: tensor<8x8xf32> {sdy.sharding = #sdy.sharding<@mesh, [{"c", ?}, {?}]>})
 // CHECK-SAME:  -> (tensor<8x8xf32> {sdy.sharding = #sdy.sharding<@mesh, [{"c", ?}, {?}]>}) {
 func.func @arg_lower_priority_than_return_value_with_replicated(
       %arg0: tensor<8x8xf32> {sdy.sharding = #sdy.sharding<@mesh, [{"a"}p1, {"b"}p1]>},
@@ -72,7 +72,7 @@ func.func @arg_lower_priority_than_return_value_with_replicated(
 // CHECK-SAME:      %arg0: tensor<8x8xf32> {sdy.sharding = #sdy.sharding<@mesh, [{"a", ?}, {"b", ?}]>},
 // CHECK-SAME:      %arg1: tensor<8x8xf32> {sdy.sharding = #sdy.sharding<@mesh, [{"a"}, {"b"}]>},
 // CHECK-SAME:      %arg2: tensor<8x8xf32> {sdy.sharding = #sdy.sharding<@mesh, [{"a", ?}, {"b", ?}]>},
-// CHECK-SAME:      %arg3: tensor<8x8xf32> {sdy.sharding = #sdy.sharding<@mesh, [{"a", ?}, {"b", ?}]>})
+// CHECK-SAME:      %arg3: tensor<8x8xf32> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {"b", ?}]>})
 // CHECK-SAME:  -> (tensor<8x8xf32> {sdy.sharding = #sdy.sharding<@mesh, [{"c", ?}, {"b", ?}]>}) {
 func.func @arg_higher_priority_than_return_value(
       %arg0: tensor<8x8xf32>, %arg1: tensor<8x8xf32> {sdy.sharding = #sdy.sharding<@mesh, [{"a"}p0, {"b"}p0]>},
@@ -146,7 +146,7 @@ func.func @dim_with_lower_priority_gets_further_sharded_by_higher(
 // CHECK-LABEL: func @different_priorities_with_closed_empty_dim(
 // CHECK-SAME:      %arg0: tensor<8x8xf32> {sdy.sharding = #sdy.sharding<@mesh, [{"a"}, {"b"}]>},
 // CHECK-SAME:      %arg1: tensor<8x8xf32> {sdy.sharding = #sdy.sharding<@mesh, [{"a", ?}, {"b", ?}]>},
-// CHECK-SAME:      %arg2: tensor<8x8xf32> {sdy.sharding = #sdy.sharding<@mesh, [{"a", ?}, {"b", ?}]>},
+// CHECK-SAME:      %arg2: tensor<8x8xf32>,
 // CHECK-SAME:      %arg3: tensor<8x8xf32> {sdy.sharding = #sdy.sharding<@mesh, [{"c", ?}, {?}]>})
 // CHECK-SAME:  -> (tensor<8x8xf32> {sdy.sharding = #sdy.sharding<@mesh, [{"c", ?}, {?}]>}) {
 func.func @different_priorities_with_closed_empty_dim(
diff --git a/third_party/llvm/generated.patch b/third_party/llvm/generated.patch
index a79a29a..d9fe9b8 100644
--- a/third_party/llvm/generated.patch
+++ b/third_party/llvm/generated.patch
@@ -1,41 +1,419 @@
 Auto generated patch. Do not edit or delete it, even if empty.
-diff -ruN --strip-trailing-cr a/libcxx/include/__tree b/libcxx/include/__tree
---- a/libcxx/include/__tree
-+++ b/libcxx/include/__tree
-@@ -1281,7 +1281,7 @@
-   }
-   _LIBCPP_HIDE_FROM_ABI void __move_assign_alloc(__tree&, false_type) _NOEXCEPT {}
+diff -ruN --strip-trailing-cr a/clang/lib/Sema/SemaExpr.cpp b/clang/lib/Sema/SemaExpr.cpp
+--- a/clang/lib/Sema/SemaExpr.cpp
++++ b/clang/lib/Sema/SemaExpr.cpp
+@@ -9966,8 +9966,13 @@
+       // If there is a conversion of some kind, check to see what kind of
+       // pointer conversion happened so we can diagnose a C++ compatibility
+       // diagnostic if the conversion is invalid. This only matters if the RHS
+-      // is some kind of void pointer.
+-      if (Kind != CK_NoOp && !getLangOpts().CPlusPlus) {
++      // is some kind of void pointer. We have a carve-out when the RHS is from
++      // a macro expansion because the use of a macro may indicate different
++      // code between C and C++. Consider: char *s = NULL; where NULL is
++      // defined as (void *)0 in C (which would be invalid in C++), but 0 in
++      // C++, which is valid in C++.
++      if (Kind != CK_NoOp && !getLangOpts().CPlusPlus &&
++          !RHS.get()->getBeginLoc().isMacroID()) {
+         QualType CanRHS =
+             RHS.get()->getType().getCanonicalType().getUnqualifiedType();
+         QualType CanLHS = LHSType.getCanonicalType().getUnqualifiedType();
+diff -ruN --strip-trailing-cr a/clang/test/Sema/implicit-void-ptr-cast.c b/clang/test/Sema/implicit-void-ptr-cast.c
+--- a/clang/test/Sema/implicit-void-ptr-cast.c
++++ b/clang/test/Sema/implicit-void-ptr-cast.c
+@@ -59,4 +59,26 @@
+   b3 = (char *)0;
+   b3 = nullptr;
+   b3 = 0;
++
++  // Note that we explicitly silence the diagnostic if the RHS is from a macro
++  // expansion. This allows for things like NULL expanding to different token
++  // sequences depending on language mode, but applies to any macro that
++  // expands to a valid null pointer constant.
++#if defined(__cplusplus)
++  #define NULL 0
++#else
++  #define NULL ((void *)0)
++#endif
++  #define SOMETHING_NOT_SPELLED_NULL nullptr
++  #define SOMETHING_THAT_IS_NOT_NULL (void *)12
++
++  char *ptr1 = NULL; // Ok
++  char *ptr2 = SOMETHING_NOT_SPELLED_NULL; // Ok
++  char *ptr3 = SOMETHING_THAT_IS_NOT_NULL; // c-warning {{implicit conversion when initializing 'char *' with an expression of type 'void *' is not permitted in C++}} \
++                                              cxx-error {{cannot initialize a variable of type 'char *' with an rvalue of type 'void *'}}
++
++  ptr1 = NULL; // Ok
++  ptr2 = SOMETHING_NOT_SPELLED_NULL; // Ok
++  ptr3 = SOMETHING_THAT_IS_NOT_NULL; // c-warning {{implicit conversion when assigning to 'char *' from type 'void *' is not permitted in C++}} \
++                                        cxx-error {{assigning to 'char *' from incompatible type 'void *'}}
+ }
+diff -ruN --strip-trailing-cr a/llvm/include/llvm/DebugInfo/DWARF/DWARFContext.h b/llvm/include/llvm/DebugInfo/DWARF/DWARFContext.h
+--- a/llvm/include/llvm/DebugInfo/DWARF/DWARFContext.h
++++ b/llvm/include/llvm/DebugInfo/DWARF/DWARFContext.h
+@@ -102,8 +102,6 @@
+     /// Parse a macro[.dwo] or macinfo[.dwo] section.
+     std::unique_ptr<DWARFDebugMacro>
+     parseMacroOrMacinfo(MacroSecType SectionType);
+-
+-    virtual Error doWorkThreadSafely(function_ref<Error()> Work) = 0;
+   };
+   friend class DWARFContextState;
  
--  template <class _From, __enable_if_t<__is_pair_v<__remove_cvref_t<_From> >, int> = 0>
-+  template <class _From, class _ValueT = _Tp, __enable_if_t<__is_tree_value_type<_ValueT>::value, int> = 0>
-   _LIBCPP_HIDE_FROM_ABI static void __assign_value(__get_node_value_type_t<value_type>& __lhs, _From&& __rhs) {
-     using __key_type = typename _NodeTypes::key_type;
+@@ -492,10 +490,6 @@
+   /// manually only for DWARF5.
+   void setParseCUTUIndexManually(bool PCUTU) { ParseCUTUIndexManually = PCUTU; }
  
-@@ -1291,7 +1291,7 @@
-     __lhs.second                         = std::forward<_From>(__rhs).second;
-   }
+-  Error doWorkThreadSafely(function_ref<Error()> Work) {
+-    return State->doWorkThreadSafely(Work);
+-  }
+-
+ private:
+   void addLocalsForDie(DWARFCompileUnit *CU, DWARFDie Subprogram, DWARFDie Die,
+                        std::vector<DILocal> &Result);
+diff -ruN --strip-trailing-cr a/llvm/include/llvm/DebugInfo/DWARF/DWARFUnit.h b/llvm/include/llvm/DebugInfo/DWARF/DWARFUnit.h
+--- a/llvm/include/llvm/DebugInfo/DWARF/DWARFUnit.h
++++ b/llvm/include/llvm/DebugInfo/DWARF/DWARFUnit.h
+@@ -566,9 +566,6 @@
+ 
+   Error tryExtractDIEsIfNeeded(bool CUDieOnly);
+ 
+-  /// clearDIEs - Clear parsed DIEs to keep memory usage low.
+-  void clearDIEs(bool KeepCUDie, bool KeepDWODies = false);
+-
+ private:
+   /// Size in bytes of the .debug_info data associated with this compile unit.
+   size_t getDebugInfoSize() const {
+@@ -584,6 +581,9 @@
+   void extractDIEsToVector(bool AppendCUDie, bool AppendNonCUDIEs,
+                            std::vector<DWARFDebugInfoEntry> &DIEs) const;
  
--  template <class _To, class _From, class _ValueT = _Tp, __enable_if_t<!__is_pair_v<__remove_cvref_t<_From> >, int> = 0>
-+  template <class _To, class _From, class _ValueT = _Tp, __enable_if_t<!__is_tree_value_type<_ValueT>::value, int> = 0>
-   _LIBCPP_HIDE_FROM_ABI static void __assign_value(_To& __lhs, _From&& __rhs) {
-     __lhs = std::forward<_From>(__rhs);
++  /// clearDIEs - Clear parsed DIEs to keep memory usage low.
++  void clearDIEs(bool KeepCUDie);
++
+   /// parseDWO - Parses .dwo file for current compile unit. Returns true if
+   /// it was actually constructed.
+   /// The \p AlternativeLocation specifies an alternative location to get
+diff -ruN --strip-trailing-cr a/llvm/lib/DebugInfo/DWARF/DWARFContext.cpp b/llvm/lib/DebugInfo/DWARF/DWARFContext.cpp
+--- a/llvm/lib/DebugInfo/DWARF/DWARFContext.cpp
++++ b/llvm/lib/DebugInfo/DWARF/DWARFContext.cpp
+@@ -621,10 +621,6 @@
+     else
+       return getNormalTypeUnitMap();
    }
-diff -ruN --strip-trailing-cr a/libcxx/test/std/containers/associative/set/set.cons/copy_assign.pass.cpp b/libcxx/test/std/containers/associative/set/set.cons/copy_assign.pass.cpp
---- a/libcxx/test/std/containers/associative/set/set.cons/copy_assign.pass.cpp
-+++ b/libcxx/test/std/containers/associative/set/set.cons/copy_assign.pass.cpp
-@@ -80,5 +80,15 @@
-     assert(*std::next(mo.begin(), 2) == 3);
+-
+-  Error doWorkThreadSafely(function_ref<Error()> Work) override {
+-    return Work();
+-  }
+ };
+ 
+ class ThreadSafeState : public ThreadUnsafeDWARFContextState {
+@@ -740,11 +736,6 @@
+     std::unique_lock<std::recursive_mutex> LockGuard(Mutex);
+     return ThreadUnsafeDWARFContextState::getTypeUnitMap(IsDWO);
    }
+-
+-  Error doWorkThreadSafely(function_ref<Error()> Work) override {
+-    std::unique_lock<std::recursive_mutex> LockGuard(Mutex);
+-    return ThreadUnsafeDWARFContextState::doWorkThreadSafely(Work);
+-  }
+ };
+ } // namespace
+ 
+diff -ruN --strip-trailing-cr a/llvm/lib/DebugInfo/DWARF/DWARFUnit.cpp b/llvm/lib/DebugInfo/DWARF/DWARFUnit.cpp
+--- a/llvm/lib/DebugInfo/DWARF/DWARFUnit.cpp
++++ b/llvm/lib/DebugInfo/DWARF/DWARFUnit.cpp
+@@ -496,111 +496,107 @@
+ }
  
-+  { // Test with std::pair, since we have some special handling for pairs inside __tree
-+    std::pair<int, int> arr[] = {
-+        std::make_pair(1, 2), std::make_pair(2, 3), std::make_pair(3, 4), std::make_pair(4, 5)};
-+    std::set<std::pair<int, int> > a(arr, arr + 4);
-+    std::set<std::pair<int, int> > b;
+ Error DWARFUnit::tryExtractDIEsIfNeeded(bool CUDieOnly) {
+-  return Context.doWorkThreadSafely([&]() -> Error {
+-    if ((CUDieOnly && !DieArray.empty()) || DieArray.size() > 1)
+-      return Error::success(); // Already parsed.
+-
+-    bool HasCUDie = !DieArray.empty();
+-    extractDIEsToVector(!HasCUDie, !CUDieOnly, DieArray);
+-
+-    if (DieArray.empty())
+-      return Error::success();
+-
+-    // If CU DIE was just parsed, copy several attribute values from it.
+-    if (HasCUDie)
+-      return Error::success();
+-
+-    DWARFDie UnitDie(this, &DieArray[0]);
+-    if (std::optional<uint64_t> DWOId =
+-            toUnsigned(UnitDie.find(DW_AT_GNU_dwo_id)))
+-      Header.setDWOId(*DWOId);
+-    if (!IsDWO) {
+-      assert(AddrOffsetSectionBase == std::nullopt);
+-      assert(RangeSectionBase == 0);
+-      assert(LocSectionBase == 0);
+-      AddrOffsetSectionBase = toSectionOffset(UnitDie.find(DW_AT_addr_base));
+-      if (!AddrOffsetSectionBase)
+-        AddrOffsetSectionBase =
+-            toSectionOffset(UnitDie.find(DW_AT_GNU_addr_base));
+-      RangeSectionBase = toSectionOffset(UnitDie.find(DW_AT_rnglists_base), 0);
+-      LocSectionBase = toSectionOffset(UnitDie.find(DW_AT_loclists_base), 0);
+-    }
+-
+-    // In general, in DWARF v5 and beyond we derive the start of the unit's
+-    // contribution to the string offsets table from the unit DIE's
+-    // DW_AT_str_offsets_base attribute. Split DWARF units do not use this
+-    // attribute, so we assume that there is a contribution to the string
+-    // offsets table starting at offset 0 of the debug_str_offsets.dwo section.
+-    // In both cases we need to determine the format of the contribution,
+-    // which may differ from the unit's format.
+-    DWARFDataExtractor DA(Context.getDWARFObj(), StringOffsetSection,
+-                          IsLittleEndian, 0);
+-    if (IsDWO || getVersion() >= 5) {
+-      auto StringOffsetOrError =
+-          IsDWO ? determineStringOffsetsTableContributionDWO(DA)
+-                : determineStringOffsetsTableContribution(DA);
+-      if (!StringOffsetOrError) {
+-        return createStringError(errc::invalid_argument,
+-                                 "invalid reference to or invalid content in "
+-                                 ".debug_str_offsets[.dwo]: " +
+-                                     toString(StringOffsetOrError.takeError()));
+-      }
+-
+-      StringOffsetsTableContribution = *StringOffsetOrError;
+-    }
+-
+-    // DWARF v5 uses the .debug_rnglists and .debug_rnglists.dwo sections to
+-    // describe address ranges.
+-    if (getVersion() >= 5) {
+-      // In case of DWP, the base offset from the index has to be added.
+-      if (IsDWO) {
+-        uint64_t ContributionBaseOffset = 0;
+-        if (auto *IndexEntry = Header.getIndexEntry())
+-          if (auto *Contrib = IndexEntry->getContribution(DW_SECT_RNGLISTS))
+-            ContributionBaseOffset = Contrib->getOffset();
+-        setRangesSection(
+-            &Context.getDWARFObj().getRnglistsDWOSection(),
+-            ContributionBaseOffset +
+-                DWARFListTableHeader::getHeaderSize(Header.getFormat()));
+-      } else
+-        setRangesSection(&Context.getDWARFObj().getRnglistsSection(),
+-                         toSectionOffset(UnitDie.find(DW_AT_rnglists_base),
+-                                         DWARFListTableHeader::getHeaderSize(
+-                                             Header.getFormat())));
+-    }
++  if ((CUDieOnly && !DieArray.empty()) || DieArray.size() > 1)
++    return Error::success(); // Already parsed.
+ 
++  bool HasCUDie = !DieArray.empty();
++  extractDIEsToVector(!HasCUDie, !CUDieOnly, DieArray);
++
++  if (DieArray.empty())
++    return Error::success();
 +
-+    b = a;
-+    assert(a == b);
++  // If CU DIE was just parsed, copy several attribute values from it.
++  if (HasCUDie)
++    return Error::success();
++
++  DWARFDie UnitDie(this, &DieArray[0]);
++  if (std::optional<uint64_t> DWOId =
++          toUnsigned(UnitDie.find(DW_AT_GNU_dwo_id)))
++    Header.setDWOId(*DWOId);
++  if (!IsDWO) {
++    assert(AddrOffsetSectionBase == std::nullopt);
++    assert(RangeSectionBase == 0);
++    assert(LocSectionBase == 0);
++    AddrOffsetSectionBase = toSectionOffset(UnitDie.find(DW_AT_addr_base));
++    if (!AddrOffsetSectionBase)
++      AddrOffsetSectionBase =
++          toSectionOffset(UnitDie.find(DW_AT_GNU_addr_base));
++    RangeSectionBase = toSectionOffset(UnitDie.find(DW_AT_rnglists_base), 0);
++    LocSectionBase = toSectionOffset(UnitDie.find(DW_AT_loclists_base), 0);
 +  }
 +
-   return 0;
++  // In general, in DWARF v5 and beyond we derive the start of the unit's
++  // contribution to the string offsets table from the unit DIE's
++  // DW_AT_str_offsets_base attribute. Split DWARF units do not use this
++  // attribute, so we assume that there is a contribution to the string
++  // offsets table starting at offset 0 of the debug_str_offsets.dwo section.
++  // In both cases we need to determine the format of the contribution,
++  // which may differ from the unit's format.
++  DWARFDataExtractor DA(Context.getDWARFObj(), StringOffsetSection,
++                        IsLittleEndian, 0);
++  if (IsDWO || getVersion() >= 5) {
++    auto StringOffsetOrError =
++        IsDWO ? determineStringOffsetsTableContributionDWO(DA)
++              : determineStringOffsetsTableContribution(DA);
++    if (!StringOffsetOrError)
++      return createStringError(errc::invalid_argument,
++                               "invalid reference to or invalid content in "
++                               ".debug_str_offsets[.dwo]: " +
++                                   toString(StringOffsetOrError.takeError()));
++
++    StringOffsetsTableContribution = *StringOffsetOrError;
++  }
++
++  // DWARF v5 uses the .debug_rnglists and .debug_rnglists.dwo sections to
++  // describe address ranges.
++  if (getVersion() >= 5) {
++    // In case of DWP, the base offset from the index has to be added.
+     if (IsDWO) {
+-      // If we are reading a package file, we need to adjust the location list
+-      // data based on the index entries.
+-      StringRef Data = Header.getVersion() >= 5
+-                           ? Context.getDWARFObj().getLoclistsDWOSection().Data
+-                           : Context.getDWARFObj().getLocDWOSection().Data;
++      uint64_t ContributionBaseOffset = 0;
+       if (auto *IndexEntry = Header.getIndexEntry())
+-        if (const auto *C = IndexEntry->getContribution(
+-                Header.getVersion() >= 5 ? DW_SECT_LOCLISTS : DW_SECT_EXT_LOC))
+-          Data = Data.substr(C->getOffset(), C->getLength());
+-
+-      DWARFDataExtractor DWARFData(Data, IsLittleEndian, getAddressByteSize());
+-      LocTable =
+-          std::make_unique<DWARFDebugLoclists>(DWARFData, Header.getVersion());
+-      LocSectionBase = DWARFListTableHeader::getHeaderSize(Header.getFormat());
+-    } else if (getVersion() >= 5) {
+-      LocTable = std::make_unique<DWARFDebugLoclists>(
+-          DWARFDataExtractor(Context.getDWARFObj(),
+-                             Context.getDWARFObj().getLoclistsSection(),
+-                             IsLittleEndian, getAddressByteSize()),
+-          getVersion());
+-    } else {
+-      LocTable = std::make_unique<DWARFDebugLoc>(DWARFDataExtractor(
+-          Context.getDWARFObj(), Context.getDWARFObj().getLocSection(),
+-          IsLittleEndian, getAddressByteSize()));
+-    }
++        if (auto *Contrib = IndexEntry->getContribution(DW_SECT_RNGLISTS))
++          ContributionBaseOffset = Contrib->getOffset();
++      setRangesSection(
++          &Context.getDWARFObj().getRnglistsDWOSection(),
++          ContributionBaseOffset +
++              DWARFListTableHeader::getHeaderSize(Header.getFormat()));
++    } else
++      setRangesSection(&Context.getDWARFObj().getRnglistsSection(),
++                       toSectionOffset(UnitDie.find(DW_AT_rnglists_base),
++                                       DWARFListTableHeader::getHeaderSize(
++                                           Header.getFormat())));
++  }
+ 
+-    // Don't fall back to DW_AT_GNU_ranges_base: it should be ignored for
+-    // skeleton CU DIE, so that DWARF users not aware of it are not broken.
++  if (IsDWO) {
++    // If we are reading a package file, we need to adjust the location list
++    // data based on the index entries.
++    StringRef Data = Header.getVersion() >= 5
++                         ? Context.getDWARFObj().getLoclistsDWOSection().Data
++                         : Context.getDWARFObj().getLocDWOSection().Data;
++    if (auto *IndexEntry = Header.getIndexEntry())
++      if (const auto *C = IndexEntry->getContribution(
++              Header.getVersion() >= 5 ? DW_SECT_LOCLISTS : DW_SECT_EXT_LOC))
++        Data = Data.substr(C->getOffset(), C->getLength());
++
++    DWARFDataExtractor DWARFData(Data, IsLittleEndian, getAddressByteSize());
++    LocTable =
++        std::make_unique<DWARFDebugLoclists>(DWARFData, Header.getVersion());
++    LocSectionBase = DWARFListTableHeader::getHeaderSize(Header.getFormat());
++  } else if (getVersion() >= 5) {
++    LocTable = std::make_unique<DWARFDebugLoclists>(
++        DWARFDataExtractor(Context.getDWARFObj(),
++                           Context.getDWARFObj().getLoclistsSection(),
++                           IsLittleEndian, getAddressByteSize()),
++        getVersion());
++  } else {
++    LocTable = std::make_unique<DWARFDebugLoc>(DWARFDataExtractor(
++        Context.getDWARFObj(), Context.getDWARFObj().getLocSection(),
++        IsLittleEndian, getAddressByteSize()));
++  }
+ 
+-    return Error::success();
+-  });
++  // Don't fall back to DW_AT_GNU_ranges_base: it should be ignored for
++  // skeleton CU DIE, so that DWARF users not aware of it are not broken.
++  return Error::success();
  }
+ 
+ bool DWARFUnit::parseDWO(StringRef DWOAlternativeLocation) {
+@@ -655,21 +651,15 @@
+   return true;
+ }
+ 
+-void DWARFUnit::clearDIEs(bool KeepCUDie, bool KeepDWODies) {
+-  assert(!Context.doWorkThreadSafely([&] {
+-    if (!KeepDWODies && DWO) {
+-      DWO->clearDIEs(KeepCUDie, KeepDWODies);
+-    }
+-    // Do not use resize() + shrink_to_fit() to free memory occupied by dies.
+-    // shrink_to_fit() is a *non-binding* request to reduce capacity() to
+-    // size(). It depends on the implementation whether the request is
+-    // fulfilled. Create a new vector with a small capacity and assign it to the
+-    // DieArray to have previous contents freed.
+-    DieArray = (KeepCUDie && !DieArray.empty())
+-                   ? std::vector<DWARFDebugInfoEntry>({DieArray[0]})
+-                   : std::vector<DWARFDebugInfoEntry>();
+-    return Error::success();
+-  }));
++void DWARFUnit::clearDIEs(bool KeepCUDie) {
++  // Do not use resize() + shrink_to_fit() to free memory occupied by dies.
++  // shrink_to_fit() is a *non-binding* request to reduce capacity() to size().
++  // It depends on the implementation whether the request is fulfilled.
++  // Create a new vector with a small capacity and assign it to the DieArray to
++  // have previous contents freed.
++  DieArray = (KeepCUDie && !DieArray.empty())
++                 ? std::vector<DWARFDebugInfoEntry>({DieArray[0]})
++                 : std::vector<DWARFDebugInfoEntry>();
+ }
+ 
+ Expected<DWARFAddressRangesVector>
+diff -ruN --strip-trailing-cr a/llvm/lib/DebugInfo/GSYM/DwarfTransformer.cpp b/llvm/lib/DebugInfo/GSYM/DwarfTransformer.cpp
+--- a/llvm/lib/DebugInfo/GSYM/DwarfTransformer.cpp
++++ b/llvm/lib/DebugInfo/GSYM/DwarfTransformer.cpp
+@@ -656,11 +656,6 @@
+       DWARFDie Die = getDie(*CU);
+       CUInfo CUI(DICtx, dyn_cast<DWARFCompileUnit>(CU.get()));
+       handleDie(Out, CUI, Die);
+-      // Release the line table, once we're done.
+-      DICtx.clearLineTableForUnit(CU.get());
+-      // Free any DIEs that were allocated by the DWARF parser.
+-      // If/when they're needed by other CU's, they'll be recreated.
+-      CU->clearDIEs(/*KeepCUDie=*/false, /*KeepDWODIEs=*/false);
+     }
+   } else {
+     // LLVM Dwarf parser is not thread-safe and we need to parse all DWARF up
+@@ -673,7 +668,12 @@
+     for (const auto &CU : DICtx.compile_units())
+       CU->getAbbreviations();
+ 
++    // Now parse all DIEs in case we have cross compile unit references in a
++    // thread pool.
+     DefaultThreadPool pool(hardware_concurrency(NumThreads));
++    for (const auto &CU : DICtx.compile_units())
++      pool.async([&CU]() { CU->getUnitDIE(false /*CUDieOnly*/); });
++    pool.wait();
+ 
+     // Now convert all DWARF to GSYM in a thread pool.
+     std::mutex LogMutex;
+@@ -681,15 +681,11 @@
+       DWARFDie Die = getDie(*CU);
+       if (Die) {
+         CUInfo CUI(DICtx, dyn_cast<DWARFCompileUnit>(CU.get()));
+-        pool.async([this, CUI, &CU, &LogMutex, &Out, Die]() mutable {
++        pool.async([this, CUI, &LogMutex, &Out, Die]() mutable {
+           std::string storage;
+           raw_string_ostream StrStream(storage);
+           OutputAggregator ThreadOut(Out.GetOS() ? &StrStream : nullptr);
+           handleDie(ThreadOut, CUI, Die);
+-          DICtx.clearLineTableForUnit(CU.get());
+-          // Free any DIEs that were allocated by the DWARF parser.
+-          // If/when they're needed by other CU's, they'll be recreated.
+-          CU->clearDIEs(/*KeepCUDie=*/false, /*KeepDWODIEs=*/false);
+           // Print ThreadLogStorage lines into an actual stream under a lock
+           std::lock_guard<std::mutex> guard(LogMutex);
+           if (Out.GetOS()) {
+@@ -701,9 +697,6 @@
+     }
+     pool.wait();
+   }
+-  // Now get rid of all the DIEs that may have been recreated
+-  for (const auto &CU : DICtx.compile_units())
+-    CU->clearDIEs(/*KeepCUDie=*/false, /*KeepDWODIEs=*/false);
+   size_t FunctionsAddedCount = Gsym.getNumFunctionInfos() - NumBefore;
+   Out << "Loaded " << FunctionsAddedCount << " functions from DWARF.\n";
+   return Error::success();
diff --git a/third_party/llvm/workspace.bzl b/third_party/llvm/workspace.bzl
index 70e5132..3b568ad 100644
--- a/third_party/llvm/workspace.bzl
+++ b/third_party/llvm/workspace.bzl
@@ -4,8 +4,8 @@ load("//third_party:repo.bzl", "tf_http_archive")
 
 def repo(name):
     """Imports LLVM."""
-    LLVM_COMMIT = "3fcfce4c5e5fd1c3072e8db1d692c93459e8cd74"
-    LLVM_SHA256 = "9c4bde7ff2804eb03b23777c1d95abc1b33ca286cda6115f8d14e057585e3974"
+    LLVM_COMMIT = "72b2219b3e2319e29831e4e9b07c440444f3add6"
+    LLVM_SHA256 = "e78b38abafb9d29e822395512a8c8f51d9a8fe7070948dda4a7060645e5103b3"
 
     tf_http_archive(
         name = name,
diff --git a/third_party/stablehlo/temporary.patch b/third_party/stablehlo/temporary.patch
index 09edf71..875d89b 100755
--- a/third_party/stablehlo/temporary.patch
+++ b/third_party/stablehlo/temporary.patch
@@ -102,65 +102,6 @@ diff --ruN a/stablehlo/stablehlo/dialect/StablehloOps.td b/stablehlo/stablehlo/d
      ]> {
    let summary = "Recv operation";
    let description = [{
-diff --ruN a/stablehlo/stablehlo/integrations/c/StablehloDialectApi.cpp b/stablehlo/stablehlo/integrations/c/StablehloDialectApi.cpp
---- stablehlo/stablehlo/integrations/c/StablehloDialectApi.cpp
-+++ stablehlo/stablehlo/integrations/c/StablehloDialectApi.cpp
-@@ -78,10 +78,11 @@
- 
- MlirLogicalResult stablehloSerializePortableArtifactFromModule(
-     MlirModule moduleStr, MlirStringRef targetVersion,
--    MlirStringCallback callback, void *userData) {
-+    MlirStringCallback callback, void *userData, bool allowOtherDialects) {
-   mlir::detail::CallbackOstream stream(callback, userData);
-   if (failed(mlir::stablehlo::serializePortableArtifact(
--          unwrap(moduleStr), unwrap(targetVersion), stream)))
-+          unwrap(moduleStr), unwrap(targetVersion), stream,
-+          allowOtherDialects)))
-     return mlirLogicalResultFailure();
-   return mlirLogicalResultSuccess();
- }
-diff --ruN a/stablehlo/stablehlo/integrations/c/StablehloDialectApi.h b/stablehlo/stablehlo/integrations/c/StablehloDialectApi.h
---- stablehlo/stablehlo/integrations/c/StablehloDialectApi.h
-+++ stablehlo/stablehlo/integrations/c/StablehloDialectApi.h
-@@ -92,7 +92,8 @@
- stablehloSerializePortableArtifactFromModule(MlirModule moduleStr,
-                                              MlirStringRef targetVersion,
-                                              MlirStringCallback callback,
--                                             void* userData);
-+                                             void* userData,
-+                                             bool allowOtherDialects = false);
- 
- // Read a StableHLO program from a portable artifact, returning the module as
- // MLIR bytecode. Note, this bytecode returned is not a portable artifact,
-diff --ruN a/stablehlo/stablehlo/integrations/python/StablehloApi.cpp b/stablehlo/stablehlo/integrations/python/StablehloApi.cpp
---- stablehlo/stablehlo/integrations/python/StablehloApi.cpp
-+++ stablehlo/stablehlo/integrations/python/StablehloApi.cpp
-@@ -102,20 +102,22 @@
-   //
-   m.def(
-       "serialize_portable_artifact",
--      [](MlirModule module, std::string_view target) -> nb::bytes {
-+      [](MlirModule module, std::string_view target,
-+         bool allowOtherDialects) -> nb::bytes {
-         StringWriterHelper accumulator;
-         if (mlirLogicalResultIsFailure(
-                 stablehloSerializePortableArtifactFromModule(
-                     module, toMlirStringRef(target),
-                     accumulator.getMlirStringCallback(),
--                    accumulator.getUserData()))) {
-+                    accumulator.getUserData(), allowOtherDialects))) {
-           throw nb::value_error("failed to serialize module");
-         }
- 
-         std::string serialized = accumulator.toString();
-         return nb::bytes(serialized.data(), serialized.size());
-       },
--      nb::arg("module"), nb::arg("target"));
-+      nb::arg("module"), nb::arg("target"),
-+      nb::arg("allow_other_dialects") = false);
- 
-   m.def(
-       "deserialize_portable_artifact",
 diff --ruN a/stablehlo/stablehlo/tests/transforms/stablehlo_convert_to_signless.mlir b/stablehlo/stablehlo/tests/transforms/stablehlo_convert_to_signless.mlir
 --- stablehlo/stablehlo/tests/transforms/stablehlo_convert_to_signless.mlir
 +++ stablehlo/stablehlo/tests/transforms/stablehlo_convert_to_signless.mlir
