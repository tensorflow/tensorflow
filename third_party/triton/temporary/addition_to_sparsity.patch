# This patch should be merged with public/sparsity.patch in the beginning of the next
# integration.
diff --git a/lib/Dialect/TritonGPU/Transforms/AccelerateMatmul.cpp b/lib/Dialect/TritonGPU/Transforms/AccelerateMatmul.cpp
--- a/lib/Dialect/TritonGPU/Transforms/AccelerateMatmul.cpp
+++ b/lib/Dialect/TritonGPU/Transforms/AccelerateMatmul.cpp
@@ -230,7 +230,7 @@ static bool bwdFilter(Operation *op) {
 // result, kwidth can be the bitwidth of the lower precision primitive.
 // Conversely, in the downcasting scenario, no reordering is performed,
 // making it directory use the lower precision primitive.
-static int computeOrigBitWidth(Value x) {
+int computeOrigBitWidth(Value x) {
   int finalBitWidth = getElementTypeOrSelf(x).getIntOrFloatBitWidth();
   int origBitWidth = finalBitWidth;
   SetVector<Operation *> slice;
@@ -1045,10 +1045,6 @@ public:
   }
 };
 
-// Expose helper functions from BlockedToMMA to be reused for sparse matmul.
-int computeOrigBitWidth(Value x) {
-  return BlockedToMMA::computeOrigBitWidth(x);
-}
 Value getSharedMemMMAOperand(Value v, mlir::PatternRewriter &rewriter,
                                 int opIdx, bool allowTranspose) {
   return getSharedMemoryMMAOperand(v, rewriter, opIdx, allowTranspose);

 