diff --git a/docs/sdy_export_passes.md b/docs/sdy_export_passes.md
index cc53465..77dad43 100755
--- a/docs/sdy_export_passes.md
+++ b/docs/sdy_export_passes.md
@@ -105,12 +105,6 @@ _Sinks all `DataFlowEdgeOp` into their input._
 
 Moves the sharding of each `DataFlowEdgeOp` to its input (the root target of
 the edge), and replaces the op with its input.
-
-#### Options
-```
--sink-debug-sharding-origins          : Whether to sink the debug sharding origins info. See `debug-sharding-origins` option in propagation for more info.
--sink-debug-propagation-edge-sharding : Whether to sink the debug propagation edge sharding info. See `debug-propagation-edge-sharding` option in propagation for more info.
-```
 ### `-sdy-update-non-divisible-input-output-shardings`
 
 _Makes FuncOp inputs/outputs evenly sharded, removing any need for padding due to non-divisible shardings._
diff --git a/shardy/dialect/sdy/ir/attrs.td b/shardy/dialect/sdy/ir/attrs.td
index c4ef24a..8c1dc72 100644
--- a/shardy/dialect/sdy/ir/attrs.td
+++ b/shardy/dialect/sdy/ir/attrs.td
@@ -362,25 +362,25 @@ def Sdy_AxisRef : AttrDef<Sdy_Dialect, "AxisRef"> {
     //  "a":(1)3, "a":(2)3 -> false
     bool canCoexist(AxisRefAttr other) const;
 
-    // If this axis or sub-axis overlaps with `other`, returns that overlapping
-    // axis or sub-axis, otherwise returns `std::nullopt`.
+    // Returns the largest prefix of this axis that overlaps with `other`, or
+    // `std::nullopt` if the prefix does not exist.
     //
     // If this axis and `other` can't coexist, returns `std::nullopt` (see
     // AxisRefAttr::canCoexist).
     //
     // For example:
-    //  "a", "a":(2)2      -> "a":(2)2
+    //  "a", "a"           -> "a"
+    //  "a":(2)2, "a"      -> "a":(2)2
     //  "a":(2)2, "a":(2)2 -> "a":(2)2
-    //  "a":(1)4, "a":(2)4 -> "a":(2)2
-    //  "a":(2)4, "a":(1)4 -> "a":(2)2
     //  "a":(1)4, "a":(1)2 -> "a":(1)2
-    //  "a":(2)8, "a":(4)2 -> "a":(4)2
-    //  "a":(1)4, "a":(4)2 -> std::nullopt
-    //  "a":(1)2, "a":(4)2 -> std::nullopt
-    //  "a":(1)4, "b":(2)4 -> std::nullopt
+    //  "a":(2)8, "a":(1)4 -> "a":(2)2
+    //  "a", "b"           -> std::nullopt
+    //  "a":(2)2, "b"      -> std::nullopt
+    //  "a":(1)4, "a":(2)4 -> std::nullopt
     //  "a":(1)2, "a":(1)3 -> std::nullopt
     //  "a":(3)2, "a":(2)3 -> std::nullopt
-    std::optional<AxisRefAttr> getOverlap(AxisRefAttr other) const;
+    std::optional<AxisRefAttr> getPrefixWithOverlap(
+        AxisRefAttr other, MeshAttr mesh) const;
 
     // If there is no overlap between this axis and `other`, return this axis.
     // Otherwise, return the largest prefix of this axis by removing the
@@ -443,6 +443,26 @@ def Sdy_AxisRef : AttrDef<Sdy_Dialect, "AxisRef"> {
     //  "a":(1)2, "a":(2)4 -> std::nullopt
     std::optional<AxisRefAttr> getGreatestCommonPrefix(AxisRefAttr other) const;
 
+    // Removes the common prefix of this axis and `other` from this axis. If the
+    // two axes do not have common prefix or `other` is greater or equal to this
+    // axis, return `std::nullopt`.
+    //
+    // If this axis and `other` can't coexist, returns `std::nullopt` (see
+    // AxisRefAttr::canCoexist).
+    //
+    // For example:
+    //  "a", "a":(1)4      -> "a":(4)2 (size("a") == 8)
+    //  "a":(1)4, "a":(1)2 -> "a":(2)2
+    //  "a":(2)8, "a":(2)4 -> "a":(8)2
+    //  "a", "b"           -> std::nullopt
+    //  "a", "a"           -> std::nullopt
+    //  "a":(1)4, "a"      -> std::nullopt
+    //  "a":(2)4, "a":(2)8 -> std::nullopt
+    //  "a":(1)2, "a":(2)4 -> std::nullopt
+    //  "a":(1)2, "a":(1)3 -> std::nullopt
+    std::optional<AxisRefAttr> removeCommonPrefix(
+        AxisRefAttr prefix, MeshAttr mesh) const;
+
     // Returns whether this axis-ref can be merged with `other`, i.e., they are
     // consecutive sub-axes of the same full axis and this sub-axis is major to
     // `other`.
diff --git a/shardy/dialect/sdy/ir/constants.h b/shardy/dialect/sdy/ir/constants.h
index da2c7a4..0be03f5 100644
--- a/shardy/dialect/sdy/ir/constants.h
+++ b/shardy/dialect/sdy/ir/constants.h
@@ -35,30 +35,16 @@ inline constexpr StringRef kShardingRuleAttr = "sdy.sharding_rule";
 // caused a value to be sharded a certain way.
 inline constexpr StringRef kShardingOriginsAttr = "sdy.sharding_origins";
 
-// Attribute name for saving which operand/result sharding of an op caused its
-// value to be sharded a certain way.
-inline constexpr StringRef kPropagationEdgesAttr = "sdy.propagation_edges";
-
 // Attribute name like `kShardingOriginsAttr` but for
 // `ShardableDataFlowOpInterface` op block arguments.
 inline constexpr StringRef kBlockArgShardingOriginsAttr =
     "sdy.block_arg_sharding_origins";
 
-// Attribute name like `kPropagationEdgesAttr` but for
-// `ShardableDataFlowOpInterface` op block arguments.
-inline constexpr StringRef kBlockArgPropagationEdgesAttr =
-    "sdy.block_arg_propagation_edges";
-
 // Attribute name like `kShardingOriginsAttr` but for
 // `ShardableDataFlowOpInterface` op results.
 inline constexpr StringRef kResultShardingOriginsAttr =
     "sdy.result_sharding_origins";
 
-// Attribute name like `kPropagationEdgesAttr` but for
-// `ShardableDataFlowOpInterface` op results.
-inline constexpr StringRef kResultPropagationEdgesAttr =
-    "sdy.result_propagation_edges";
-
 // Attribute name for the unique name of a sharding origin. Is either an
 // `sdy.sharding_constraint`, or `sdy.ManualComputationOp` input/output.
 inline constexpr StringRef kShardingOriginNameAttr = "sdy.sharding_origin_name";
diff --git a/shardy/dialect/sdy/ir/dialect.cc b/shardy/dialect/sdy/ir/dialect.cc
index a912576..01ec501 100644
--- a/shardy/dialect/sdy/ir/dialect.cc
+++ b/shardy/dialect/sdy/ir/dialect.cc
@@ -436,22 +436,6 @@ bool AxisRefAttr::overlaps(AxisRefAttr other) const {
          otherSubAxisInfo.getPreSize() < thisSubAxisInfo.getNextPreSize();
 }
 
-namespace {
-
-bool canSubAxesCoexist(int64_t minPreSize, int64_t maxPreSize,
-                       int64_t minNextPreSize, int64_t maxNextPreSize) {
-  if (minNextPreSize > maxPreSize) {
-    // Sub-axes overlap, check if overlapping and non-overlapping parts are
-    // valid.
-    return minNextPreSize % maxPreSize == 0 && maxPreSize % minPreSize == 0 &&
-           maxNextPreSize % minNextPreSize == 0;
-  }
-  // Sub-axes don't overlap, check if the gap is valid.
-  return maxPreSize % minNextPreSize == 0;
-}
-
-}  // namespace
-
 bool AxisRefAttr::canCoexist(AxisRefAttr other) const {
   if (getName() != other.getName()) {
     return true;
@@ -473,46 +457,31 @@ bool AxisRefAttr::canCoexist(AxisRefAttr other) const {
   auto [minNextPreSize, maxNextPreSize] =
       std::minmax(thisNextPreSize, otherNextPreSize);
 
-  return canSubAxesCoexist(minPreSize, maxPreSize, minNextPreSize,
-                           maxNextPreSize);
+  if (minNextPreSize > maxPreSize) {
+    // Sub-axes overlap, check if overlapping and non-overlapping parts are
+    // valid.
+    return minNextPreSize % maxPreSize == 0 && maxPreSize % minPreSize == 0 &&
+           maxNextPreSize % minNextPreSize == 0;
+  }
+  // Sub-axes don't overlap, check if the gap is valid.
+  return maxPreSize % minNextPreSize == 0;
 }
 
-std::optional<AxisRefAttr> AxisRefAttr::getOverlap(AxisRefAttr other) const {
-  if (other.getName() != getName()) {
+std::optional<AxisRefAttr> AxisRefAttr::getPrefixWithOverlap(
+    AxisRefAttr other, MeshAttr mesh) const {
+  int64_t thisPreSize = getSubAxisPreSize();
+  if (!canCoexist(other) || !overlaps(other) ||
+      other.getSubAxisPreSize() > thisPreSize) {
     return std::nullopt;
   }
-
-  SubAxisInfoAttr thisSubAxisInfo = getSubAxisInfo();
-  SubAxisInfoAttr otherSubAxisInfo = other.getSubAxisInfo();
-
-  if (!thisSubAxisInfo) {
-    // This is a full axis.
-    return other;
-  }
-
-  if (!otherSubAxisInfo) {
-    // Other is a full axis.
+  if (other.contains(*this)) {
     return *this;
   }
-
-  int64_t thisPreSize = thisSubAxisInfo.getPreSize();
-  int64_t otherPreSize = otherSubAxisInfo.getPreSize();
-  int64_t thisNextPreSize = thisSubAxisInfo.getNextPreSize();
-  int64_t otherNextPreSize = otherSubAxisInfo.getNextPreSize();
-
-  auto [minPreSize, maxPreSize] = std::minmax(thisPreSize, otherPreSize);
-  auto [minNextPreSize, maxNextPreSize] =
-      std::minmax(thisNextPreSize, otherNextPreSize);
-
-  if (minNextPreSize <= maxPreSize ||
-      !canSubAxesCoexist(minPreSize, maxPreSize, minNextPreSize,
-                         maxNextPreSize)) {
-    // No overlap or can't co-exist.
-    return std::nullopt;
-  }
-
-  return AxisRefAttr::get(getContext(), getName(), maxPreSize,
-                          minNextPreSize / maxPreSize);
+  int64_t thisNextPreSize = getNextPreSizeOrFullSize(mesh);
+  int64_t otherNextPreSize = other.getNextPreSizeOrFullSize(mesh);
+  return AxisRefAttr::get(
+      getContext(), getName(), thisPreSize,
+      std::min(thisNextPreSize, otherNextPreSize) / thisPreSize);
 }
 
 std::optional<AxisRefAttr> AxisRefAttr::getPrefixWithoutOverlap(
@@ -587,6 +556,14 @@ std::optional<AxisRefAttr> AxisRefAttr::getGreatestCommonPrefix(
   return std::nullopt;
 }
 
+std::optional<AxisRefAttr> AxisRefAttr::removeCommonPrefix(
+    AxisRefAttr prefix, MeshAttr mesh) const {
+  if (!prefix.strictPrefixOf(*this)) {
+    return std::nullopt;
+  }
+  return getSuffixWithoutOverlap(prefix, mesh);
+}
+
 //===----------------------------------------------------------------------===//
 // DimensionShardingAttr
 //===----------------------------------------------------------------------===//
diff --git a/shardy/dialect/sdy/ir/dialect_test.cc b/shardy/dialect/sdy/ir/dialect_test.cc
index ffbf8de..cde0334 100644
--- a/shardy/dialect/sdy/ir/dialect_test.cc
+++ b/shardy/dialect/sdy/ir/dialect_test.cc
@@ -252,47 +252,57 @@ TEST_F(DialectTest, AxisRefAttrCompare) {
   compare(createSubAxis("x", 1, 4), createSubAxis("x", 2, 2));
 }
 
-TEST_F(DialectTest, AxisRefAttrGetOverlap) {
-  auto contained = [](AxisRefAttr small, AxisRefAttr large) {
-    EXPECT_TRUE(large.contains(small));
-    EXPECT_EQ(large.getOverlap(small), small);
-    EXPECT_EQ(small.getOverlap(large), small);
-  };
-  contained(createAxis("x"), createAxis("x"));
-  contained(createSubAxis("x", 1, 4), createAxis("x"));
-  contained(createSubAxis("x", 4, 8), createAxis("x"));
-  contained(createSubAxis("x", 2, 2), createSubAxis("x", 2, 2));
-  contained(createSubAxis("x", 1, 2), createSubAxis("x", 1, 4));
-  contained(createSubAxis("x", 2, 2), createSubAxis("x", 1, 4));
-  contained(createSubAxis("x", 2, 2), createSubAxis("x", 1, 8));
-
-  auto overlaps = [](AxisRefAttr a, AxisRefAttr b, AxisRefAttr expected) {
-    EXPECT_EQ(a.getOverlap(b), expected);
-    EXPECT_EQ(b.getOverlap(a), expected);
+TEST_F(DialectTest, AxisRefAttrGetPrefixWithOverlap) {
+  auto mesh = MeshAttr::get(&context, {MeshAxisAttr::get(&context, "x", 16),
+                                       MeshAxisAttr::get(&context, "y", 4)});
+  auto samePrefix = [&](AxisRefAttr a, AxisRefAttr b) {
+    AxisRefAttr smaller = std::min(a, b);
+    EXPECT_EQ(a.getPrefixWithOverlap(b, mesh), smaller);
+    EXPECT_EQ(b.getPrefixWithOverlap(a, mesh), smaller);
   };
-  overlaps(createSubAxis("x", 1, 4), createSubAxis("x", 2, 4),
-           createSubAxis("x", 2, 2));
-  overlaps(createSubAxis("x", 4, 4), createSubAxis("x", 2, 4),
-           createSubAxis("x", 4, 2));
+  samePrefix(createAxis("x"), createAxis("x"));
+  samePrefix(createSubAxis("x", 2, 2), createSubAxis("x", 2, 2));
+  samePrefix(createSubAxis("x", 1, 4), createSubAxis("x", 1, 2));
 
-  auto checkNoOverlap = [](AxisRefAttr a, AxisRefAttr b) {
-    EXPECT_FALSE(a.overlaps(b));
-    EXPECT_EQ(a.getOverlap(b), std::nullopt);
-    EXPECT_EQ(b.getOverlap(a), std::nullopt);
+  // "x":(2)4 and "x"
+  EXPECT_EQ(
+      createSubAxis("x", 2, 4).getPrefixWithOverlap(createAxis("x"), mesh),
+      createSubAxis("x", 2, 4));
+  EXPECT_EQ(
+      createAxis("x").getPrefixWithOverlap(createSubAxis("x", 2, 4), mesh),
+      std::nullopt);
+
+  // "x":(2)4 and "x":(1)4
+  EXPECT_EQ(createSubAxis("x", 2, 4).getPrefixWithOverlap(
+                createSubAxis("x", 1, 4), mesh),
+            createSubAxis("x", 2, 2));
+  EXPECT_EQ(createSubAxis("x", 1, 4).getPrefixWithOverlap(
+                createSubAxis("x", 2, 4), mesh),
+            std::nullopt);
+
+  // "x"(4)2 and "x":(2)8
+  EXPECT_EQ(createSubAxis("x", 4, 2).getPrefixWithOverlap(
+                createSubAxis("x", 2, 8), mesh),
+            createSubAxis("x", 4, 2));
+  EXPECT_EQ(createSubAxis("x", 2, 8).getPrefixWithOverlap(
+                createSubAxis("x", 4, 2), mesh),
+            std::nullopt);
+
+  auto checkNoOverlap = [&](AxisRefAttr a, AxisRefAttr b) {
+    EXPECT_EQ(a.getPrefixWithOverlap(b, mesh), std::nullopt);
+    EXPECT_EQ(b.getPrefixWithOverlap(a, mesh), std::nullopt);
   };
   checkNoOverlap(createAxis("x"), createAxis("y"));
   checkNoOverlap(createAxis("x"), createSubAxis("y", 1, 2));
   checkNoOverlap(createSubAxis("x", 1, 4), createSubAxis("x", 4, 2));
   checkNoOverlap(createSubAxis("x", 1, 2), createSubAxis("x", 4, 2));
 
-  auto checkCannotCoexist = [](AxisRefAttr a, AxisRefAttr b) {
-    EXPECT_FALSE(a.canCoexist(b));
-    EXPECT_EQ(a.getOverlap(b), std::nullopt);
-    EXPECT_EQ(b.getOverlap(a), std::nullopt);
+  auto checkCannotCoexist = [&](AxisRefAttr a, AxisRefAttr b) {
+    EXPECT_EQ(a.getPrefixWithOverlap(b, mesh), std::nullopt);
+    EXPECT_EQ(b.getPrefixWithOverlap(a, mesh), std::nullopt);
   };
-  checkCannotCoexist(createSubAxis("x", 1, 2), createSubAxis("x", 3, 2));
-  checkCannotCoexist(createSubAxis("x", 1, 3), createSubAxis("x", 2, 3));
-  checkCannotCoexist(createSubAxis("x", 2, 3), createSubAxis("x", 3, 2));
+  checkCannotCoexist(createSubAxis("x", 1, 2), createSubAxis("x", 1, 3));
+  checkCannotCoexist(createSubAxis("x", 3, 2), createSubAxis("x", 2, 3));
 }
 
 // The test cases are the same as DialectTest.AxisRefAttrOverlaps.
@@ -443,6 +453,36 @@ TEST_F(DialectTest, AxisRefAttrGetGreatestCommonPrefix) {
   prefix(createSubAxis("x", 2, 4), createSubAxis("x", 2, 8));
 }
 
+TEST_F(DialectTest, AxisRefAttrRemoveCommonPrefix) {
+  auto mesh = MeshAttr::get(&context, {MeshAxisAttr::get(&context, "x", 16),
+                                       MeshAxisAttr::get(&context, "y", 4)});
+  auto isNotPrefix = [&](AxisRefAttr a, AxisRefAttr b) {
+    EXPECT_EQ(a.removeCommonPrefix(b, mesh), std::nullopt);
+    EXPECT_EQ(b.removeCommonPrefix(a, mesh), std::nullopt);
+  };
+  isNotPrefix(createAxis("x"), createAxis("y"));
+  isNotPrefix(createSubAxis("x", 1, 2), createSubAxis("y", 1, 2));
+  isNotPrefix(createSubAxis("x", 1, 2), createSubAxis("x", 2, 4));
+  isNotPrefix(createSubAxis("x", 1, 2), createSubAxis("x", 1, 3));
+
+  auto equals = [&](AxisRefAttr a) {
+    EXPECT_EQ(a.removeCommonPrefix(a, mesh), std::nullopt);
+  };
+  equals(createAxis("x"));
+  equals(createSubAxis("x", 2, 4));
+
+  auto prefix = [&](AxisRefAttr small, AxisRefAttr large,
+                    AxisRefAttr expected) {
+    EXPECT_EQ(large.removeCommonPrefix(small, mesh), expected);
+    EXPECT_EQ(small.removeCommonPrefix(large, mesh), std::nullopt);
+  };
+  prefix(createSubAxis("x", 1, 4), createAxis("x"), createSubAxis("x", 4, 4));
+  prefix(createSubAxis("x", 1, 2), createSubAxis("x", 1, 4),
+         createSubAxis("x", 2, 2));
+  prefix(createSubAxis("x", 2, 4), createSubAxis("x", 2, 8),
+         createSubAxis("x", 8, 2));
+}
+
 TEST_F(DialectTest, TensorShardingAttrCanShardOrReplicate) {
   TensorShardingAttr sharding = createTensorSharding(
       {createDimSharding({createAxis("x"), createSubAxis("z", 2, 2)},
diff --git a/shardy/dialect/sdy/ir/verifiers.cc b/shardy/dialect/sdy/ir/verifiers.cc
index b6da095..4c15ee4 100644
--- a/shardy/dialect/sdy/ir/verifiers.cc
+++ b/shardy/dialect/sdy/ir/verifiers.cc
@@ -780,7 +780,8 @@ ArrayRef<AxisRefAttr>::iterator findManualAxisAfterFreeAxis(
 // For each set of op values (operands/results) and corresponding sharding for
 // each value, verifies:
 // 1. the sharding list itself wrt the mesh and `globalTypes`,
-// 2. the in/out shardings are valid w.r.t the corresponding global type,
+// 2. the in/out shardings are valid w.r.t the corresponding global
+//    type,
 // 3. the number of global and local tensor inputs/outputs of the op region
 //    match,
 // 4. the manual axes come before any free axes in each dim sharding,
@@ -815,7 +816,7 @@ LogicalResult verifyManualComputationValue(
     return failure();
   }
 
-  // 3. Verify the number of global and local tensor inputs/outputs of the op
+  // 4. Verify the number of global and local tensor inputs/outputs of the op
   //    region match.
   if (globalTypes.size() != localTypes.size()) {
     return op->emitOpError("number of op ")
@@ -829,7 +830,7 @@ LogicalResult verifyManualComputationValue(
            globalTypes, localTypes, shardingPerValueAttr.getShardings()))) {
     auto [globalType, localType, sharding] = valueEntry;
 
-    // 4. Verify the manual axes come before any free axes in each dim sharding.
+    // 5. Verify the manual axes come before any free axes in each dim sharding.
     for (auto [dim, dimSharding] :
          llvm::enumerate(sharding.getDimShardings())) {
       ArrayRef<AxisRefAttr> axes = dimSharding.getAxes();
@@ -845,7 +846,7 @@ LogicalResult verifyManualComputationValue(
       }
     }
 
-    // 5. Verify the global shape and local shapes of the op regions
+    // 6. Verify the global shape and local shapes of the op regions
     //    arguments/results match.
     SmallVector<int64_t> newDimSizes;
     auto globalRankedType = mlir::cast<RankedTensorType>(globalType);
@@ -872,7 +873,7 @@ LogicalResult verifyManualComputationValue(
              << ", actual local shape " << localRankedType;
     }
 
-    // 6. No manual axes are split.
+    // 7. No manual axes are split.
     if (sharding.anyOfAxisRef([&](AxisRefAttr axis) {
           return axis.getSubAxisInfo() &&
                  manualAxesSet.contains(axis.getName());
diff --git a/shardy/dialect/sdy/transforms/export/BUILD b/shardy/dialect/sdy/transforms/export/BUILD
index 767b1ab..20d67dc 100644
--- a/shardy/dialect/sdy/transforms/export/BUILD
+++ b/shardy/dialect/sdy/transforms/export/BUILD
@@ -58,7 +58,6 @@ cc_library(
         "//shardy/dialect/sdy/transforms/propagation:op_sharding_rule_registry",
         "//shardy/dialect/sdy/transforms/propagation:sharding_projection",
         "//shardy/dialect/sdy/transforms/propagation:utils",
-        "//shardy/dialect/sdy/transforms/propagation/debugging:source_sharding",
         "@llvm-project//llvm:Support",
         "@llvm-project//mlir:FuncDialect",
         "@llvm-project//mlir:IR",
diff --git a/shardy/dialect/sdy/transforms/export/passes.td b/shardy/dialect/sdy/transforms/export/passes.td
index 9a53737..e454dd7 100644
--- a/shardy/dialect/sdy/transforms/export/passes.td
+++ b/shardy/dialect/sdy/transforms/export/passes.td
@@ -28,19 +28,6 @@ def SinkDataFlowEdgesPass : Pass<"sdy-sink-data-flow-edges", "func::FuncOp"> {
   }];
   let dependentDialects = ["mlir::sdy::SdyDialect"];
   //TODO(tomnatan): consider moving the sharding to all targets that can have a sharding attached.
-
-  let options = [
-    Option<"sinkDebugShardingOrigins", "sink-debug-sharding-origins", "bool",
-           /*default=*/"false",
-           "Whether to sink the debug sharding origins info. See "
-           "`debug-sharding-origins` option in propagation for more info.">,
-    Option<"sinkDebugPropagationEdgeSharding",
-           "sink-debug-propagation-edge-sharding", "bool",
-           /*default=*/"false",
-           "Whether to sink the debug propagation edge sharding info. See "
-           "`debug-propagation-edge-sharding` option in propagation for more "
-           "info.">
-  ];
 }
 
 def UpdateNonDivisibleInputOutputShardingsPass : Pass<"sdy-update-non-divisible-input-output-shardings", "func::FuncOp"> {
diff --git a/shardy/dialect/sdy/transforms/export/reshard_to_collectives.cc b/shardy/dialect/sdy/transforms/export/reshard_to_collectives.cc
index 19ac62e..955f093 100644
--- a/shardy/dialect/sdy/transforms/export/reshard_to_collectives.cc
+++ b/shardy/dialect/sdy/transforms/export/reshard_to_collectives.cc
@@ -15,20 +15,17 @@ limitations under the License.
 
 #include <cassert>
 #include <cstdint>
-#include <functional>
 #include <iterator>
 #include <list>
 #include <memory>  // IWYU pragma: keep
 #include <optional>
+#include <set>
 #include <utility>
 
-#include "llvm/ADT/DenseMap.h"
 #include "llvm/ADT/STLExtras.h"
 #include "llvm/ADT/SmallVector.h"
 #include "mlir/Dialect/Func/IR/FuncOps.h"  // IWYU pragma: keep
-#include "mlir/IR/Attributes.h"
 #include "mlir/IR/Diagnostics.h"
-#include "mlir/IR/Location.h"
 #include "mlir/IR/MLIRContext.h"
 #include "mlir/IR/PatternMatch.h"
 #include "mlir/Pass/Pass.h"  // IWYU pragma: keep
@@ -49,13 +46,36 @@ namespace {
 
 using OptionalAxisRef = std::optional<AxisRefAttr>;
 
-using AxesPerDim = SmallVector<SmallVector<AxisRefAttr>>;
-
-// We use an std::list so we can pop from the front, back, and with a specific
+// We use an std::list so we can pop from the front and the back and with an
 // iterator at constant time.
+// TODO(tomnatan): Consider using AxisListRef instead of std::list once it can
+// also replace the first axis in the list with a different sub-axis.
 using AxisList = std::list<AxisRefAttr>;
 
-using AxisRefToDimMap = llvm::SmallDenseMap<AxisRefAttr, int64_t>;
+// We use an std::set so sub-axes are ordered by their pre-size and size, and
+// we can use set::lower_bound to find the first overlapping axis (see
+// getFirstOverlapping).
+using AvailableAxes = std::set<AxisRefAttr>;
+
+// Removes the common prefix of both `first` and `second`.
+void removeCommonPrefix(AxisList& first, AxisList& second, MeshAttr mesh) {
+  while (!first.empty() && !second.empty() && first.front() == second.front()) {
+    first.pop_front();
+    second.pop_front();
+  }
+  if (first.empty() || second.empty()) {
+    return;
+  }
+  if (OptionalAxisRef suffix =
+          first.front().removeCommonPrefix(second.front(), mesh)) {
+    first.front() = *suffix;
+    second.pop_front();
+  } else if (OptionalAxisRef suffix =
+                 second.front().removeCommonPrefix(first.front(), mesh)) {
+    second.front() = *suffix;
+    first.pop_front();
+  }
+}
 
 // Returns a vector of `InnerAxisList` per dimension from the given `sharding`.
 template <class InnerAxisList>
@@ -68,555 +88,304 @@ SmallVector<InnerAxisList> getAxesPerDim(TensorShardingAttr sharding) {
   return axesPerDim;
 }
 
-// Returns an iterator to the first axis in `orderedAxes` that overlaps with
-// `axis`, or `orderedAxes.end()` if there is no such axis.
-ArrayRef<AxisRefAttr>::iterator getFirstOverlapping(
-    AxisRefAttr axis, ArrayRef<AxisRefAttr> orderedAxes) {
-  if (orderedAxes.empty()) {
-    return orderedAxes.end();
+AvailableAxes::const_iterator getPrevOrEnd(AvailableAxes::iterator it,
+                                           const AvailableAxes& availableAxes) {
+  return it == availableAxes.begin() ? availableAxes.end() : std::prev(it);
+}
+
+// Returns an iterator to the first axis in `availableAxes` that overlaps with
+// `axis`, or `availableAxes.end()` if there is no such axis.
+AvailableAxes::iterator getFirstOverlapping(
+    AxisRefAttr axis, const AvailableAxes& availableAxes) {
+  if (availableAxes.empty()) {
+    return availableAxes.end();
   }
-  auto* afterIt = llvm::lower_bound(orderedAxes, axis);
+  auto afterIt = availableAxes.lower_bound(axis);
+  auto beforeIt = getPrevOrEnd(afterIt, availableAxes);
   // If there is at least one overlapping axis, the first one is necessarily
-  // `afterIt` or `beforeIt = std::prev(afterIt)`.
+  // `afterIt` or `beforeIt`.
   //
   // Proof:
-  // Given the definition of `lower_bound`, we have `beforeIt < A <= afterIt`,
-  // where A is `axis`.
+  // Let `axis` be A and the first overlapping axis in `availableAxes` be B.
   //
-  // - For any entry B with `B < beforeIt < A`, B and `beforeIt` cannot overlap.
-  //   Thus `beforeIt` isolates A and B such that they cannot overlap.
-  // - For any entry C with `A <= afterIt < C`, if A and C overlap, then A and
-  //   `afterIt` must overlap as well.
-
-  if (afterIt != orderedAxes.begin() && std::prev(afterIt)->overlaps(axis)) {
-    return std::prev(afterIt);
+  // Note that there can't be two overlapping available axes. `lower_bound`
+  // returns the first available axis greater or equal to A.
+  //
+  // * If `B >= A`, then there can't be another available axis C such that
+  //   `A <= C < B` since it would have to be overlapping with A and thus the
+  //   first overlapping axis instead of B. Therefore, `lower_bound` will
+  //   return B.
+  // * If `B < A`, then there can't be another available axis C such that
+  //   `B < C < A` since B and C can't overlap. Therefore, `lower_bound` will
+  //   return the axis after B, which doesn't overlap with A.
+
+  if (beforeIt != availableAxes.end() && beforeIt->overlaps(axis)) {
+    return beforeIt;
   }
-  if (afterIt != orderedAxes.end() && afterIt->overlaps(axis)) {
+  if (afterIt != availableAxes.end() && afterIt->overlaps(axis)) {
     return afterIt;
   }
-  return orderedAxes.end();
+  return availableAxes.end();
 }
 
-// Returns a map from `AxisRefAttr` to the dimension in `axesPerDim` that this
-// axis appears.
-AxisRefToDimMap getAxisRefToDimMap(ArrayRef<AxisList> axesPerDim) {
-  AxisRefToDimMap result;
-  for (auto [dim, axes] : llvm::enumerate(axesPerDim)) {
-    for (AxisRefAttr axis : axes) {
-      result.try_emplace(axis, dim);
-    }
+// Removes `availableAxis` from `availableAxes` and adds the prefix and suffix
+// of `availableAxis` that don't overlap with `overlap` back to `availableAxes`.
+//
+// We assume that `availableAxis` overlaps with `overlap`.
+void removeOverlapFromAvailable(AxisRefAttr availableAxis, AxisRefAttr overlap,
+                                AvailableAxes& availableAxes, MeshAttr mesh) {
+  availableAxes.erase(availableAxis);
+  if (OptionalAxisRef prefix = availableAxis.getPrefixWithoutOverlap(overlap)) {
+    availableAxes.insert(*prefix);
   }
-  return result;
-}
-
-SmallVector<AxisRefAttr> getOrderedAxes(ArrayRef<AxisList> axesPerDim) {
-  SmallVector<AxisRefAttr> result;
-  for (const AxisList& axes : axesPerDim) {
-    result.append(axes.begin(), axes.end());
+  if (OptionalAxisRef suffix =
+          availableAxis.getSuffixWithoutOverlap(overlap, mesh)) {
+    availableAxes.insert(*suffix);
   }
-  llvm::sort(result);
-  return result;
 }
 
-// Remove the common prefix of `inAxesPerDim` and `outAxesPerDim`.
-void removeCommonPrefix(SmallVector<AxisList>& inAxesPerDim,
-                        SmallVector<AxisList>& outAxesPerDim) {
-  for (auto [inAxes, outAxes] : llvm::zip_equal(inAxesPerDim, outAxesPerDim)) {
-    while (!inAxes.empty() && !outAxes.empty() &&
-           inAxes.front() == outAxes.front()) {
-      inAxes.pop_front();
-      outAxes.pop_front();
-    }
+// Adds `axis` to `availableAxes` and merges it with sub-axes in
+// `availableAxes` that can be merged with `axis`.
+//
+// We assume that `axis` doesn't overlap with any axis in `availableAxes`.
+void addAvailableAxis(AxisRefAttr axis, AvailableAxes& availableAxes,
+                      MeshAttr mesh) {
+  // `lower_bound` returns the first available axis greater or equal to `axis`,
+  // and we know `axis` doesn't overlap with any available axis.
+  auto afterIt = availableAxes.lower_bound(axis);
+  auto beforeIt = getPrevOrEnd(afterIt, availableAxes);
+  AxisRefAttr axisToAdd = axis;
+  // Try to merge `axisToAdd` with the first axis greater than it from the left.
+  if (afterIt != availableAxes.end() && axisToAdd.canMerge(*afterIt)) {
+    axisToAdd = axisToAdd.merge(*afterIt, mesh);
+    availableAxes.erase(afterIt);
   }
-}
 
-// In case an axis A in `axes` overlaps but isn't equal to an axis B in
-// `orderedOtherAxes`, decomposes A into 1-3 sub-axes (overlap and
-// non-overlapping prefix and suffix), and replaces A with the decomposed
-// sub-axes that form it.
-void alignSubAxesByDecomposition(AxisList& axes,
-                                 ArrayRef<AxisRefAttr> orderedOtherAxes,
-                                 MeshAttr mesh) {
-  auto axisIt = axes.begin();
-  while (axisIt != axes.end()) {
-    AxisRefAttr axis = *axisIt;
-    auto* overlapIt = getFirstOverlapping(axis, orderedOtherAxes);
-    // There are two paths to complete the while loop below:
-    // 1. the while condition is not met from the start, in which case we need
-    //    to advance `axisIt`.
-    // 2. we enter the while until the condition isn't met, in which case we
-    //    only need to advance `axisIt` if it points to a created suffix.
-    bool axisAdvancedInWhile = false;
-    while (overlapIt != orderedOtherAxes.end() && overlapIt->canCoexist(axis) &&
-           !overlapIt->contains(axis) && overlapIt->overlaps(axis)) {
-      axisIt = axes.erase(axisIt);
-      if (OptionalAxisRef prefix = axis.getPrefixWithoutOverlap(*overlapIt)) {
-        axes.insert(axisIt, *prefix);
-      }
-      axes.insert(axisIt, *axis.getOverlap(*overlapIt));
-      if (OptionalAxisRef suffix =
-              axis.getSuffixWithoutOverlap(*overlapIt, mesh)) {
-        // If there is a suffix, that should be the next axis to process.
-        axisIt = axes.insert(axisIt, *suffix);
-        axis = *suffix;
-        ++overlapIt;
-        axisAdvancedInWhile = false;
-      } else {
-        // Otherwise, we're done with the current axis.
-        axisAdvancedInWhile = true;
-        break;
-      }
-    }
-    if (!axisAdvancedInWhile) {
-      ++axisIt;
-    }
+  // Try to merge `axisToAdd` with the last axis less than it from the right.
+  if (beforeIt != availableAxes.end() && beforeIt->canMerge(axisToAdd)) {
+    axisToAdd = beforeIt->merge(axisToAdd, mesh);
+    availableAxes.erase(beforeIt);
   }
+  availableAxes.insert(axisToAdd);
 }
 
-// In case two `AxisRefAttr` in `inAxesPerDim` and `outAxesPerDim` respectively
-// overlap but aren't equal, decomposes them into up to three sub-axes (overlap
-// and non-overlapping prefix and suffix), and replaces each original axis with
-// the decomposed sub-axes that form it (see overload above).
-//
-// For example, "a":(1)8 and "a":(4)4 are decomposed into "a":(1)4, "a":(4)2,
-// and "a":(8)2. Then "a":(1)8 is replaced with ["a":(1)4, "a":(4)2] and
-// "a":(4)4 is replaced with ["a":(4)2, "a":(8)2].
-void alignSubAxesByDecomposition(SmallVector<AxisList>& inAxesPerDim,
-                                 SmallVector<AxisList>& outAxesPerDim,
-                                 MeshAttr mesh) {
-  SmallVector<AxisRefAttr> orderedInAxes = getOrderedAxes(inAxesPerDim);
-  SmallVector<AxisRefAttr> orderedOutAxes = getOrderedAxes(outAxesPerDim);
-  for (AxisList& inAxes : inAxesPerDim) {
-    alignSubAxesByDecomposition(inAxes, orderedOutAxes, mesh);
+// If there is a prefix of `axis` that fully overlaps with an axis in
+// `availableAxes`, returns that prefix and removes it from `availableAxes`.
+// Otherwise, returns `std::nullopt` and leaves `availableAxes` unchanged.
+std::optional<AxisRefAttr> takeAvailablePrefix(AxisRefAttr axis,
+                                               AvailableAxes& availableAxes,
+                                               MeshAttr mesh) {
+  // It's enough to check the first overlapping axis since any other overlapping
+  // axis would necessarily not fully overlap with a prefix of `axis`.
+  auto availableIt = getFirstOverlapping(axis, availableAxes);
+  if (availableIt == availableAxes.end()) {
+    return std::nullopt;
   }
-  for (AxisList& outAxes : outAxesPerDim) {
-    alignSubAxesByDecomposition(outAxes, orderedInAxes, mesh);
+  AxisRefAttr availableAxis = *availableIt;
+  if (OptionalAxisRef result = axis.getPrefixWithOverlap(availableAxis, mesh)) {
+    removeOverlapFromAvailable(availableAxis, *result, availableAxes, mesh);
+    return result;
   }
+  return std::nullopt;
 }
 
-// Removes the axes in `axesToPop` from the back of `currentAxes`.
+// Removes all axis refs in `axes` from `availableAxes`.
 //
-// Note that `axesToPop` can have decomposed sub-axes of an axis in
-// `currentAxes`, which is taken into account.
-void popBackFromCurrentAxes(SmallVector<AxisRefAttr>& currentAxes,
-                            const AxisList& axesToPop,
-                            AxisList::iterator startIt) {
-  for (auto it = axesToPop.rbegin(); it != std::make_reverse_iterator(startIt);
-       ++it) {
-    if (auto prefix = currentAxes.back().getPrefixWithoutOverlap(*it)) {
-      currentAxes.back() = *prefix;
-    } else {
-      currentAxes.pop_back();
-    }
+// We assume for every axis ref in `axes` there is exactly one axis ref in
+// `availableAxes` that contains it, and if they aren't equal, we remove the
+// containing axis and add back the prefix and suffix that don't overlap, if
+// exist.
+void removeUnavailableAxes(ArrayRef<AxisRefAttr> axes, MeshAttr mesh,
+                           AvailableAxes& availableAxes) {
+  for (AxisRefAttr axis : axes) {
+    removeOverlapFromAvailable(*getFirstOverlapping(axis, availableAxes), axis,
+                               availableAxes, mesh);
   }
 }
 
-struct AllToAllInfo {
-  SmallVector<AxisRefAttr> axes;
-  int64_t tgtDim;
-
-  explicit AllToAllInfo(int64_t tgtDim) : tgtDim(tgtDim) {}
-};
-
-// A class that applies an algorithm to transform an input sharding into an
-// output sharding via a sequence of collectives.
-//
-// The current sharding is initialized with the input sharding, and after each
-// collective insertion, the current sharding is updated w.r.t the collective,
-// until it matches the output sharding and we are done.
-//
-// We define the current state of the transformation as follows:
-//
-// - `inAxesPerDim` - the axes in the current sharding per dimension, such that
-//   the common prefix with the output sharding is removed.
-// - `outAxesPerDim` - the axes in the output sharding per dimension, such that
-//   the common prefix with the current sharding is removed.
-// - `currentAxesPerDim` - the axes in the current sharding, including the
-//   common prefix with the output sharding.
-//
-// These invariants are maintained throughout the algorithm, and specifically
-// after each collective insertion.
-//
-// We also maintain `inAxisToDimMap` and `outAxisToDimMap`, which are used to
-// find the dimension in `inAxesPerDim` and `outAxesPerDim` respectively where
-// a given axis ref appears. `inAxisToDimMap` is updated when in axes are
-// removed or moved to another dim, and `outAxisToDimMap` remains unchanged.
-//
-// Note that `inAxesPerDim` and `outAxesPerDim` represent the *diff* between the
-// current and output sharding, i.e., when they are empty the shardings match
-// exactly. The algorithm inserts collectives and updates the current state
-// accordingly, until both `inAxesPerDim` and `outAxesPerDim` are empty.
-class CollectiveInserter {
- public:
-  CollectiveInserter(TensorShardingAttr inSharding,
-                     TensorShardingAttr outSharding, MeshAttr mesh,
-                     Value result, ConversionPatternRewriter& rewriter,
-                     Location loc)
-      : rewriter(rewriter),
-        loc(loc),
-        mesh(mesh),
-        meshOrRef(inSharding.getMeshOrRef()),
-        result(result),
-        inAxesPerDim(getAxesPerDim<AxisList>(inSharding)),
-        outAxesPerDim(getAxesPerDim<AxisList>(outSharding)),
-        currentAxesPerDim(getAxesPerDim<SmallVector<AxisRefAttr>>(inSharding)),
-        collectiveAxesPerDim(inSharding.getRank()) {
-    // We align sub-axes between the input and output axes, so that we can treat
-    // sub-axes like full axes and assume any two sub-axes that overlap are also
-    // equal, which allows using them as keys in a hash map.
-    alignSubAxesByDecomposition(inAxesPerDim, outAxesPerDim, mesh);
-    // We remove the common prefix of `inAxesPerDim` and `outAxesPerDim`, since
-    // those axes stay exactly the same during the reshard. We are left with
-    // `inAxesPerDim` and `outAxesPerDim` that need to become empty, via a
-    // sequence of collectives.
-    removeCommonPrefix(inAxesPerDim, outAxesPerDim);
-
-    inAxisToDimMap = getAxisRefToDimMap(inAxesPerDim);
-    outAxisToDimMap = getAxisRefToDimMap(outAxesPerDim);
-  }
-
-  // Inserts a sequence of collectives to transform the input sharding into the
-  // output sharding, and returns the result of the final collective.
-  //
-  // If the input and output sharding are the same, returns the input value
-  // without inserting any collective.
-  Value insert() {
-    while (!isDone()) {
-      // 1. Try to insert an all-slice, that decreases the size of the tensor.
-      tryAllSlice();
-
-      // 2. Try to insert all-to-alls, that preserves the size of the tensor.
-      tryAllToAlls();
-
-      // 3. Try to insert an all-gather, that increases the size of the tensor.
-      tryAllGather();
-    }
-
-    return result;
+// Returns all available axes or sub-axes in `mesh` that aren't used in
+// `axesPerDim`.
+AvailableAxes getAvailableAxes(ArrayRef<SmallVector<AxisRefAttr>> axesPerDim,
+                               MeshAttr mesh) {
+  AvailableAxes unboundAxes;
+  for (MeshAxisAttr axis : mesh.getAxes()) {
+    unboundAxes.insert(AxisRefAttr::get(mesh.getContext(), axis.getName()));
   }
-
- private:
-  // Returns true if the input sharding has been transformed into the output
-  // sharding, i.e., both `inAxesPerDim` and `outAxesPerDim` are empty.
-  bool isDone() const {
-    return llvm::all_of(inAxesPerDim, std::mem_fn(&AxisList::empty)) &&
-           llvm::all_of(outAxesPerDim, std::mem_fn(&AxisList::empty));
-  }
-
-  MLIRContext* getContext() const { return rewriter.getContext(); }
-
-  int64_t getRank() const { return inAxesPerDim.size(); }
-
-  TensorShardingAttr getCurrentSharding() const {
-    return TensorShardingAttr::getClosed(getContext(), meshOrRef,
-                                         currentAxesPerDim);
+  for (ArrayRef<AxisRefAttr> axes : axesPerDim) {
+    removeUnavailableAxes(axes, mesh, unboundAxes);
   }
+  return unboundAxes;
+}
 
-  // If an all-gather can be performed on `dim`, returns the axes to gather for
-  // that dimension.
-  //
-  // We gather all axes in `gatheringAxes = inAxesPerDim[dim]`, and update the
-  // internal state as follows:
-  //
-  // - `inAxesPerDim[dim]` is cleared.
-  // - `gatheringAxes` are popped from the back of `currentAxesPerDim[dim]`.
-  //
-  // For example:
-  //
-  // Input: `dim = 1`
-  //
-  // Initial state:
-  // - `inAxesPerDim = [[], ["x", "y"]]`,
-  // - `outAxesPerDim = [[], []]`
-  // - `currentAxesPerDim = [["w"], ["z", "x", "y"]]`
-  //
-  // Returns: `["x", "y"]`, and updates:
-  // - `inAxesPerDim = [[], []]`,
-  // - `outAxesPerDim = [[], []]`
-  // - `currentAxesPerDim = [["w"], ["z"]]`
-  SmallVector<AxisRefAttr> getGatheringAxes(int64_t dim) {
-    AxisList& inAxes = inAxesPerDim[dim];
-    if (inAxes.empty()) {
-      return {};
-    }
-    SmallVector<AxisRefAttr>& currentAxes = currentAxesPerDim[dim];
-    SmallVector<AxisRefAttr> gatheringAxes;
-    gatheringAxes.reserve(inAxes.size());
-    popBackFromCurrentAxes(currentAxes, inAxes, inAxes.begin());
-    for (AxisRefAttr axis : inAxes) {
-      addAxisOrMerge(gatheringAxes, axis, mesh);
-      inAxisToDimMap.erase(axis);
-    }
-    inAxes.clear();
-    return gatheringAxes;
+// Returns the axes to slice for a specific dimension.
+//
+// If `inAxes` is empty, the prefix of `outAxes` that is available (i.e., fully
+// contained by axes in `availableAxes`) can be sliced. The slicing axes are
+// removed from `outAxes` and `availableAxes`, and added to `currentAxes`.
+SmallVector<AxisRefAttr> getSlicingAxes(const AxisList& inAxes,
+                                        AxisList& outAxes,
+                                        SmallVector<AxisRefAttr>& currentAxes,
+                                        AvailableAxes& availableAxes,
+                                        MeshAttr mesh) {
+  if (!inAxes.empty()) {
+    return {};
   }
-
-  // Tries to insert an `sdy.all_gather`.
-  void tryAllGather() {
-    bool hasGatheringAxes = false;
-    for (auto [dim, collectiveAxes] : llvm::enumerate(collectiveAxesPerDim)) {
-      SmallVector<AxisRefAttr> gatheringAxes = getGatheringAxes(dim);
-      if (!gatheringAxes.empty()) {
-        hasGatheringAxes = true;
-      }
-      collectiveAxes = AxisRefListAttr::get(getContext(), gatheringAxes);
-    }
-    if (hasGatheringAxes) {
-      result = rewriter.create<AllGatherOp>(loc, result, collectiveAxesPerDim,
-                                            getCurrentSharding());
+  SmallVector<AxisRefAttr> slicingAxes;
+  while (!outAxes.empty()) {
+    AxisRefAttr outAxis = outAxes.front();
+    std::optional<AxisRefAttr> availablePrefix =
+        takeAvailablePrefix(outAxis, availableAxes, mesh);
+    if (!availablePrefix) {
+      break;
     }
-  }
-
-  // TODO(b/392952931): currently we are greedily slicing and all-to-all-ing
-  // axes even if the destination dimension is too small to accommodate the
-  // extra axes. This would introduce padding which is sub-optimal, thus we
-  // should only do this if the dimension has enough space left, or slice as
-  // much as possible to fill the space.
-
-  // If an all-slice can be performed, returns the axes to slice for each
-  // dimension.
-  //
-  // For each dimension d, each axis X in `outAxesPerDim[d]` that isn't present
-  // in `inAxisToDimMap` (i.e., available to slice) is sliced as follows:
-  //
-  // - If the last axis Y before X in `outAxesPerDim[d]` that isn't sliced holds
-  //   `inAxisToDimMap[Y] == d`, or there isn't such an axis, then X is sliced
-  //   on that dimension.
-  // - Otherwise, X is sliced on the mapped dimension (`inAxisToDimMap[Y]`), so
-  //   we can later do an all-to-all on a smaller tensor to move both axes to
-  //   the other dimension.
-  //
-  // Returns std::nullopt if there are no slicing axes in any dimension.
-  //
-  // The internal state is updated as follows for each dimension `d` and the
-  // slicing axes on that dimension (`slicingAxes`):
-  //
-  // - `slicingAxes` are appended to `inAxesPerDim[d]` and
-  //   `currentAxesPerDim[d]`.
-  // - The common prefix between `inAxesPerDim[d]` and `outAxesPerDim[d]` is
-  //   removed from both.
-  //
-  // Note that this brings us closer to being done, i.e., having both
-  // `inAxesPerDim` and `outAxesPerDim` empty, because we take axes that are
-  // present in `outAxesPerDim` but not in `inAxesPerDim`, and either:
-  //
-  // - Remove them from `outAxesPerDim`, if they are where they need to be.
-  // - Add them to `inAxesPerDim` otherwise, which will allow us to perform an
-  //   all-to-all or collective-permute on them to get them to the right place.
-  //
-  // For example:
-  //
-  // Initial state:
-  // - `inAxesPerDim = [[], ["y"], []]`,
-  // - `outAxesPerDim = [["x"], [], ["y", "z", "w"]]`
-  // - `currentAxesPerDim = [["u"], ["y"], []]`
-  //
-  // Returns: `[["x"], ["z", "w"], []]`, and updates:
-  // - `inAxesPerDim = [[], ["y", "z", "w"], []]`,
-  // - `outAxesPerDim = [[], [], ["y", "z", "w"]]`
-  // - `currentAxesPerDim = [["u", "x"], ["y", "z", "w"], []]`
-  std::optional<AxesPerDim> getSlicingAxesPerDim() {
-    AxesPerDim slicingAxesPerDim(currentAxesPerDim.size());
-
-    bool hasSlicingAxes = false;
-    for (auto [outDim, outAxes] : llvm::enumerate(outAxesPerDim)) {
-      auto outIt = outAxes.begin();
-      std::optional<int64_t> lastInDim;
-      while (outIt != outAxes.end()) {
-        AxisRefAttr outAxis = *outIt;
-        if (auto inAxisEntryIt = inAxisToDimMap.find(outAxis);
-            inAxisEntryIt != inAxisToDimMap.end()) {
-          // Out axis isn't available to slice.
-          lastInDim = inAxisEntryIt->second;
-          ++outIt;
-          continue;
-        }
-        // We should slice `outAxis` at `lastInDim` if present or `outDim`
-        // otherwise.
-        hasSlicingAxes = true;
-        int64_t slicingDim = lastInDim.value_or(outDim);
-        addAxisOrMerge(slicingAxesPerDim[slicingDim], outAxis, mesh);
-        addAxisOrMerge(currentAxesPerDim[slicingDim], outAxis, mesh);
-        AxisList& inAxes = inAxesPerDim[slicingDim];
-        if (inAxes.empty() && outIt == outAxes.begin()) {
-          // Slicing axis is where it needs to be.
-          outIt = outAxes.erase(outIt);
-        } else {
-          inAxisToDimMap.try_emplace(outAxis, slicingDim);
-          inAxes.push_back(outAxis);
-          ++outIt;
-        }
-      }
+    slicingAxes.push_back(*availablePrefix);
+    addAxisOrMerge(currentAxes, *availablePrefix, mesh);
+    outAxes.pop_front();
+    if (*availablePrefix != outAxis) {
+      // Safe to dereference since we know `availablePrefix` and `outAxis` have
+      // a common prefix and aren't equal.
+      outAxes.push_front(
+          *outAxis.getSuffixWithoutOverlap(*availablePrefix, mesh));
+      break;
     }
-
-    return hasSlicingAxes ? std::make_optional(slicingAxesPerDim)
-                          : std::nullopt;
   }
+  return slicingAxes;
+}
 
-  // Tries to insert an `sdy.all_slice`.
-  void tryAllSlice() {
-    if (std::optional<AxesPerDim> slicingAxesPerDim = getSlicingAxesPerDim()) {
-      for (auto [collectiveAxes, slicingAxes] :
-           llvm::zip_equal(collectiveAxesPerDim, *slicingAxesPerDim)) {
-        collectiveAxes = AxisRefListAttr::get(getContext(), slicingAxes);
-      }
-      result = rewriter.create<AllSliceOp>(loc, result, collectiveAxesPerDim,
-                                           getCurrentSharding());
-    }
+// Returns the axes to gather for a specific dimension.
+//
+// All axes in `inAxes` are gathered greedily. The gathering axes are removed
+// from `availableAxes`, popped from the back of `currentAxes`, and `inAxes` is
+// cleared.
+SmallVector<AxisRefAttr> getGatheringAxes(AxisList& inAxes,
+                                          SmallVector<AxisRefAttr>& currentAxes,
+                                          AvailableAxes& availableAxes,
+                                          MeshAttr mesh) {
+  if (inAxes.empty()) {
+    return {};
   }
-
-  // If an all-to-all can be performed for the given source dimension `srcDim`,
-  // returns the axes and target dimension of this all-to-all.
-  //
-  // The suffix of axes in `inAxesPerDim[srcDim]` that are mapped to the same
-  // dimension in `outAxisToDimMap` are all-to-all-ed with the mapped dimension
-  // as the target (tgtDim).
-  //
-  // The internal state is updated as follows for `allToAllAxes` and `tgtDim`:
-  //
-  // - `allToAllAxes` are popped from the back of `inAxesPerDim[srcDim]` and
-  //   `currentAxesPerDim[srcDim]`.
-  // - `allToAllAxes` are appended to `inAxesPerDim[tgtDim]` and
-  //   `currentAxesPerDim[tgtDim]`.
-  // - The common prefix between `inAxesPerDim[tgtDim]` and
-  //   `outAxesPerDim[tgtDim]` is removed from both.
-  //
-  // Note that this brings us closer to being done, i.e., having both
-  // `inAxesPerDim` and `outAxesPerDim` empty, because we move axes from
-  // `inAxesPerDim[srcDim]` to either:
-  //
-  // - Where they need to be in `tgtDim`, in which case they are removed from
-  //   `outAxesPerDim[tgtDim]`.
-  // - Move axes from `inAxesPerDim[srcDim]` to `inAxesPerDim[tgtDim]`, which
-  //   will allow us to perform a collective permute on them to get them to the
-  //   right place.
-  //
-  // For example:
-  //
-  // Input: `srcDim = 1`
-  //
-  // Initial state:
-  // - `inAxesPerDim = [["w"], ["x", "y", "z"], []]`,
-  // - `outAxesPerDim = [["x"], [], ["y", "z"]]`
-  // - `currentAxesPerDim = [["w"], ["x", "y", "z"], []]`
-  //
-  // First call returns: `{axes = ["y", "z"], tgtDim = 2}`, and updates:
-  // - `inAxesPerDim = [["w"], ["x"], []]`,
-  // - `outAxesPerDim = [["x"], [], []]`
-  // - `currentAxesPerDim = [["w"], ["x"], ["y", "z"]]`
-  //
-  // Second call returns: `{axes = ["x"], tgtDim = 0}`, and updates:
-  // - `inAxesPerDim = [["w", "x"], [], []]`,
-  // - `outAxesPerDim = [["x"], [], []]`
-  // - `currentAxesPerDim = [["w", "x"], [], ["y", "z"]]`
-  std::optional<AllToAllInfo> getAllToAllInfo(int64_t srcDim) {
-    AxisList& srcInAxes = inAxesPerDim[srcDim];
-
-    auto axisRevIt = srcInAxes.rbegin();
-    int64_t numAxes = 0;
-    std::optional<int64_t> optTgtDim;
-    for (; axisRevIt != srcInAxes.rend(); ++axisRevIt) {
-      auto outAxisEntryIt = outAxisToDimMap.find(*axisRevIt);
-      if (outAxisEntryIt == outAxisToDimMap.end()) {
-        break;
-      }
-      int64_t outAxisDim = outAxisEntryIt->second;
-      if (outAxisDim == srcDim || (optTgtDim && outAxisDim != *optTgtDim)) {
-        break;
-      }
-      optTgtDim = outAxisDim;
-      ++numAxes;
-    }
-
-    if (!optTgtDim) {
-      // Can't do an all-to-all from `srcDim` to any dimension.
-      return std::nullopt;
-    }
-
-    auto startInAxisIt = axisRevIt.base();
-
-    AllToAllInfo result(*optTgtDim);
-    auto& [allToAllAxes, tgtDim] = result;
-    allToAllAxes.reserve(numAxes);
-
-    SmallVector<AxisRefAttr>& srcCurrentAxes = currentAxesPerDim[srcDim];
-    SmallVector<AxisRefAttr>& tgtCurrentAxes = currentAxesPerDim[tgtDim];
-
-    popBackFromCurrentAxes(srcCurrentAxes, srcInAxes, startInAxisIt);
-
-    AxisList& tgtInAxes = inAxesPerDim[tgtDim];
-    AxisList& tgtOutAxes = outAxesPerDim[tgtDim];
-    auto srcInAxisIt = startInAxisIt;
-    while (srcInAxisIt != srcInAxes.end()) {
-      AxisRefAttr axis = *srcInAxisIt;
-      addAxisOrMerge(allToAllAxes, axis, mesh);
-      addAxisOrMerge(tgtCurrentAxes, axis, mesh);
-      srcInAxisIt = srcInAxes.erase(srcInAxisIt);
-      inAxisToDimMap.erase(axis);
-      if (tgtInAxes.empty() && tgtOutAxes.front() == axis) {
-        tgtOutAxes.pop_front();
-      } else {
-        tgtInAxes.push_back(axis);
-        inAxisToDimMap.try_emplace(axis, tgtDim);
-      }
-    }
-
-    return result;
+  SmallVector<AxisRefAttr> gatheringAxes = llvm::to_vector(inAxes);
+  currentAxes.pop_back_n(inAxes.size() - 1);
+  if (OptionalAxisRef prefix =
+          currentAxes.back().getPrefixWithoutOverlap(inAxes.front())) {
+    currentAxes.back() = *prefix;
+  } else {
+    currentAxes.pop_back();
   }
 
-  // Tries to insert a sequence of `sdy.all_to_all`s.
-  void tryAllToAlls() {
-    bool allToAllCreated = false;
-    do {
-      allToAllCreated = false;
-      for (int64_t srcDim = 0; srcDim < getRank(); ++srcDim) {
-        if (auto info = getAllToAllInfo(srcDim)) {
-          result =
-              rewriter.create<AllToAllOp>(loc, result, srcDim, info->tgtDim,
-                                          info->axes, getCurrentSharding());
-          allToAllCreated = true;
-        }
-      }
-    } while (allToAllCreated);
+  for (AxisRefAttr axis : inAxes) {
+    addAvailableAxis(axis, availableAxes, mesh);
   }
-
-  ConversionPatternRewriter& rewriter;
-  Location loc;
-  MeshAttr mesh;
-  Attribute meshOrRef;
-  Value result;
-  SmallVector<AxisList> inAxesPerDim, outAxesPerDim;
-  AxesPerDim currentAxesPerDim;
-  SmallVector<AxisRefListAttr> collectiveAxesPerDim;
-  AxisRefToDimMap inAxisToDimMap, outAxisToDimMap;
-};
+  inAxes.clear();
+  return gatheringAxes;
+}
 
 class ReshardPattern : public OpConversionPattern<ReshardOp> {
  public:
   using OpConversionPattern::OpConversionPattern;
 
  private:
+  // For the moment we only consider all_gather and all_slice.
+  // TODO(b/380226848): Add support for other collectives.
   LogicalResult matchAndRewrite(
       ReshardOp op, OpAdaptor adaptor,
       ConversionPatternRewriter& rewriter) const override {
-    TensorShardingAttr inSharding = getSharding(adaptor.getInput());
-    TensorShardingAttr outSharding = adaptor.getSharding();
+    TensorShardingAttr inputSharding = getSharding(adaptor.getInput());
+    TensorShardingAttr outputSharding = adaptor.getSharding();
     // Here it's safe to assume that shardings' meshes have a name.
-    if (inSharding.getRank() != outSharding.getRank() ||
-        inSharding.getMeshName() != outSharding.getMeshName()) {
+    if (inputSharding.getRank() != outputSharding.getRank() ||
+        inputSharding.getMeshName() != outputSharding.getMeshName()) {
       return rewriter.notifyMatchFailure(
           op, [](Diagnostic& diag) { diag << "Incompatible shardings"; });
     }
+    int64_t rank = inputSharding.getRank();
 
     // TODO(tomnatan): we should verify that the operand of ReshardOp has a
     // sharding.
     // TODO(tomnatan): use a SymbolTable.
 
-    CollectiveInserter collectiveInserter(
-        inSharding, outSharding, inSharding.getMesh(op), adaptor.getInput(),
-        rewriter, op.getLoc());
-    rewriter.replaceOp(op, collectiveInserter.insert());
+    MeshAttr mesh = inputSharding.getMesh(op);
+    SmallVector<AxisList> inAxesPerDim = getAxesPerDim<AxisList>(inputSharding);
+    SmallVector<AxisList> outAxesPerDim =
+        getAxesPerDim<AxisList>(outputSharding);
+    // We remove the common prefix of `inAxes` and `outAxes`, since those axes
+    // stay exactly the same during the reshard. We are left with `inAxes` that
+    // need to be transformed into `outAxes`, via a sequence of collectives.
+    for (auto [inAxes, outAxes] :
+         llvm::zip_equal(inAxesPerDim, outAxesPerDim)) {
+      removeCommonPrefix(inAxes, outAxes, mesh);
+    }
+
+    auto hasRemainingAxes = [](const AxisList& axes) { return !axes.empty(); };
+    bool hasRemainingInAxes = llvm::any_of(inAxesPerDim, hasRemainingAxes);
+    bool hasRemainingOutAxes = llvm::any_of(outAxesPerDim, hasRemainingAxes);
+
+    if (!hasRemainingInAxes && !hasRemainingOutAxes) {
+      rewriter.replaceOp(op, adaptor.getInput());
+      return success();
+    }
+
+    SmallVector<SmallVector<AxisRefAttr>> currentAxesPerDim =
+        getAxesPerDim<SmallVector<AxisRefAttr>>(inputSharding);
+    AvailableAxes availableAxes = getAvailableAxes(currentAxesPerDim, mesh);
+
+    Value input = adaptor.getInput();
+    MLIRContext* context = rewriter.getContext();
+
+    auto getCurrentSharding = [&]() {
+      return TensorShardingAttr::getClosed(
+          context, inputSharding.getMeshOrRef(), currentAxesPerDim);
+    };
+
+    SmallVector<AxisRefListAttr> collectiveAxesPerDim(rank);
+
+    // We aren't done until both `inAxesPerDim` and `outAxesPerDim` are
+    // empty.
+    // TODO(b/380226848): this is an initial implementation that only inserts
+    // all-gathers and all-slices, and greedily all-gathers axes after the first
+    // attempt to insert an all-slice.
+    while (hasRemainingInAxes || hasRemainingOutAxes) {
+      // 1. Try to insert an all-slice first, as it decreases the size of the
+      // tensor.
+      hasRemainingOutAxes = false;
+      bool hasSlicingAxes = false;
+      for (auto [inAxes, outAxes, currentAxes, collectiveAxes] :
+           llvm::zip_equal(inAxesPerDim, outAxesPerDim, currentAxesPerDim,
+                           collectiveAxesPerDim)) {
+        SmallVector<AxisRefAttr> slicingAxes =
+            getSlicingAxes(inAxes, outAxes, currentAxes, availableAxes, mesh);
+        if (!slicingAxes.empty()) {
+          hasSlicingAxes = true;
+        }
+        if (!outAxes.empty()) {
+          hasRemainingOutAxes = true;
+        }
+        collectiveAxes = AxisRefListAttr::get(context, slicingAxes);
+      }
+      if (hasSlicingAxes) {
+        input = rewriter.create<AllSliceOp>(
+            op.getLoc(), input, collectiveAxesPerDim, getCurrentSharding());
+      }
+
+      // 2. Try to insert an all-gather, that increases the size of the tensor.
+      hasRemainingInAxes = false;
+      bool hasGatheringAxes = false;
+      for (auto [inAxes, currentAxes, collectiveAxes] : llvm::zip_equal(
+               inAxesPerDim, currentAxesPerDim, collectiveAxesPerDim)) {
+        SmallVector<AxisRefAttr> gatheringAxes =
+            getGatheringAxes(inAxes, currentAxes, availableAxes, mesh);
+        if (!gatheringAxes.empty()) {
+          hasGatheringAxes = true;
+        }
+        collectiveAxes = AxisRefListAttr::get(context, gatheringAxes);
+      }
+      if (hasGatheringAxes) {
+        input = rewriter.create<AllGatherOp>(
+            op.getLoc(), input, collectiveAxesPerDim, getCurrentSharding());
+      }
+    }
 
+    rewriter.replaceOp(op, input);
     return success();
   }
 };
@@ -628,7 +397,7 @@ struct ReshardToCollectivesPass
   LogicalResult initialize(MLIRContext* context) final {
     target = std::make_shared<ConversionTarget>(*context);
     target->addIllegalOp<ReshardOp>();
-    target->addLegalOp<AllGatherOp, AllSliceOp, AllToAllOp>();
+    target->addLegalOp<AllGatherOp, AllSliceOp>();
 
     RewritePatternSet patternsInternal(context);
     patternsInternal.add<ReshardPattern>(context);
diff --git a/shardy/dialect/sdy/transforms/export/sink_data_flow_edges.cc b/shardy/dialect/sdy/transforms/export/sink_data_flow_edges.cc
index e54a0cf..6873d22 100644
--- a/shardy/dialect/sdy/transforms/export/sink_data_flow_edges.cc
+++ b/shardy/dialect/sdy/transforms/export/sink_data_flow_edges.cc
@@ -30,10 +30,9 @@ limitations under the License.
 #include "mlir/IR/Visitors.h"
 #include "mlir/Pass/Pass.h"  // IWYU pragma: keep
 #include "mlir/Support/LLVM.h"
+#include "shardy/dialect/sdy/ir/constants.h"
 #include "shardy/dialect/sdy/ir/dialect.h"
 #include "shardy/dialect/sdy/ir/utils.h"
-#include "shardy/dialect/sdy/transforms/export/passes.h"  // IWYU pragma: keep
-#include "shardy/dialect/sdy/transforms/propagation/debugging/source_sharding.h"
 
 namespace mlir {
 namespace sdy {
@@ -82,6 +81,44 @@ SmallVector<TensorShardingAttr> getShardingsFromDataFlowEdges(
   return shardings;
 }
 
+// Saves an array of all the origin sharding dictionaries for the given
+// `edgeOwners` on `op`. If non exist, nothing is saved.
+//
+// For debugging the origin shardings, we want to preserve the origin sharding
+// dictionaries from the `DataFlowEdgeOp`s on the owning op so that they are
+// preserved after the propagation pipeline.
+//
+// See the `debug-sharding-origins` config on propagation for more details.
+//
+// TODO(b/388458831): add `saveDebugPropagationInfo` to the pass and pass it in
+// here. Can then reserve the right size for `originShardingDicts` and not need
+// the `exists` boolean.
+void buildOriginShardingDictsFromDataFlowEdges(ValueRange edgeOwners,
+                                               Operation* op,
+                                               StringRef attrName,
+                                               IRRewriter& rewriter) {
+  SmallVector<Attribute> originShardingDicts;
+  // TODO(b/388458831): pass through a boolean indicating whether the origin
+  // sharding debug information is enabled.
+  bool exists = false;
+  for (Value edgeOwner : edgeOwners) {
+    DictionaryAttr dict;
+    if (auto dataFlowEdgeOp = DataFlowEdgeOp::lookup(edgeOwner)) {
+      dict =
+          dataFlowEdgeOp->getAttrOfType<DictionaryAttr>(kShardingOriginsAttr);
+    }
+    if (!dict) {
+      dict = rewriter.getDictionaryAttr({});
+    } else {
+      exists = true;
+    }
+    originShardingDicts.push_back(dict);
+  }
+  if (exists) {
+    op->setAttr(attrName, rewriter.getArrayAttr(originShardingDicts));
+  }
+}
+
 struct SinkDataFlowEdgesPass
     : public impl::SinkDataFlowEdgesPassBase<SinkDataFlowEdgesPass> {
   using SinkDataFlowEdgesPassBase::SinkDataFlowEdgesPassBase;
@@ -115,9 +152,8 @@ struct SinkDataFlowEdgesPass
         shardableDataFlowOp.setBlockArgumentEdgeOwnerShardings(
             blockArgShardings);
       }
-      saveDebugInfoDictsFromDataFlowEdges(
-          blockArgOwners, op, sinkDebugShardingOrigins,
-          sinkDebugPropagationEdgeSharding, EdgeNodeType::OPERAND, rewriter);
+      buildOriginShardingDictsFromDataFlowEdges(
+          blockArgOwners, op, kBlockArgShardingOriginsAttr, rewriter);
 
       ResultRange resultOwners = shardableDataFlowOp.getOpResultEdgeOwners();
       if (SmallVector<TensorShardingAttr> resultShardings =
@@ -125,9 +161,8 @@ struct SinkDataFlowEdgesPass
           !resultShardings.empty()) {
         shardableDataFlowOp.setOpResultEdgeOwnerShardings(resultShardings);
       }
-      saveDebugInfoDictsFromDataFlowEdges(
-          resultOwners, op, sinkDebugShardingOrigins,
-          sinkDebugPropagationEdgeSharding, EdgeNodeType::RESULT, rewriter);
+      buildOriginShardingDictsFromDataFlowEdges(
+          resultOwners, op, kResultShardingOriginsAttr, rewriter);
       return WalkResult::advance();
     });
   }
diff --git a/shardy/dialect/sdy/transforms/export/test/insert_explicit_reshards.mlir b/shardy/dialect/sdy/transforms/export/test/insert_explicit_reshards.mlir
index 8e4da5f..acb871e 100644
--- a/shardy/dialect/sdy/transforms/export/test/insert_explicit_reshards.mlir
+++ b/shardy/dialect/sdy/transforms/export/test/insert_explicit_reshards.mlir
@@ -1156,124 +1156,3 @@ func.func @select_scalar_pred(%arg0: tensor<i1>, %arg1: tensor<4x8xf32> {sdy.sha
   %0 = stablehlo.select %arg0, %arg1, %arg2 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{}, {}]>]>} : (tensor<i1>, tensor<4x8xf32>, tensor<4x8xf32>) -> tensor<4x8xf32>
   return %0 : tensor<4x8xf32>
 }
-
-// CHECK-LABEL: func @while
-func.func @while(%arg0: tensor<210xf32> {sdy.sharding = #sdy.sharding<@mesh, [{"x"}]>}) -> (tensor<210xf32> {sdy.sharding = #sdy.sharding<@mesh, [{"y"}]>}) {
-  %c = stablehlo.constant dense<0> : tensor<i32>
-  %c_0 = stablehlo.constant dense<1> : tensor<i32>
-  %c_1 = stablehlo.constant dense<32> : tensor<i32>
-  %c_2 = stablehlo.constant dense<0.0> : tensor<f32>
-  // TODO(enver): Reshard input to [y].
-  %0:2 = stablehlo.while(%iterArg = %arg0, %iterArg_2 = %c) : tensor<210xf32>, tensor<i32> attributes {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"y"}]>, <@mesh, []>]>}
-    cond {
-    %2 = stablehlo.compare  LT, %iterArg_2, %c_1 : (tensor<i32>, tensor<i32>) -> tensor<i1>
-    %3 = stablehlo.dot %iterArg, %iterArg : (tensor<210xf32>, tensor<210xf32>) -> tensor<f32>
-    %4 = stablehlo.compare  LT, %3, %c_2 : (tensor<f32>, tensor<f32>) -> tensor<i1>
-    %5 = stablehlo.and %2, %4 : (tensor<i1>, tensor<i1>) -> tensor<i1>
-    stablehlo.return %5 : tensor<i1>
-  } do {
-    %2 = stablehlo.add %iterArg_2, %c_0 : tensor<i32>
-    // CHECK: %[[RESHARD:.*]] = sdy.reshard %iterArg <@mesh, [{"x"}]> : tensor<210xf32>
-    // CHECK-NEXT: stablehlo.negate %[[RESHARD]]
-    %3 = stablehlo.negate %iterArg {sdy.sharding= #sdy.sharding_per_value<[<@mesh, [{"x"}]>]>} : tensor<210xf32>
-    %4 = stablehlo.add %3, %3 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"x"}]>]>}: tensor<210xf32>
-    // TODO(enver): Reshard input to [y].
-    stablehlo.return %4, %2 : tensor<210xf32>, tensor<i32>
-  }
-  %1 = stablehlo.negate %0#0 {sdy.sharding= #sdy.sharding_per_value<[<@mesh, [{"y"}]>]>} : tensor<210xf32>
-  return %1 : tensor<210xf32>
-}
-
-// CHECK-LABEL: func @while_missing_sharding
-func.func @while_missing_sharding(%arg0: tensor<210xf32> {sdy.sharding = #sdy.sharding<@mesh, [{"x"}]>}) -> (tensor<210xf32>) {
-  %c = stablehlo.constant dense<0> : tensor<i32>
-  %c_0 = stablehlo.constant dense<1> : tensor<i32>
-  %c_1 = stablehlo.constant dense<32> : tensor<i32>
-  %c_2 = stablehlo.constant dense<0.0> : tensor<f32>
-  // TODO(enver): Reshard input to [].
-  %0:2 = stablehlo.while(%iterArg = %arg0, %iterArg_2 = %c) : tensor<210xf32>, tensor<i32>
-    cond {
-    %2 = stablehlo.compare  LT, %iterArg_2, %c_1 : (tensor<i32>, tensor<i32>) -> tensor<i1>
-    %3 = stablehlo.dot %iterArg, %iterArg : (tensor<210xf32>, tensor<210xf32>) -> tensor<f32>
-    %4 = stablehlo.compare  LT, %3, %c_2 : (tensor<f32>, tensor<f32>) -> tensor<i1>
-    %5 = stablehlo.and %2, %4 : (tensor<i1>, tensor<i1>) -> tensor<i1>
-    stablehlo.return %5 : tensor<i1>
-  } do {
-    %2 = stablehlo.add %iterArg_2, %c_0 : tensor<i32>
-    // CHECK: %[[RESHARD:.*]] = sdy.reshard %iterArg <@mesh, [{"x"}]> : tensor<210xf32>
-    // CHECK-NEXT: stablehlo.negate %[[RESHARD]]
-    %3 = stablehlo.negate %iterArg {sdy.sharding= #sdy.sharding_per_value<[<@mesh, [{"x"}]>]>} : tensor<210xf32>
-    %4 = stablehlo.add %3, %3 {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"x"}]>]>}: tensor<210xf32>
-    // TODO(enver): Reshard block result to [].
-    stablehlo.return %4, %2 : tensor<210xf32>, tensor<i32>
-  }
-  %1 = stablehlo.negate %0#0 : tensor<210xf32>
-  return %1: tensor<210xf32>
-}
-
-// CHECK-LABEL: func @case
-func.func @case(%arg0: tensor<210xf32> {sdy.sharding = #sdy.sharding<@mesh, [{"x":(1)2}]>}, %arg1: tensor<i32>) -> (tensor<210xf32> {sdy.sharding = #sdy.sharding<@mesh, [{"y"}]>}) {
-  %0 = "stablehlo.case"(%arg1) ({
-    // CHECK: %[[RESHARD:.*]] = sdy.reshard %arg0 <@mesh, [{"x"}]> : tensor<210xf32>
-    // CHECK-NEXT: stablehlo.abs %[[RESHARD]]
-    %2 = stablehlo.abs %arg0 {sdy.sharding=#sdy.sharding_per_value<[<@mesh, [{"x"}]>]>} : tensor<210xf32>
-    // TODO(enver): Reshard block result to [y].
-    stablehlo.return %2 : tensor<210xf32>
-  }, {
-    %2 = stablehlo.cosine %arg0 {sdy.sharding=#sdy.sharding_per_value<[<@mesh, [{"y"}]>]>} : tensor<210xf32>
-    // CHECK: %[[RESHARD:.*]] = sdy.reshard %2 <@mesh, [{"y"}]> : tensor<210xf32>
-    // CHECK-NEXT: stablehlo.abs %[[RESHARD]]
-    %3 = stablehlo.abs %2 {sdy.sharding=#sdy.sharding_per_value<[<@mesh, [{"y"}]>]>} : tensor<210xf32>
-    stablehlo.return %3 : tensor<210xf32>
-  }, {
-    %2 = stablehlo.abs %arg0 {sdy.sharding=#sdy.sharding_per_value<[<@mesh, [{"x":(1)2}]>]>} : tensor<210xf32>
-    // TODO(enver): Reshard block result to [y].
-    stablehlo.return %2 : tensor<210xf32>
-  }) {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"y"}]>]>} : (tensor<i32>) -> tensor<210xf32>
-  %1 = stablehlo.negate %0 {sdy.sharding= #sdy.sharding_per_value<[<@mesh, [{"y"}]>]>} : tensor<210xf32>
-  return %1 : tensor<210xf32>
-}
-
-// CHECK-LABEL: func @named_computation
-func.func @named_computation(%arg0: tensor<210xf32> {sdy.sharding = #sdy.sharding<@mesh, [{"x":(1)2}]>}) -> (tensor<210xf32> {sdy.sharding = #sdy.sharding<@mesh, [{"y"}]>}) {
-  // TODO(enver): Reshard input to [x].
-  %0 = sdy.named_computation<"foo">(%arg0) in_shardings=[<@mesh, [{"x"}]>] out_shardings=[<@mesh, [{"y"}]>] (%arg1: tensor<210xf32>) {
-    %2 = stablehlo.abs %arg1 {sdy.sharding=#sdy.sharding_per_value<[<@mesh, [{"x"}]>]>} : tensor<210xf32>
-    // TODO(enver): Reshard block result to [y].
-    sdy.return %2 : tensor<210xf32>
-  } : (tensor<210xf32>) -> (tensor<210xf32>)
-  %1 = stablehlo.negate %0 {sdy.sharding= #sdy.sharding_per_value<[<@mesh, [{"y"}]>]>} : tensor<210xf32>
-  return %1 : tensor<210xf32>
-}
-
-// CHECK-LABEL: func @named_computation_empty_block
-func.func @named_computation_empty_block(%arg0: tensor<210xf32> {sdy.sharding = #sdy.sharding<@mesh, [{"x"}]>}) -> (tensor<210xf32> {sdy.sharding = #sdy.sharding<@mesh, [{"y"}]>}) {
-  // CHECK: sdy.named_computation<"foo">(%arg0)
-  %0 = sdy.named_computation<"foo">(%arg0) in_shardings=[<@mesh, [{"x"}]>] out_shardings=[<@mesh, [{"y"}]>] (%arg1: tensor<210xf32>) {
-    // TODO(enver): Reshard block result to [y].
-    sdy.return %arg1 : tensor<210xf32>
-  } : (tensor<210xf32>) -> (tensor<210xf32>)
-  %1 = stablehlo.negate %0 {sdy.sharding= #sdy.sharding_per_value<[<@mesh, [{"y"}]>]>} : tensor<210xf32>
-  return %1 : tensor<210xf32>
-}
-
-// CHECK-LABEL: func @manual_computation
-func.func @manual_computation(%arg0: tensor<210xf32> {sdy.sharding = #sdy.sharding<@mesh, [{"x":(1)2}]>}) -> (tensor<210xf32> {sdy.sharding = #sdy.sharding<@mesh, [{"y"}]>}) {
-  // TODO(enver): Reshard input to [x].
-  %0 = sdy.manual_computation(%arg0)
-    in_shardings=[<@mesh, [{"x"}]>] out_shardings=[<@mesh, [{"y"}]>] manual_axes={} (%arg1: tensor<210xf32>) {
-    %2 = stablehlo.abs %arg1 {sdy.sharding=#sdy.sharding_per_value<[<@mesh, [{"x"}]>]>} : tensor<210xf32>
-    // TODO(enver): Reshard block result to [y].
-    sdy.return %2 : tensor<210xf32>
-  } : (tensor<210xf32>) -> (tensor<210xf32>)
-  %1 = stablehlo.negate %0 {sdy.sharding= #sdy.sharding_per_value<[<@mesh, [{"y"}]>]>} : tensor<210xf32>
-  return %1 : tensor<210xf32>
-}
-
-// CHECK-LABEL: func @optimization_barrier
-func.func @optimization_barrier(%arg0: tensor<210xf32> {sdy.sharding = #sdy.sharding<@mesh, [{"x"}]>}) -> (tensor<210xf32> {sdy.sharding = #sdy.sharding<@mesh, [{"y"}]>}) {
-  // TODO(enver): Reshard input to [y].
-  %1 = stablehlo.optimization_barrier {sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"y"}]>]>} %arg0 : tensor<210xf32>
-  %2 = stablehlo.negate %1 {sdy.sharding= #sdy.sharding_per_value<[<@mesh, [{"y"}]>]>} : tensor<210xf32>
-  return %2 : tensor<210xf32>
-}
diff --git a/shardy/dialect/sdy/transforms/export/test/reshard_to_collectives.mlir b/shardy/dialect/sdy/transforms/export/test/reshard_to_collectives.mlir
index 1a87721..0f92727 100644
--- a/shardy/dialect/sdy/transforms/export/test/reshard_to_collectives.mlir
+++ b/shardy/dialect/sdy/transforms/export/test/reshard_to_collectives.mlir
@@ -5,8 +5,6 @@ sdy.mesh @mesh2d = <["x"=2, "y"=2]>
 sdy.mesh @mesh2d_4x2 = <["x"=4, "y"=2]>
 sdy.mesh @mesh2d_2x8 = <["x"=2, "y"=8]>
 sdy.mesh @mesh3d = <["x"=2, "y"=2, "z"=2]>
-sdy.mesh @mesh3d_4x2x4 = <["x"=4, "y"=2, "z"=4]>
-sdy.mesh @mesh4d_z4 = <["x"=2, "y"=2, "z"=4, "w"=2]>
 sdy.mesh @mesh4d_w4 = <["x"=2, "y"=2, "z"=2, "w"=4]>
 sdy.mesh @mesh4d_w16 = <["x"=2, "y"=2, "z"=2, "w"=16]>
 
@@ -17,222 +15,72 @@ func.func @redundant_reshard(%arg0 : tensor<16x8xf32> {sdy.sharding=#sdy.shardin
   return %0 : tensor<16x8xf32>
 }
 
-// CHECK-LABEL: func @all_gather_single_axis
-func.func @all_gather_single_axis(%arg0 : tensor<16x8xf32> {sdy.sharding=#sdy.sharding<@mesh2d, [{"y"}, {"x"}]>}) -> tensor<16x8xf32> {
+// CHECK-LABEL: func @reshard_to_all_gather_single_axis
+func.func @reshard_to_all_gather_single_axis(%arg0 : tensor<16x8xf32> {sdy.sharding=#sdy.sharding<@mesh2d, [{"y"}, {"x"}]>}) -> tensor<16x8xf32> {
   // CHECK-NEXT: sdy.all_gather [{}, {"x"}] %arg0 out_sharding=<@mesh2d, [{"y"}, {}]>
   %0 = sdy.reshard %arg0 <@mesh2d, [{"y"}, {}]> : tensor<16x8xf32>
   return %0 : tensor<16x8xf32>
 }
 
-// CHECK-LABEL: func @all_gather_multiple_axes
-func.func @all_gather_multiple_axes(%arg0 : tensor<16x8xf32> {sdy.sharding=#sdy.sharding<@mesh3d, [{"x", "y", "z"}, {}]>}) -> tensor<16x8xf32> {
+// CHECK-LABEL: func @reshard_to_all_gather_multiple_axes
+func.func @reshard_to_all_gather_multiple_axes(%arg0 : tensor<16x8xf32> {sdy.sharding=#sdy.sharding<@mesh3d, [{"x", "y", "z"}, {}]>}) -> tensor<16x8xf32> {
   // CHECK-NEXT: sdy.all_gather [{"y", "z"}, {}] %arg0 out_sharding=<@mesh3d, [{"x"}, {}]>
   %0 = sdy.reshard %arg0 <@mesh3d, [{"x"}, {}]> : tensor<16x8xf32>
   return %0 : tensor<16x8xf32>
 }
 
-// CHECK-LABEL: func @all_gather_multiple_dims
-func.func @all_gather_multiple_dims(%arg0 : tensor<16x8xf32> {sdy.sharding=#sdy.sharding<@mesh3d, [{"y", "z"}, {"x"}]>}) -> tensor<16x8xf32> {
+// CHECK-LABEL: func @reshard_to_all_gather_multiple_dims
+func.func @reshard_to_all_gather_multiple_dims(%arg0 : tensor<16x8xf32> {sdy.sharding=#sdy.sharding<@mesh3d, [{"y", "z"}, {"x"}]>}) -> tensor<16x8xf32> {
   // CHECK-NEXT: sdy.all_gather [{"z"}, {}] %arg0 out_sharding=<@mesh3d, [{"y"}, {"x"}]>
   %0 = sdy.reshard %arg0 <@mesh3d, [{"y"}, {"x"}]> : tensor<16x8xf32>
   return %0 : tensor<16x8xf32>
 }
 
-// CHECK-LABEL: func @all_gather_with_subaxis
-func.func @all_gather_with_subaxis(%arg0 : tensor<16x8xf32> {sdy.sharding=#sdy.sharding<@mesh2d_2x8, [{"y"}, {"x"}]>}) -> tensor<16x8xf32> {
+// CHECK-LABEL: func @reshard_to_all_gather_with_subaxis
+func.func @reshard_to_all_gather_with_subaxis(%arg0 : tensor<16x8xf32> {sdy.sharding=#sdy.sharding<@mesh2d_2x8, [{"y"}, {"x"}]>}) -> tensor<16x8xf32> {
   // CHECK-NEXT: sdy.all_gather [{"y":(4)2}, {}] %arg0 out_sharding=<@mesh2d_2x8, [{"y":(1)4}, {"x"}]>
  %0 = sdy.reshard %arg0 <@mesh2d_2x8, [{"y":(1)4}, {"x"}]> :  tensor<16x8xf32>
  return %0 : tensor<16x8xf32>
 }
 
-// CHECK-LABEL: func @all_slice_multiple_axes
-func.func @all_slice_multiple_axes(%arg0 : tensor<16x8xf32> {sdy.sharding=#sdy.sharding<@mesh3d, [{}, {}]>}) -> tensor<16x8xf32> {
+// CHECK-LABEL: func @reshard_to_all_slice_multiple_axes
+func.func @reshard_to_all_slice_multiple_axes(%arg0 : tensor<16x8xf32> {sdy.sharding=#sdy.sharding<@mesh3d, [{}, {}]>}) -> tensor<16x8xf32> {
   // CHECK-NEXT: sdy.all_slice [{"x"}, {"y", "z"}] %arg0 out_sharding=<@mesh3d, [{"x"}, {"y", "z"}]>
   %0 = sdy.reshard %arg0 <@mesh3d, [{"x"}, {"y", "z"}]> : tensor<16x8xf32>
   return %0 : tensor<16x8xf32>
 }
 
-// CHECK-LABEL: func @all_slice_minor_axis
-func.func @all_slice_minor_axis(%arg0 : tensor<16x8xf32> {sdy.sharding=#sdy.sharding<@mesh3d, [{"x"}, {"y"}]>}) -> tensor<16x8xf32> {
+// CHECK-LABEL: func @reshard_to_all_slice_minor_axis
+func.func @reshard_to_all_slice_minor_axis(%arg0 : tensor<16x8xf32> {sdy.sharding=#sdy.sharding<@mesh3d, [{"x"}, {"y"}]>}) -> tensor<16x8xf32> {
   // CHECK-NEXT: sdy.all_slice [{}, {"z"}] %arg0 out_sharding=<@mesh3d, [{"x"}, {"y", "z"}]>
   %0 = sdy.reshard %arg0 <@mesh3d, [{"x"}, {"y", "z"}]> : tensor<16x8xf32>
   return %0 : tensor<16x8xf32>
 }
 
-// CHECK-LABEL: func @all_slice_with_subaxis
-func.func @all_slice_with_subaxis(%arg0 : tensor<16x8xf32> {sdy.sharding=#sdy.sharding<@mesh3d_4x2x4, [{"x":(1)2}, {"y"}]>}) -> tensor<16x8xf32> {
-  // CHECK-NEXT: sdy.all_slice [{"x":(2)2}, {"z":(1)2}] %arg0 out_sharding=<@mesh3d_4x2x4, [{"x"}, {"y", "z":(1)2}]>
-  %0 = sdy.reshard %arg0 <@mesh3d_4x2x4, [{"x"}, {"y", "z":(1)2}]> : tensor<16x8xf32>
-  return %0 : tensor<16x8xf32>
-}
-
-// CHECK-LABEL: func @all_to_all_single_axis
-func.func @all_to_all_single_axis(%arg0 : tensor<16x8x8xf32> {sdy.sharding=#sdy.sharding<@mesh3d, [{"x"}, {"y"}, {}]>}) -> tensor<16x8x8xf32> {
-  // CHECK-NEXT: sdy.all_to_all {"x"} 0->2 %arg0 out_sharding=<@mesh3d, [{}, {"y"}, {"x"}]>
-  %0 = sdy.reshard %arg0 <@mesh3d, [{}, {"y"}, {"x"}]> : tensor<16x8x8xf32>
-  return %0 : tensor<16x8x8xf32>
-}
-
-// CHECK-LABEL: func @all_to_all_multiple_axes
-func.func @all_to_all_multiple_axes(%arg0 : tensor<16x8x8xf32> {sdy.sharding=#sdy.sharding<@mesh3d, [{"x"}, {}, {"y", "z"}]>}) -> tensor<16x8x8xf32> {
-  // CHECK-NEXT: sdy.all_to_all {"y", "z"} 2->1 %arg0 out_sharding=<@mesh3d, [{"x"}, {"y", "z"}, {}]>
-  %0 = sdy.reshard %arg0 <@mesh3d, [{"x"}, {"y", "z"}, {}]> : tensor<16x8x8xf32>
-  return %0 : tensor<16x8x8xf32>
-}
-
-// CHECK-LABEL: func @two_all_to_alls_different_tgt_dims
-func.func @two_all_to_alls_different_tgt_dims(%arg0 : tensor<16x8x8xf32> {sdy.sharding=#sdy.sharding<@mesh3d_4x2x4, [{}, {"y", "x"}, {}]>}) -> tensor<16x8x8xf32> {
-  // CHECK-NEXT: %[[ALL_TO_ALL_0:.*]] = sdy.all_to_all {"x"} 1->0 %arg0 out_sharding=<@mesh3d_4x2x4, [{"x"}, {"y"}, {}]>
-  // CHECK-NEXT: %[[ALL_TO_ALL_1:.*]] = sdy.all_to_all {"y"} 1->2 %[[ALL_TO_ALL_0]] out_sharding=<@mesh3d_4x2x4, [{"x"}, {}, {"y"}]>
-  // CHECK-NEXT: return %[[ALL_TO_ALL_1]]
-  %0 = sdy.reshard %arg0 <@mesh3d_4x2x4, [{"x"}, {}, {"y"}]> : tensor<16x8x8xf32>
-  return %0 : tensor<16x8x8xf32>
-}
-
-// CHECK-LABEL: func @two_all_to_alls_tgt_dim_not_empty
-func.func @two_all_to_alls_tgt_dim_not_empty(%arg0 : tensor<16x8x8xf32> {sdy.sharding=#sdy.sharding<@mesh3d_4x2x4, [{"x"}, {"y", "z"}, {}]>}) -> tensor<16x8x8xf32> {
-  // CHECK-NEXT: %[[ALL_TO_ALL_0:.*]] = sdy.all_to_all {"z"} 1->0 %arg0 out_sharding=<@mesh3d_4x2x4, [{"x", "z"}, {"y"}, {}]>
-  // CHECK-NEXT: %[[ALL_TO_ALL_1:.*]] = sdy.all_to_all {"y"} 1->2 %[[ALL_TO_ALL_0]] out_sharding=<@mesh3d_4x2x4, [{"x", "z"}, {}, {"y"}]>
-  // CHECK-NEXT: return %[[ALL_TO_ALL_1]]
-  %0 = sdy.reshard %arg0 <@mesh3d_4x2x4, [{"x", "z"}, {}, {"y"}]> : tensor<16x8x8xf32>
-  return %0 : tensor<16x8x8xf32>
-}
-
-// CHECK-LABEL: func @slice_then_all_to_alls
-func.func @slice_then_all_to_alls(%arg0 : tensor<16x8x8xf32> {sdy.sharding=#sdy.sharding<@mesh3d_4x2x4, [{}, {"y", "z"}, {}]>}) -> tensor<16x8x8xf32> {
-  // CHECK-NEXT: %[[ALL_SLICE:.*]] = sdy.all_slice [{"x"}, {}, {}] %arg0 out_sharding=<@mesh3d_4x2x4, [{"x"}, {"y", "z"}, {}]>
-  // CHECK-NEXT: %[[ALL_TO_ALL_0:.*]] = sdy.all_to_all {"z"} 1->0 %[[ALL_SLICE]] out_sharding=<@mesh3d_4x2x4, [{"x", "z"}, {"y"}, {}]>
-  // CHECK-NEXT: %[[ALL_TO_ALL_1:.*]] = sdy.all_to_all {"y"} 1->2 %[[ALL_TO_ALL_0]] out_sharding=<@mesh3d_4x2x4, [{"x", "z"}, {}, {"y"}]>
-  // CHECK-NEXT: return %[[ALL_TO_ALL_1]]
-  %0 = sdy.reshard %arg0 <@mesh3d_4x2x4, [{"x", "z"}, {}, {"y"}]> : tensor<16x8x8xf32>
-  return %0 : tensor<16x8x8xf32>
-}
-
-// CHECK-LABEL: func @all_to_all_subaxis_then_all_gather
-func.func @all_to_all_subaxis_then_all_gather(%arg0 : tensor<16x8x8xf32> {sdy.sharding=#sdy.sharding<@mesh3d_4x2x4, [{"x"}, {"z", "y"}, {}]>}) -> tensor<16x8x8xf32> {
-  // CHECK-NEXT: %[[ALL_TO_ALL_0:.*]] = sdy.all_to_all {"y"} 1->2 %arg0 out_sharding=<@mesh3d_4x2x4, [{"x"}, {"z"}, {"y"}]>
-  // CHECK-NEXT: %[[ALL_TO_ALL_1:.*]] = sdy.all_to_all {"z":(2)2} 1->0 %[[ALL_TO_ALL_0]] out_sharding=<@mesh3d_4x2x4, [{"x", "z":(2)2}, {"z":(1)2}, {"y"}]>
-  // CHECK-NEXT: %[[ALL_GATHER:.*]] = sdy.all_gather [{}, {"z":(1)2}, {}] %[[ALL_TO_ALL_1]] out_sharding=<@mesh3d_4x2x4, [{"x", "z":(2)2}, {}, {"y"}]>
-  // CHECK-NEXT: return %[[ALL_GATHER]]
-  %0 = sdy.reshard %arg0 <@mesh3d_4x2x4, [{"x", "z":(2)2}, {}, {"y"}]> : tensor<16x8x8xf32>
-  return %0 : tensor<16x8x8xf32>
-}
-
-// CHECK-LABEL: func @all_to_all_subaxis_and_full_axis_then_all_gather
-func.func @all_to_all_subaxis_and_full_axis_then_all_gather(%arg0 : tensor<16x8x8xf32> {sdy.sharding=#sdy.sharding<@mesh4d_z4, [{"x"}, {"z", "w", "y"}, {}]>}) -> tensor<16x8x8xf32> {
-  // CHECK-NEXT: %[[ALL_TO_ALL_0:.*]] = sdy.all_to_all {"y"} 1->2 %arg0 out_sharding=<@mesh4d_z4, [{"x"}, {"z", "w"}, {"y"}]>
-  // CHECK-NEXT: %[[ALL_TO_ALL_1:.*]] = sdy.all_to_all {"z":(2)2, "w"} 1->0 %[[ALL_TO_ALL_0]] out_sharding=<@mesh4d_z4, [{"x", "z":(2)2, "w"}, {"z":(1)2}, {"y"}]>
-  // CHECK-NEXT: %[[ALL_GATHER:.*]] = sdy.all_gather [{}, {"z":(1)2}, {}] %[[ALL_TO_ALL_1]] out_sharding=<@mesh4d_z4, [{"x", "z":(2)2, "w"}, {}, {"y"}]>
-  // CHECK-NEXT: return %[[ALL_GATHER]]
-  %0 = sdy.reshard %arg0 <@mesh4d_z4, [{"x", "z":(2)2, "w"}, {}, {"y"}]> : tensor<16x8x8xf32>
-  return %0 : tensor<16x8x8xf32>
-}
-
-// CHECK-LABEL: func @slice_on_src_dim_then_all_to_all_subaxis
-func.func @slice_on_src_dim_then_all_to_all_subaxis(%arg0 : tensor<16x8x8xf32> {sdy.sharding=#sdy.sharding<@mesh4d_w4, [{}, {"w":(1)2}, {}]>}) -> tensor<16x8x8xf32> {
-  // CHECK-NEXT: %[[ALL_SLICE:.*]] = sdy.all_slice [{}, {"w":(2)2}, {}] %arg0 out_sharding=<@mesh4d_w4, [{}, {"w"}, {}]>
-  // CHECK-NEXT: %[[ALL_TO_ALL:.*]] = sdy.all_to_all {"w"} 1->0 %[[ALL_SLICE]] out_sharding=<@mesh4d_w4, [{"w"}, {}, {}]>
-  // CHECK-NEXT: return %[[ALL_TO_ALL]]
-  %0 = sdy.reshard %arg0 <@mesh4d_w4, [{"w"}, {}, {}]> : tensor<16x8x8xf32>
-  return %0 : tensor<16x8x8xf32>
-}
-
-// CHECK-LABEL: func @slice_on_src_dim_then_all_to_all_multiple_axes
-func.func @slice_on_src_dim_then_all_to_all_multiple_axes(%arg0 : tensor<16x8x8xf32> {sdy.sharding=#sdy.sharding<@mesh4d_w4, [{}, {"x"}, {}]>}) -> tensor<16x8x8xf32> {
-  // CHECK-NEXT: %[[ALL_SLICE:.*]] = sdy.all_slice [{}, {"y", "z"}, {}] %arg0 out_sharding=<@mesh4d_w4, [{}, {"x", "y", "z"}, {}]>
-  // CHECK-NEXT: %[[ALL_TO_ALL:.*]] = sdy.all_to_all {"x", "y", "z"} 1->2 %[[ALL_SLICE]] out_sharding=<@mesh4d_w4, [{}, {}, {"x", "y", "z"}]>
-  // CHECK-NEXT: return %[[ALL_TO_ALL]]
-  %0 = sdy.reshard %arg0 <@mesh4d_w4, [{}, {}, {"x", "y", "z"}]> : tensor<16x8x8xf32>
-  return %0 : tensor<16x8x8xf32>
-}
-
-// TODO(b/380226848): the tests below require collective permute to do the right
-// thing. At the moment, we do a redundant all-slice or all-to-all, just to
-// all-gather the added axes and slice again in the right order.
-
-// CHECK-LABEL: func @all_to_all_axes_at_src_out_of_order
-func.func @all_to_all_axes_at_src_out_of_order(%arg0 : tensor<16x8x8xf32> {sdy.sharding=#sdy.sharding<@mesh3d_4x2x4, [{"z"}, {"y", "x"}, {}]>}) -> tensor<16x8x8xf32> {
-  // CHECK-NEXT: %[[ALL_TO_ALL:.*]] = sdy.all_to_all {"y", "x"} 1->0 %arg0 out_sharding=<@mesh3d_4x2x4, [{"z", "y", "x"}, {}, {}]>
-  // CHECK-NEXT: %[[ALL_GATHER:.*]] = sdy.all_gather [{"z", "y", "x"}, {}, {}] %[[ALL_TO_ALL]] out_sharding=<@mesh3d_4x2x4, [{}, {}, {}]>
-  // CHECK-NEXT: %[[ALL_SLICE:.*]] = sdy.all_slice [{"x", "y", "z"}, {}, {}] %[[ALL_GATHER]] out_sharding=<@mesh3d_4x2x4, [{"x", "y", "z"}, {}, {}]>
-  // CHECK-NEXT: return %[[ALL_SLICE]]
-  %0 = sdy.reshard %arg0 <@mesh3d_4x2x4, [{"x", "y", "z"}, {}, {}]> : tensor<16x8x8xf32>
-  return %0 : tensor<16x8x8xf32>
-}
-
-// CHECK-LABEL: func @all_to_all_two_tgt_dims_src_out_of_order
-func.func @all_to_all_two_tgt_dims_src_out_of_order(%arg0 : tensor<16x8x8xf32> {sdy.sharding=#sdy.sharding<@mesh3d_4x2x4, [{}, {"x", "z", "y"}, {}]>}) -> tensor<16x8x8xf32> {
-  // CHECK-NEXT: %[[ALL_TO_ALL_0:.*]] = sdy.all_to_all {"y"} 1->0 %arg0 out_sharding=<@mesh3d_4x2x4, [{"y"}, {"x", "z"}, {}]>
-  // CHECK-NEXT: %[[ALL_TO_ALL_1:.*]] = sdy.all_to_all {"z"} 1->2 %[[ALL_TO_ALL_0]] out_sharding=<@mesh3d_4x2x4, [{"y"}, {"x"}, {"z"}]>
-  // CHECK-NEXT: %[[ALL_TO_ALL_2:.*]] = sdy.all_to_all {"x"} 1->0 %[[ALL_TO_ALL_1]] out_sharding=<@mesh3d_4x2x4, [{"y", "x"}, {}, {"z"}]>
-  // CHECK-NEXT: %[[ALL_GATHER:.*]] = sdy.all_gather [{"y", "x"}, {}, {}] %[[ALL_TO_ALL_2]] out_sharding=<@mesh3d_4x2x4, [{}, {}, {"z"}]>
-  // CHECK-NEXT: %[[ALL_SLICE:.*]] = sdy.all_slice [{"x", "y"}, {}, {}] %[[ALL_GATHER]] out_sharding=<@mesh3d_4x2x4, [{"x", "y"}, {}, {"z"}]>
-  // CHECK-NEXT: return %[[ALL_SLICE]]
-  %0 = sdy.reshard %arg0 <@mesh3d_4x2x4, [{"x", "y"}, {}, {"z"}]> : tensor<16x8x8xf32>
-  return %0 : tensor<16x8x8xf32>
-}
-
-// CHECK-LABEL: func @all_to_all_two_tgt_dims_src_out_of_order_2
-func.func @all_to_all_two_tgt_dims_src_out_of_order_2(%arg0 : tensor<16x8x8xf32> {sdy.sharding=#sdy.sharding<@mesh3d_4x2x4, [{}, {"y", "z", "x"}, {}]>}) -> tensor<16x8x8xf32> {
-  // CHECK-NEXT: %[[ALL_TO_ALL_0:.*]] = sdy.all_to_all {"x"} 1->0 %arg0 out_sharding=<@mesh3d_4x2x4, [{"x"}, {"y", "z"}, {}]>
-  // CHECK-NEXT: %[[ALL_TO_ALL_1:.*]] = sdy.all_to_all {"z"} 1->2 %[[ALL_TO_ALL_0]] out_sharding=<@mesh3d_4x2x4, [{"x"}, {"y"}, {"z"}]>
-  // CHECK-NEXT: %[[ALL_TO_ALL_2:.*]] = sdy.all_to_all {"y"} 1->0 %[[ALL_TO_ALL_1]] out_sharding=<@mesh3d_4x2x4, [{"x", "y"}, {}, {"z"}]>
-  // CHECK-NEXT: return %[[ALL_TO_ALL_2]]
-  %0 = sdy.reshard %arg0 <@mesh3d_4x2x4, [{"x", "y"}, {}, {"z"}]> : tensor<16x8x8xf32>
-  return %0 : tensor<16x8x8xf32>
-}
-
-// CHECK-LABEL: func @all_to_all_and_gather_src_dim_out_of_order
-func.func @all_to_all_and_gather_src_dim_out_of_order(%arg0 : tensor<16x8x8xf32> {sdy.sharding=#sdy.sharding<@mesh4d_z4, [{"x"}, {"y", "z", "w"}, {}]>}) -> tensor<16x8x8xf32> {
-  // CHECK-NEXT: %[[ALL_TO_ALL:.*]] = sdy.all_to_all {"z":(2)2, "w"} 1->0 %arg0 out_sharding=<@mesh4d_z4, [{"x", "z":(2)2, "w"}, {"y", "z":(1)2}, {}]>
-  // CHECK-NEXT: %[[ALL_GATHER:.*]] = sdy.all_gather [{}, {"y", "z":(1)2}, {}] %[[ALL_TO_ALL]] out_sharding=<@mesh4d_z4, [{"x", "z":(2)2, "w"}, {}, {}]>
-  // CHECK-NEXT: %[[ALL_SLICE:.*]] = sdy.all_slice [{}, {}, {"y"}] %[[ALL_GATHER]] out_sharding=<@mesh4d_z4, [{"x", "z":(2)2, "w"}, {}, {"y"}]>
-  // CHECK-NEXT: return %[[ALL_SLICE]]
-  %0 = sdy.reshard %arg0 <@mesh4d_z4, [{"x", "z":(2)2, "w"}, {}, {"y"}]> : tensor<16x8x8xf32>
-  return %0 : tensor<16x8x8xf32>
-}
-
-// CHECK-LABEL: func @slice_then_reorder_axes
-func.func @slice_then_reorder_axes(%arg0 : tensor<16x8x8xf32> {sdy.sharding=#sdy.sharding<@mesh2d, [{"y"}, {}, {}]>}) -> tensor<16x8x8xf32> {
-  // CHECK-NEXT: %[[ALL_SLICE:.*]] = sdy.all_slice [{"x"}, {}, {}] %arg0 out_sharding=<@mesh2d, [{"y", "x"}, {}, {}]>
-  // CHECK-NEXT: %[[ALL_GATHER:.*]] = sdy.all_gather [{"y", "x"}, {}, {}] %[[ALL_SLICE]] out_sharding=<@mesh2d, [{}, {}, {}]>
-  // CHECK-NEXT: %[[ALL_SLICE:.*]] = sdy.all_slice [{"x", "y"}, {}, {}] %[[ALL_GATHER]] out_sharding=<@mesh2d, [{"x", "y"}, {}, {}]>
-  // CHECK-NEXT: return %[[ALL_SLICE]]
-  %0 = sdy.reshard %arg0 <@mesh2d, [{"x", "y"}, {}, {}]> : tensor<16x8x8xf32>
-  return %0 : tensor<16x8x8xf32>
-}
-
 // CHECK-LABEL: func @major_axis_available_to_slice
 func.func @major_axis_available_to_slice(%arg0: tensor<16x8xf32> {sdy.sharding = #sdy.sharding<@mesh4d_w4, [{"y", "z", "w"}, {}]>}) -> tensor<16x8xf32> {
-  // CHECK-NEXT: %[[ALL_SLICE:.*]] = sdy.all_slice [{}, {"x"}] %arg0 out_sharding=<@mesh4d_w4, [{"y", "z", "w"}, {"x"}]>
-  // CHECK-NEXT: %[[ALL_TO_ALL:.*]] = sdy.all_to_all {"w"} 0->1 %[[ALL_SLICE]] out_sharding=<@mesh4d_w4, [{"y", "z"}, {"x", "w"}]>
-  // CHECK-NEXT: %[[ALL_GATHER:.*]] = sdy.all_gather [{"z"}, {}] %[[ALL_TO_ALL]] out_sharding=<@mesh4d_w4, [{"y"}, {"x", "w"}]>
-  // CHECK-NEXT: return %[[ALL_GATHER]]
+  // CHECK-NEXT: %[[ALL_SLICE_0:.*]] = sdy.all_slice [{}, {"x"}] %arg0 out_sharding=<@mesh4d_w4, [{"y", "z", "w"}, {"x"}]>
+  // CHECK-NEXT: %[[ALL_GATHER:.*]] = sdy.all_gather [{"z", "w"}, {}] %[[ALL_SLICE_0]] out_sharding=<@mesh4d_w4, [{"y"}, {"x"}]>
+  // CHECK-NEXT: %[[ALL_SLICE_1:.*]] = sdy.all_slice [{}, {"w"}] %[[ALL_GATHER]] out_sharding=<@mesh4d_w4, [{"y"}, {"x", "w"}]>
+  // CHECK-NEXT: return %[[ALL_SLICE_1]]
   %0 = sdy.reshard %arg0 <@mesh4d_w4, [{"y"}, {"x", "w"}]> : tensor<16x8xf32>
   return %0 : tensor<16x8xf32>
 }
 
 // CHECK-LABEL: func @prefix_subaxis_available_to_slice
 func.func @prefix_subaxis_available_to_slice(%arg0: tensor<16x8xf32> {sdy.sharding = #sdy.sharding<@mesh4d_w4, [{"y", "z", "w":(2)2}, {}]>}) -> tensor<16x8xf32> {
-  // CHECK-NEXT: %[[ALL_SLICE:.*]] = sdy.all_slice [{}, {"x", "w":(1)2}] %arg0 out_sharding=<@mesh4d_w4, [{"y", "z", "w":(2)2}, {"x", "w":(1)2}]>
-  // CHECK-NEXT: %[[ALL_TO_ALL:.*]] = sdy.all_to_all {"w":(2)2} 0->1 %[[ALL_SLICE]] out_sharding=<@mesh4d_w4, [{"y", "z"}, {"x", "w"}]>
-  // CHECK-NEXT: %[[ALL_GATHER:.*]] = sdy.all_gather [{"z"}, {}] %[[ALL_TO_ALL]] out_sharding=<@mesh4d_w4, [{"y"}, {"x", "w"}]>
-  // CHECK-NEXT: return %[[ALL_GATHER]]
+  // CHECK-NEXT: %[[ALL_SLICE_0:.*]] = sdy.all_slice [{}, {"x", "w":(1)2}] %arg0 out_sharding=<@mesh4d_w4, [{"y", "z", "w":(2)2}, {"x", "w":(1)2}]>
+  // CHECK-NEXT: %[[ALL_GATHER:.*]] = sdy.all_gather [{"z", "w":(2)2}, {}] %[[ALL_SLICE_0]] out_sharding=<@mesh4d_w4, [{"y"}, {"x", "w":(1)2}]>
+  // CHECK-NEXT: %[[ALL_SLICE_1:.*]] = sdy.all_slice [{}, {"w":(2)2}] %[[ALL_GATHER]] out_sharding=<@mesh4d_w4, [{"y"}, {"x", "w"}]>
+  // CHECK-NEXT: return %[[ALL_SLICE_1]]
   %0 = sdy.reshard %arg0 <@mesh4d_w4, [{"y"}, {"x", "w"}]> : tensor<16x8xf32>
   return %0 : tensor<16x8xf32>
 }
 
-// NOTE: this test case should have the following result with collective permute:
-// %0 = sdy.all_slice [{}, {"x"}] %arg0 out_sharding=<@mesh4d_w16, [{"y", "w":(4)2, "z", "w":(1)2}, {"x"}]> : tensor<16x8xf32>
-// %1 = sdy.collective_permute %0 out_sharding=<@mesh4d_w16, [{"y", "w":(2)8}, {"x"}]> : tensor<16x8xf32>
-// %2 = sdy.all_to_all {"w":(2)8} 0->1 %1 out_sharding=<@mesh4d_w16, [{"y"}, {"x", "w":(2)8}]> : tensor<16x8xf32>
-// return %2 : tensor<16x8xf32>
-
 // CHECK-LABEL: func @prefix_subaxis_available_to_slice_2
 func.func @prefix_subaxis_available_to_slice_2(%arg0: tensor<16x8xf32> {sdy.sharding = #sdy.sharding<@mesh4d_w16, [{"y", "w":(4)2, "z", "w":(1)2}, {}]>}) -> tensor<16x8xf32> {
-  // CHECK-NEXT: %[[ALL_SLICE_0:.*]] = sdy.all_slice [{"w":(8)2}, {"x", "w":(2)2}] %arg0 out_sharding=<@mesh4d_w16, [{"y", "w":(4)2, "z", "w":(1)2, "w":(8)2}, {"x", "w":(2)2}]>
-  // CHECK-NEXT: %[[ALL_TO_ALL:.*]] = sdy.all_to_all {"w":(8)2} 0->1 %[[ALL_SLICE_0]] out_sharding=<@mesh4d_w16, [{"y", "w":(4)2, "z", "w":(1)2}, {"x", "w":(2)2, "w":(8)2}]>
-  // CHECK-NEXT: %[[ALL_GATHER:.*]] = sdy.all_gather [{"w":(4)2, "z", "w":(1)2}, {"w":(8)2}] %[[ALL_TO_ALL]] out_sharding=<@mesh4d_w16, [{"y"}, {"x", "w":(2)2}]>
+  // CHECK-NEXT: %[[ALL_SLICE_0:.*]] = sdy.all_slice [{}, {"x", "w":(2)2}] %arg0 out_sharding=<@mesh4d_w16, [{"y", "w":(4)2, "z", "w":(1)2}, {"x", "w":(2)2}]>
+  // CHECK-NEXT: %[[ALL_GATHER:.*]] = sdy.all_gather [{"w":(4)2, "z", "w":(1)2}, {}] %[[ALL_SLICE_0]] out_sharding=<@mesh4d_w16, [{"y"}, {"x", "w":(2)2}]>
   // CHECK-NEXT: %[[ALL_SLICE_1:.*]] = sdy.all_slice [{}, {"w":(4)4}] %[[ALL_GATHER]] out_sharding=<@mesh4d_w16, [{"y"}, {"x", "w":(2)8}]>
   // CHECK-NEXT: return %[[ALL_SLICE_1]]
   %0 = sdy.reshard %arg0 <@mesh4d_w16, [{"y"}, {"x", "w":(2)8}]> : tensor<16x8xf32>
@@ -242,8 +90,7 @@ func.func @prefix_subaxis_available_to_slice_2(%arg0: tensor<16x8xf32> {sdy.shar
 // CHECK-LABEL: func @split_full_axis_not_available_to_slice
 func.func @split_full_axis_not_available_to_slice(%arg0: tensor<16x8xf32> {sdy.sharding = #sdy.sharding<@mesh4d_w4, [{"y", "w":(1)2, "z", "w":(2)2}, {}]>}) -> tensor<16x8xf32> {
   // CHECK-NEXT: %[[ALL_SLICE_0:.*]] = sdy.all_slice [{}, {"x"}] %arg0 out_sharding=<@mesh4d_w4, [{"y", "w":(1)2, "z", "w":(2)2}, {"x"}]>
-  // CHECK-NEXT: %[[ALL_TO_ALL:.*]] = sdy.all_to_all {"w":(2)2} 0->1 %[[ALL_SLICE_0]] out_sharding=<@mesh4d_w4, [{"y", "w":(1)2, "z"}, {"x", "w":(2)2}]>
-  // CHECK-NEXT: %[[ALL_GATHER:.*]] = sdy.all_gather [{"w":(1)2, "z"}, {"w":(2)2}] %[[ALL_TO_ALL]] out_sharding=<@mesh4d_w4, [{"y"}, {"x"}]>
+  // CHECK-NEXT: %[[ALL_GATHER:.*]] = sdy.all_gather [{"w":(1)2, "z", "w":(2)2}, {}] %[[ALL_SLICE_0]] out_sharding=<@mesh4d_w4, [{"y"}, {"x"}]>
   // CHECK-NEXT: %[[ALL_SLICE_1:.*]] = sdy.all_slice [{}, {"w"}] %[[ALL_GATHER]] out_sharding=<@mesh4d_w4, [{"y"}, {"x", "w"}]>
   // CHECK-NEXT: return %[[ALL_SLICE_1]]
   %0 = sdy.reshard %arg0 <@mesh4d_w4, [{"y"}, {"x", "w"}]> : tensor<16x8xf32>
@@ -252,50 +99,47 @@ func.func @split_full_axis_not_available_to_slice(%arg0: tensor<16x8xf32> {sdy.s
 
 // CHECK-LABEL: func @prefix_subaxis_not_available_to_slice
 func.func @prefix_subaxis_not_available_to_slice(%arg0: tensor<16x8xf32> {sdy.sharding = #sdy.sharding<@mesh4d_w4, [{"y", "z", "w":(1)2}, {}]>}) -> tensor<16x8xf32> {
-  // CHECK-NEXT: %[[ALL_SLICE:.*]] = sdy.all_slice [{"w":(2)2}, {"x"}] %arg0 out_sharding=<@mesh4d_w4, [{"y", "z", "w"}, {"x"}]>
-  // CHECK-NEXT: %[[ALL_TO_ALL:.*]] = sdy.all_to_all {"w"} 0->1 %[[ALL_SLICE]] out_sharding=<@mesh4d_w4, [{"y", "z"}, {"x", "w"}]>
-  // CHECK-NEXT: %[[ALL_GATHER:.*]] = sdy.all_gather [{"z"}, {}] %[[ALL_TO_ALL]] out_sharding=<@mesh4d_w4, [{"y"}, {"x", "w"}]>
-  // CHECK-NEXT: return %[[ALL_GATHER]]
+  // CHECK-NEXT: %[[ALL_SLICE_0:.*]] = sdy.all_slice [{}, {"x"}] %arg0 out_sharding=<@mesh4d_w4, [{"y", "z", "w":(1)2}, {"x"}]>
+  // CHECK-NEXT: %[[ALL_GATHER:.*]] = sdy.all_gather [{"z", "w":(1)2}, {}] %[[ALL_SLICE_0]] out_sharding=<@mesh4d_w4, [{"y"}, {"x"}]>
+  // CHECK-NEXT: %[[ALL_SLICE_1:.*]] = sdy.all_slice [{}, {"w"}] %[[ALL_GATHER]] out_sharding=<@mesh4d_w4, [{"y"}, {"x", "w"}]>
+  // CHECK-NEXT: return %[[ALL_SLICE_1]]
   %0 = sdy.reshard %arg0 <@mesh4d_w4, [{"y"}, {"x", "w"}]> : tensor<16x8xf32>
   return %0 : tensor<16x8xf32>
 }
 
 // CHECK-LABEL: func @prefix_and_suffix_subaxes_not_available_to_slice
 func.func @prefix_and_suffix_subaxes_not_available_to_slice(%arg0: tensor<16x8xf32> {sdy.sharding = #sdy.sharding<@mesh4d_w16, [{"y", "w":(4)2, "z", "w":(1)2}, {}]>}) -> tensor<16x8xf32> {
-  // CHECK-NEXT: %[[ALL_SLICE_0:.*]] = sdy.all_slice [{"w":(2)2, "w":(8)2}, {"x"}] %arg0 out_sharding=<@mesh4d_w16, [{"y", "w":(4)2, "z", "w":(1)4, "w":(8)2}, {"x"}]>
-  // CHECK-NEXT: %[[ALL_TO_ALL:.*]] = sdy.all_to_all {"w":(1)4, "w":(8)2} 0->1 %[[ALL_SLICE_0]] out_sharding=<@mesh4d_w16, [{"y", "w":(4)2, "z"}, {"x", "w":(1)4, "w":(8)2}]>
-  // CHECK-NEXT: %[[ALL_GATHER:.*]] = sdy.all_gather [{"w":(4)2, "z"}, {"w":(8)2}] %[[ALL_TO_ALL]] out_sharding=<@mesh4d_w16, [{"y"}, {"x", "w":(1)4}]>
-  // CHECK-NEXT: %[[ALL_SLICE_1:.*]] = sdy.all_slice [{}, {"w":(4)4}] %[[ALL_GATHER]] out_sharding=<@mesh4d_w16, [{"y"}, {"x", "w"}]>
+  // CHECK-NEXT: %[[ALL_SLICE_0:.*]] = sdy.all_slice [{}, {"x"}] %arg0 out_sharding=<@mesh4d_w16, [{"y", "w":(4)2, "z", "w":(1)2}, {"x"}]>
+  // CHECK-NEXT: %[[ALL_GATHER:.*]] = sdy.all_gather [{"w":(4)2, "z", "w":(1)2}, {}] %[[ALL_SLICE_0]] out_sharding=<@mesh4d_w16, [{"y"}, {"x"}]>
+  // CHECK-NEXT: %[[ALL_SLICE_1:.*]] = sdy.all_slice [{}, {"w"}] %[[ALL_GATHER]] out_sharding=<@mesh4d_w16, [{"y"}, {"x", "w"}]>
   // CHECK-NEXT: return %[[ALL_SLICE_1]]
   %0 = sdy.reshard %arg0 <@mesh4d_w16, [{"y"}, {"x", "w"}]> : tensor<16x8xf32>
   return %0 : tensor<16x8xf32>
 }
 
-// TODO(b/391138813): Add proper support for axes that can't co-exist
-
-// LABEL: func @reshard_with_non_divisible_subaxes_same_pre_size
-// func.func @reshard_with_non_divisible_subaxes_same_pre_size(%arg0 : tensor<6x2xf32> {sdy.sharding=#sdy.sharding<@mesh1d_6, [{"x":(1)2}, {}]>}) -> tensor<6x2xf32> {
-//   NEXT: %[[ALL_GATHER:.*]] = sdy.all_gather [{"x":(1)2}, {}] %arg0 out_sharding=<@mesh1d_6, [{}, {}]>
-//   NEXT: %[[ALL_SLICE:.*]] = sdy.all_slice [{"x":(1)3}, {}] %[[ALL_GATHER]] out_sharding=<@mesh1d_6, [{"x":(1)3}, {}]>
-//   NEXT: return %[[ALL_SLICE]]
-//  %0 = sdy.reshard %arg0 <@mesh1d_6, [{"x":(1)3}, {}]> :  tensor<6x2xf32>
-//  return %0 : tensor<6x2xf32>
-// }
+// CHECK-LABEL: func @reshard_with_non_divisible_subaxes_same_pre_size
+func.func @reshard_with_non_divisible_subaxes_same_pre_size(%arg0 : tensor<6x2xf32> {sdy.sharding=#sdy.sharding<@mesh1d_6, [{"x":(1)2}, {}]>}) -> tensor<6x2xf32> {
+  // CHECK-NEXT: %[[ALL_GATHER:.*]] = sdy.all_gather [{"x":(1)2}, {}] %arg0 out_sharding=<@mesh1d_6, [{}, {}]>
+  // CHECK-NEXT: %[[ALL_SLICE:.*]] = sdy.all_slice [{"x":(1)3}, {}] %[[ALL_GATHER]] out_sharding=<@mesh1d_6, [{"x":(1)3}, {}]>
+  // CHECK-NEXT: return %[[ALL_SLICE]]
+ %0 = sdy.reshard %arg0 <@mesh1d_6, [{"x":(1)3}, {}]> :  tensor<6x2xf32>
+ return %0 : tensor<6x2xf32>
+}
 
-// LABEL: func @reshard_with_non_divisible_overlapping_subaxes
-// func.func @reshard_with_non_divisible_overlapping_subaxes(%arg0 : tensor<6x2xf32> {sdy.sharding=#sdy.sharding<@mesh1d_6, [{"x":(2)3}, {}]>}) -> tensor<6x2xf32> {
-//   NEXT: %[[ALL_GATHER:.*]] = sdy.all_gather [{"x":(2)3}, {}] %arg0 out_sharding=<@mesh1d_6, [{}, {}]>
-//   NEXT: %[[ALL_SLICE:.*]] = sdy.all_slice [{"x":(1)3}, {}] %[[ALL_GATHER]] out_sharding=<@mesh1d_6, [{"x":(1)3}, {}]>
-//   NEXT: return %[[ALL_SLICE]]
-//  %0 = sdy.reshard %arg0 <@mesh1d_6, [{"x":(1)3}, {}]> :  tensor<6x2xf32>
-//  return %0 : tensor<6x2xf32>
-// }
+// CHECK-LABEL: func @reshard_with_non_divisible_overlapping_subaxes
+func.func @reshard_with_non_divisible_overlapping_subaxes(%arg0 : tensor<6x2xf32> {sdy.sharding=#sdy.sharding<@mesh1d_6, [{"x":(2)3}, {}]>}) -> tensor<6x2xf32> {
+  // CHECK-NEXT: %[[ALL_GATHER:.*]] = sdy.all_gather [{"x":(2)3}, {}] %arg0 out_sharding=<@mesh1d_6, [{}, {}]>
+  // CHECK-NEXT: %[[ALL_SLICE:.*]] = sdy.all_slice [{"x":(1)3}, {}] %[[ALL_GATHER]] out_sharding=<@mesh1d_6, [{"x":(1)3}, {}]>
+  // CHECK-NEXT: return %[[ALL_SLICE]]
+ %0 = sdy.reshard %arg0 <@mesh1d_6, [{"x":(1)3}, {}]> :  tensor<6x2xf32>
+ return %0 : tensor<6x2xf32>
+}
 
-// LABEL: func @reshard_with_non_divisible_overlapping_diff_dim
-// func.func @reshard_with_non_divisible_overlapping_diff_dim(%arg0 : tensor<6x2xf32> {sdy.sharding=#sdy.sharding<@mesh1d_6, [{"x":(2)3}, {}]>}) -> tensor<6x2xf32> {
-//   NEXT: %[[ALL_GATHER:.*]] = sdy.all_gather [{"x":(2)3}, {}] %arg0 out_sharding=<@mesh1d_6, [{}, {}]>
-//   NEXT: %[[ALL_SLICE:.*]] = sdy.all_slice [{}, {"x":(1)3}] %[[ALL_GATHER]] out_sharding=<@mesh1d_6, [{}, {"x":(1)3}]>
-//   NEXT: return %[[ALL_SLICE]]
-//  %0 = sdy.reshard %arg0 <@mesh1d_6, [{}, {"x":(1)3}]> :  tensor<6x2xf32>
-//  return %0 : tensor<6x2xf32>
-// }
+// CHECK-LABEL: func @reshard_with_non_divisible_overlapping_diff_dim
+func.func @reshard_with_non_divisible_overlapping_diff_dim(%arg0 : tensor<6x2xf32> {sdy.sharding=#sdy.sharding<@mesh1d_6, [{"x":(2)3}, {}]>}) -> tensor<6x2xf32> {
+  // CHECK-NEXT: %[[ALL_GATHER:.*]] = sdy.all_gather [{"x":(2)3}, {}] %arg0 out_sharding=<@mesh1d_6, [{}, {}]>
+  // CHECK-NEXT: %[[ALL_SLICE:.*]] = sdy.all_slice [{}, {"x":(1)3}] %[[ALL_GATHER]] out_sharding=<@mesh1d_6, [{}, {"x":(1)3}]>
+  // CHECK-NEXT: return %[[ALL_SLICE]]
+ %0 = sdy.reshard %arg0 <@mesh1d_6, [{}, {"x":(1)3}]> :  tensor<6x2xf32>
+ return %0 : tensor<6x2xf32>
+}
diff --git a/shardy/dialect/sdy/transforms/propagation/basic_propagation.cc b/shardy/dialect/sdy/transforms/propagation/basic_propagation.cc
index e375bce..f843578 100644
--- a/shardy/dialect/sdy/transforms/propagation/basic_propagation.cc
+++ b/shardy/dialect/sdy/transforms/propagation/basic_propagation.cc
@@ -245,8 +245,7 @@ void updateTensorShardings(const PropagationTensorParams& operandsParams,
 LogicalResult propagateTensorShardings(
     const PropagationTensorParams& operandsParams,
     const PropagationTensorParams& resultsParams,
-    OpShardingRuleAttr shardingRule,
-    PropagationDirectionAlongFactor directionAlongFactor,
+    OpShardingRuleAttr shardingRule, PropagationDirection direction,
     const FactorPropagation& factorPropagation, bool conservativePropagation,
     Operation* op, const SymbolTable& symbolTable, PatternRewriter* rewriter,
     ShardingGroupMap shardingGroupMap) {
@@ -281,6 +280,11 @@ LogicalResult propagateTensorShardings(
   ShardingProjection shardingProjection = ShardingProjection::build(
       operandsParams.shardings, resultsParams.shardings, shardingRule, mesh);
   bool anyUpdated = false;
+
+  PropagationDirectionAlongFactor directionAlongFactor = [direction](int64_t) {
+    return direction;
+  };
+
   auto updateShardings = [&]() {
     auto [updateOperand, updateResult] =
         factorPropagation.propagateFactorShardings(
@@ -300,8 +304,8 @@ LogicalResult propagateTensorShardings(
   if (context->hasActionHandler()) {
     context->executeAction<SourceShardingAction>(
         updateShardings,
-        /*IRUnits=*/{op}, op, operandsParams.tensors, resultsParams.tensors,
-        mesh, shardingRule, shardingProjection, anyUpdated);
+        /*IRUnits=*/{op}, operandsParams.tensors, resultsParams.tensors, mesh,
+        shardingRule, shardingProjection);
   } else {
     updateShardings();
   }
@@ -314,14 +318,29 @@ LogicalResult propagateTensorShardings(
   return success(anyUpdated);
 }
 
+// Same as the overload above, except there is a single operand and result.
+LogicalResult propagateTensorShardings(
+    const PropagationTensorParams& operandsParams,
+    const PropagationTensorParams& resultsParams,
+    OpShardingRuleAttr shardingRule, Operation* op,
+    const SymbolTable& symbolTable, PatternRewriter* rewriter,
+    const FactorPropagation& factorPropagation,
+    const ShardingGroupMap& shardingGroupMap,
+    PropagationDirection direction = PropagationDirection::BOTH,
+    bool conservativePropagation = false) {
+  return propagateTensorShardings(
+      operandsParams, resultsParams, shardingRule, direction, factorPropagation,
+      conservativePropagation, op, symbolTable, rewriter, shardingGroupMap);
+}
+
 // Same as the overload above, except the operand and result shardings are
 // extracted using `getSharding` and set using `setSharding`.
 LogicalResult propagateTensorShardings(
     ValueRange operands, ValueRange results, OpShardingRuleAttr shardingRule,
     Operation* op, const SymbolTable& symbolTable, PatternRewriter& rewriter,
-    PropagationDirectionAlongFactor directionAlongFactor,
     const FactorPropagation& factorPropagation,
     const ShardingGroupMap& shardingGroupMap,
+    PropagationDirection direction = PropagationDirection::BOTH,
     bool conservativePropagation = false) {
   SmallVector<TensorShardingAttr> operandsShardings = getShardings(operands);
   SmallVector<TensorShardingAttr> resultsShardings = getShardings(results);
@@ -338,10 +357,9 @@ LogicalResult propagateTensorShardings(
         setSharding(results[index], sharding);
       });
 
-  return propagateTensorShardings(operandsParams, resultsParams, shardingRule,
-                                  directionAlongFactor, factorPropagation,
-                                  conservativePropagation, op, symbolTable,
-                                  &rewriter, shardingGroupMap);
+  return propagateTensorShardings(
+      operandsParams, resultsParams, shardingRule, direction, factorPropagation,
+      conservativePropagation, op, symbolTable, &rewriter, shardingGroupMap);
 }
 
 // Propagates the shardings between the operands of the `funcOp`'s terminator
@@ -388,12 +406,10 @@ LogicalResult propagateFuncResults(FuncOp funcOp,
     (void)propagateTensorShardings(
         operandsParams, resultsParams,
         // Treat the sharding data flow b/w the `funcOp` terminator and func
-        // result attrs as an identity op. Create an equivalent sharding rule.
-        createIdentityShardingRule(tensorType),
-        std::bind(propagateAny, funcOp, std::placeholders::_1),
-        factorPropagation,
-        /*conservativePropagation=*/false, funcOp, symbolTable,
-        /*rewriter=*/nullptr, shardingGroupMap);
+        // result attrs as an identity op. Create an equivalent sharding
+        // rule.
+        createIdentityShardingRule(tensorType), funcOp, symbolTable,
+        /*rewriter=*/nullptr, factorPropagation, shardingGroupMap);
   }
   return success();
 }
@@ -420,13 +436,13 @@ class PropagateRegisteredOp : public RewritePattern {
   explicit PropagateRegisteredOp(
       MLIRContext* context, const SymbolTable& symbolTable,
       GetDirectionToPropagateFn getDirectionToPropagate,
-      const FactorPropagation& factorPropagation, bool conservativePropagation,
+      bool conservativePropagation, const FactorPropagation& factorPropagation,
       const ShardingGroupMap& shardingGroupMap)
       : RewritePattern(MatchAnyOpTypeTag(), /*benefit=*/1, context),
         symbolTable(symbolTable),
         getDirectionToPropagate(getDirectionToPropagate),
-        factorPropagation(factorPropagation),
         conservativePropagation(conservativePropagation),
+        factorPropagation(factorPropagation),
         shardingGroupMap(shardingGroupMap) {}
 
   LogicalResult matchAndRewrite(Operation* op,
@@ -439,20 +455,26 @@ class PropagateRegisteredOp : public RewritePattern {
         diag << "op doesn't have a registered sharding rule";
       });
     }
+    PropagationDirection direction = getDirectionToPropagate(op);
+    if (direction == PropagationDirection::NONE) {
+      // No need to continue to propagate if the direction is `NONE`, as
+      // neither operands nor results can be updated.
+      return rewriter.notifyMatchFailure(op, [](Diagnostic& diag) {
+        diag << "propagation direction on op is NONE";
+      });
+    }
 
-    PropagationDirectionAlongFactor directionAlongFactor =
-        std::bind(getDirectionToPropagate, op, std::placeholders::_1);
     return propagateTensorShardings(op->getOperands(), op->getResults(),
                                     shardingRule, op, symbolTable, rewriter,
-                                    directionAlongFactor, factorPropagation,
-                                    shardingGroupMap, conservativePropagation);
+                                    factorPropagation, shardingGroupMap,
+                                    direction, conservativePropagation);
   }
 
  private:
   const SymbolTable& symbolTable;
   GetDirectionToPropagateFn getDirectionToPropagate;
-  const FactorPropagation& factorPropagation;
   bool conservativePropagation;
+  const FactorPropagation& factorPropagation;
   const ShardingGroupMap& shardingGroupMap;
 };
 
@@ -462,21 +484,27 @@ class PropagateRegisteredOp : public RewritePattern {
 // The `sdy.data_flow_edge` holds the updateable sharding of all targets.
 class PropagateDataFlowEdgeOp : public OpRewritePattern<DataFlowEdgeOp> {
  public:
-  explicit PropagateDataFlowEdgeOp(
-      MLIRContext* context, const SymbolTable& symbolTable,
-      GetDirectionToPropagateFn getDirectionToPropagate,
-      const FactorPropagation& factorPropagation,
-      const ShardingGroupMap& shardingGroupMap)
+  explicit PropagateDataFlowEdgeOp(MLIRContext* context,
+                                   const SymbolTable& symbolTable,
+                                   const FactorPropagation& factorPropagation,
+                                   const ShardingGroupMap& shardingGroupMap)
       : OpRewritePattern<DataFlowEdgeOp>(context),
         symbolTable(symbolTable),
-        getDirectionToPropagate(getDirectionToPropagate),
         factorPropagation(factorPropagation),
         shardingGroupMap(shardingGroupMap) {}
 
   LogicalResult matchAndRewrite(DataFlowEdgeOp dataFlowEdgeOp,
                                 PatternRewriter& rewriter) const override {
     SmallVector<Value> sources = dataFlowEdgeOp.getSources();
+    // The sharding of `dataFlowEdgeOp.getResult()` is the sharding of all
+    // targets.
+
     SmallVector<TensorShardingAttr> operandShardingRef = getShardings(sources);
+    TensorShardingAttr resultsShardingRef =
+        dataFlowEdgeOp.transformTargetSharding(
+            dataFlowEdgeOp.getShardingAttr(),
+            DataFlowShardingTransformType::kBeforeEdgePropagation);
+
     PropagationTensorParams operandsParams = PropagationTensorParams(
         /*tensors=*/sources,
         /*shardings=*/operandShardingRef,
@@ -484,36 +512,26 @@ class PropagateDataFlowEdgeOp : public OpRewritePattern<DataFlowEdgeOp> {
         [&sources](TensorShardingAttr sharding, int64_t index) {
           setSharding(sources[index], sharding);
         });
-
     Value result = dataFlowEdgeOp.getResult();
-    // The sharding of `result` is the sharding of all targets.
-    TensorShardingAttr resultsShardingRef =
-        dataFlowEdgeOp.transformTargetSharding(
-            dataFlowEdgeOp.getShardingAttr(),
-            DataFlowShardingTransformType::kBeforeEdgePropagation);
     PropagationTensorParams resultsParams = PropagationTensorParams(
         /*tensors=*/result,
         /*shardings=*/resultsShardingRef,
         /*setShardingCallback=*/
-        [&dataFlowEdgeOp](TensorShardingAttr sharding, int64_t) {
+        [&dataFlowEdgeOp](TensorShardingAttr sharding, int64_t _) {
           dataFlowEdgeOp.setShardingAttr(dataFlowEdgeOp.transformTargetSharding(
               sharding, DataFlowShardingTransformType::kAfterEdgePropagation));
         });
 
-    PropagationDirectionAlongFactor directionAlongFactor = std::bind(
-        getDirectionToPropagate, dataFlowEdgeOp, std::placeholders::_1);
     return propagateTensorShardings(
         operandsParams, resultsParams,
         createIdentityShardingRule(cast<ShapedType>(dataFlowEdgeOp.getType()),
                                    sources.size()),
-        directionAlongFactor, factorPropagation,
+        PropagationDirection::BOTH, factorPropagation,
         /*conservativePropagation=*/false, dataFlowEdgeOp, symbolTable,
         &rewriter, shardingGroupMap);
   }
-
  private:
   const SymbolTable& symbolTable;
-  GetDirectionToPropagateFn getDirectionToPropagate;
   const FactorPropagation& factorPropagation;
   const ShardingGroupMap& shardingGroupMap;
 };
@@ -538,9 +556,8 @@ class PropagatePropagationBarrier
         propagationBarrierOp.getInput(), propagationBarrierOp.getResult(),
         createIdentityShardingRule(
             cast<RankedTensorType>(propagationBarrierOp.getType())),
-        propagationBarrierOp, symbolTable, rewriter,
-        [&](int64_t) { return propagationBarrierOp.getAllowedDirection(); },
-        factorPropagation, shardingGroupMap);
+        propagationBarrierOp, symbolTable, rewriter, factorPropagation,
+        shardingGroupMap, propagationBarrierOp.getAllowedDirection());
   }
 
  private:
@@ -587,7 +604,7 @@ bool allValidShapes(ModuleOp moduleOp) {
 
 }  // namespace
 
-PropagationDirection propagateAny(Operation*, int64_t) {
+PropagationDirection propagateAny(Operation*) {
   return PropagationDirection::BOTH;
 }
 
@@ -604,16 +621,14 @@ LogicalResult BasicPropagationPassImpl::propagate(
   }
   MLIRContext* context = moduleOp.getContext();
   RewritePatternSet patterns(context);
-  patterns.add<PropagatePropagationBarrier>(
+  patterns.add<PropagateDataFlowEdgeOp, PropagatePropagationBarrier>(
       context, symbolTable, factorPropagation, shardingGroupMap);
-  patterns.add<PropagateDataFlowEdgeOp>(context, symbolTable,
-                                        getDirectionToPropagate,
-                                        factorPropagation, shardingGroupMap);
   patterns.add<PropagateRegisteredOp>(
-      context, symbolTable, getDirectionToPropagate, factorPropagation,
-      conservativePropagation, shardingGroupMap);
-  // We only need a single iteration (and another to confirm convergence), since
-  // we make sure ops whose sharding changes are added back to the worklist.
+      context, symbolTable, getDirectionToPropagate, conservativePropagation,
+      factorPropagation, shardingGroupMap);
+  // Note that we only need a single iteration (and another to confirm
+  // convergence), since we make sure ops whose sharding changes are
+  // added back to the worklist.
   GreedyRewriteConfig config;
   config.useTopDownTraversal = true;
   config.enableRegionSimplification = mlir::GreedySimplifyRegionLevel::Disabled;
@@ -650,8 +665,7 @@ void BasicPropagationPassImpl::runOnOperation() {
   MLIRContext& context = getContext();
 
   // Prepare debugging handler for sharding origins and edge sources.
-  ShardingDebugMappings mappings(debugShardingOrigins,
-                                 debugPropagationEdgeSharding);
+  ShardingDebugMappings mappings(debugShardingOrigins, debugEdgeSourceSharding);
   SourceShardingHandler handler(&mappings);
   handler.prepareHandler(moduleOp);
 
@@ -685,7 +699,7 @@ void BasicPropagationPassImpl::setPropagationOptions(
   dumpDirectory = options.dumpDirectory.str();
   conservativePropagation = options.conservativePropagation;
   debugShardingOrigins = options.debugShardingOrigins;
-  debugPropagationEdgeSharding = options.debugPropagationEdgeSharding;
+  debugEdgeSourceSharding = options.debugEdgeSourceSharding;
 }
 
 std::unique_ptr<Pass> createBasicPropagationPass(
diff --git a/shardy/dialect/sdy/transforms/propagation/basic_propagation.h b/shardy/dialect/sdy/transforms/propagation/basic_propagation.h
index 7b98935..732565d 100644
--- a/shardy/dialect/sdy/transforms/propagation/basic_propagation.h
+++ b/shardy/dialect/sdy/transforms/propagation/basic_propagation.h
@@ -17,8 +17,6 @@ limitations under the License.
 #define SHARDY_DIALECT_SDY_TRANSFORMS_PROPAGATION_BASIC_PROPAGATION_H_
 
 #include <stdbool.h>
-
-#include <cstdint>
 #include <functional>
 #include <memory>
 #include <string>
@@ -31,22 +29,21 @@ limitations under the License.
 #include "mlir/Support/LLVM.h"
 #include "mlir/Support/LogicalResult.h"
 #include "shardy/dialect/sdy/ir/dialect.h"
+#include "shardy/dialect/sdy/transforms/propagation/passes.h"
 #include "shardy/dialect/sdy/transforms/propagation/basic_factor_propagation.h"
 #include "shardy/dialect/sdy/transforms/propagation/factor_propagation.h"
-#include "shardy/dialect/sdy/transforms/propagation/passes.h"
 #include "shardy/dialect/sdy/transforms/propagation/sharding_group_map.h"
 
 namespace mlir {
 namespace sdy {
 
 // A function that determines in which direction propagation should happen for a
-// given op and factor index.
+// given op.
 using GetDirectionToPropagateFn =
-    std::function<PropagationDirection(Operation* op, int64_t factorIndex)>;
+    std::function<PropagationDirection(Operation*)>;
 
-// A function that returns `PropagationDirection::BOTH` for all operations and
-// factor indices.
-PropagationDirection propagateAny(Operation* op, int64_t factorIndex);
+// A function that returns `PropagationDirection::BOTH` for all operations.
+PropagationDirection propagateAny(Operation* op);
 
 // The implementation class for the basic propagation pass.
 //
@@ -126,12 +123,12 @@ class BasicPropagationPassImpl : public OperationPass<ModuleOp> {
           "before propagation."),
       llvm::cl::init(false)};
 
-  Option<bool> debugPropagationEdgeSharding{
-      *this, "debug-propagation-edge-sharding",
+  Option<bool> debugEdgeSourceSharding{
+      *this, "debug-edge-source-sharding",
       llvm::cl::desc(
-          "whether to save information about the SSA value edges of how a "
-          "sharding on the MLIR module propagated around. These are from which "
-          "operand/result a sharding was propagated to a given op."),
+          "whether to save information about the edge source of a sharding "
+          "on the MLIR module. These are from which operand/result a sharding "
+          "was propagated."),
       llvm::cl::init(false)};
 
  private:
diff --git a/shardy/dialect/sdy/transforms/propagation/debugging/source_sharding.cc b/shardy/dialect/sdy/transforms/propagation/debugging/source_sharding.cc
index e45a6b2..cdbd067 100644
--- a/shardy/dialect/sdy/transforms/propagation/debugging/source_sharding.cc
+++ b/shardy/dialect/sdy/transforms/propagation/debugging/source_sharding.cc
@@ -22,7 +22,6 @@ limitations under the License.
 #include <optional>
 #include <string>
 
-#include "llvm/ADT/DenseSet.h"
 #include "llvm/ADT/STLExtras.h"
 #include "llvm/ADT/StringRef.h"
 #include "llvm/Support/ErrorHandling.h"
@@ -35,9 +34,7 @@ limitations under the License.
 #include "mlir/IR/BuiltinOps.h"
 #include "mlir/IR/MLIRContext.h"
 #include "mlir/IR/Operation.h"
-#include "mlir/IR/PatternMatch.h"
 #include "mlir/IR/Value.h"
-#include "mlir/IR/ValueRange.h"
 #include "mlir/Support/LLVM.h"
 #include "shardy/dialect/sdy/ir/constants.h"
 #include "shardy/dialect/sdy/ir/dialect.h"
@@ -50,8 +47,8 @@ namespace sdy {
 namespace {
 
 // The map from factor to edge source for operands and results.
-struct FactorsToEdgeMap {
-  llvm::SmallVector<AxisToEdgeMap> operands, results;
+struct FactorsToEdgeSourceMap {
+  llvm::SmallVector<AxisToEdgeSourceMap> operands, results;
 };
 
 // Finds what operand/result the new sharding axes came from for a given
@@ -76,120 +73,123 @@ std::optional<int64_t> findNewAxisRefMatch(
 //
 // This only saves any newly introduced factor shardings, not any pre-existing
 // ones. So if no operand/result sharding changes, the map will be empty.
-FactorsToEdgeMap createSourceMap(
+FactorsToEdgeSourceMap createSourceMap(
     const ShardingProjection& oldShardingProjection,
     const ShardingProjection& newShardingProjection,
-    OpShardingRuleAttr shardingRule, MeshAttr mesh,
-    const int64_t propagationStep) {
-  FactorsToEdgeMap axisToEdgeMap{
-      llvm::SmallVector<AxisToEdgeMap>(oldShardingProjection.getNumOperands(),
-                                       AxisToEdgeMap()),
-      llvm::SmallVector<AxisToEdgeMap>(oldShardingProjection.getNumResults(),
-                                       AxisToEdgeMap())};
+    OpShardingRuleAttr shardingRule, MeshAttr mesh) {
+  FactorsToEdgeSourceMap axisToEdgeSourceMap{
+      llvm::SmallVector<AxisToEdgeSourceMap>(
+          oldShardingProjection.getNumOperands(), AxisToEdgeSourceMap()),
+      llvm::SmallVector<AxisToEdgeSourceMap>(
+          oldShardingProjection.getNumResults(), AxisToEdgeSourceMap())};
 
   // Saves the `axisRefs` to the specified `valueSourceMap` of
-  // `axisToEdgeMap`.
-  auto saveEdges = [&](ArrayRef<AxisRefAttr> newAxisRefs,
-                       ArrayRef<AxisRefAttr> oldAxisRefs, EdgeNode source,
-                       EdgeNode target, AxisToEdgeMap& valueSourceMap) {
+  // `axisToEdgeSourceMap`.
+  auto saveEdgeSources = [&](ArrayRef<AxisRefAttr> newAxisRefs,
+                             ArrayRef<AxisRefAttr> oldAxisRefs,
+                             EdgeSourceType type, int64_t sourceIndex,
+                             AxisToEdgeSourceMap& valueSourceMap) {
     // To avoid iterating over all the new axes, only compare the very last old
     // axis (since there could have been a sub-axis update) and then the
     // trailing new axes.
     int64_t oldAxisIndex = oldAxisRefs.size() - 1;
     if (!oldAxisRefs.empty() &&
         oldAxisRefs[oldAxisIndex] != newAxisRefs[oldAxisIndex]) {
-      valueSourceMap.try_emplace(
-          newAxisRefs[oldAxisIndex],
-          PropagationEdge{source, target, propagationStep});
+      valueSourceMap.try_emplace(newAxisRefs[oldAxisIndex],
+                                 EdgeSource{type, sourceIndex});
     }
     for (AxisRefAttr axisRef : newAxisRefs.drop_front(oldAxisRefs.size())) {
-      valueSourceMap.try_emplace(
-          axisRef, PropagationEdge{source, target, propagationStep});
+      valueSourceMap.try_emplace(axisRef, EdgeSource{type, sourceIndex});
     }
   };
 
   MLIRContext* context = mesh.getContext();
   ArrayRef<int64_t> factorSizes = shardingRule.getFactorSizes();
-  auto visitValue = [&](const TensorFactorShardings& oldValue,
-                        const TensorFactorShardings& newValue,
-                        EdgeNodeType valueType, int64_t valueIndex,
-                        TensorMappingAttr tensorMapping,
-                        llvm::SmallVector<AxisToEdgeMap>& valueSourceMap) {
-    DenseSet<AxisRefAttr> oldAxes;
-    for (const auto& [_, oldFactorSharding] : oldValue.factorIndexToSharding) {
-      oldAxes.insert(oldFactorSharding.axisRefs.begin(),
-                     oldFactorSharding.axisRefs.end());
-    }
-    for (const auto& [oldFactorSharding, newFactorSharding] : llvm::zip_equal(
-             oldValue.factorIndexToSharding, newValue.factorIndexToSharding)) {
-      if (oldFactorSharding.second.axisRefs ==
-          newFactorSharding.second.axisRefs) {
-        continue;
-      }
-      SmallVector<AxisRefAttr> newlyIntroducedAxes;
-      // If multiple sub axes can be merged due to a dimension sharding having
-      // multiple factors, each sharded on a sub axis, make sure we only save
-      // the merged one. This can happen during an `(A, B) -> (AB,)` reshape.
-      TensorShardingAttr tensorSharding = newValue.createTensorShardingAttr(
-          context, tensorMapping, factorSizes, "", mesh);
-      for (DimensionShardingAttr dimSharding :
-           tensorSharding.getDimShardings()) {
-        llvm::copy_if(
-            dimSharding.getAxes(), std::back_inserter(newlyIntroducedAxes),
-            [&](const AxisRefAttr& axisRef) {
-              // Don't add any axes that were already in the
-              // old sharding. We just want new axes.
-              if (oldAxes.contains(axisRef)) {
-                return false;
-              }
-              // We need to avoid any axes that already existed in the old
-              // sharding, but aren't in the new projection as the conflicted.
-              // E.g. for a contracting dim matmul, if both the LHS/RHS are
-              // sharded on the same axis on their respective non-contracting
-              // dims, the dimension sharding will contain the conflicting axes,
-              // but the factor sharding will not. And we don't want this axis
-              // as it isn't a newly introduced axis.
-              for (AxisRefAttr newAxisRef : newFactorSharding.second.axisRefs) {
-                if (newAxisRef.prefixOf(axisRef)) {
-                  return true;
-                }
-              }
-              return false;
-            });
-      }
-      // This factor sharding has changed, let's find who changed it.
-      if (std::optional<int64_t> operandSource = findNewAxisRefMatch(
-              newFactorSharding.second.axisRefs, oldFactorSharding.first,
-              oldShardingProjection.getOperands())) {
-        saveEdges(newlyIntroducedAxes, oldFactorSharding.second.axisRefs,
-                  EdgeNode{EdgeNodeType::OPERAND, *operandSource},
-                  EdgeNode{valueType, valueIndex}, valueSourceMap[valueIndex]);
-      } else if (std::optional<int64_t> resultSource = findNewAxisRefMatch(
-                     newFactorSharding.second.axisRefs, oldFactorSharding.first,
-                     oldShardingProjection.getResults())) {
-        saveEdges(newlyIntroducedAxes, oldFactorSharding.second.axisRefs,
-                  EdgeNode{EdgeNodeType::RESULT, *resultSource},
-                  EdgeNode{valueType, valueIndex}, valueSourceMap[valueIndex]);
-      }
-    }
-  };
+  auto visitValue =
+      [&](const TensorFactorShardings& oldValue,
+          const TensorFactorShardings& newValue, int64_t valueIndex,
+          TensorMappingAttr tensorMapping,
+          llvm::SmallVector<AxisToEdgeSourceMap>& valueSourceMap) {
+        DenseSet<AxisRefAttr> oldAxes;
+        for (const auto& [_, oldFactorSharding] :
+             oldValue.factorIndexToSharding) {
+          oldAxes.insert(oldFactorSharding.axisRefs.begin(),
+                         oldFactorSharding.axisRefs.end());
+        }
+        for (const auto& [factorIndex, oldFactorSharding] :
+             oldValue.factorIndexToSharding) {
+          const FactorSharding& newFactorSharding =
+              newValue.factorIndexToSharding.at(factorIndex);
+          if (oldFactorSharding.axisRefs == newFactorSharding.axisRefs) {
+            continue;
+          }
+          SmallVector<AxisRefAttr> newlyIntroducedAxes;
+          // If multiple sub axes can be merged due to a dimension sharding
+          // having multiple factors, each sharded on a sub axis, make sure we
+          // only save the merged one. This can happen during an
+          // `(A, B) -> (AB,)` reshape.
+          TensorShardingAttr tensorSharding = newValue.createTensorShardingAttr(
+              context, tensorMapping, factorSizes, "", mesh);
+          for (DimensionShardingAttr dimSharding :
+               tensorSharding.getDimShardings()) {
+            llvm::copy_if(
+                dimSharding.getAxes(), std::back_inserter(newlyIntroducedAxes),
+                [&](const AxisRefAttr& axisRef) {
+                  // Don't add any axes that were already in the
+                  // old sharding. We just want new axes.
+                  if (oldAxes.contains(axisRef)) {
+                    return false;
+                  }
+                  // We need to avoid any axes that already existed
+                  // in the old sharding, but aren't in the new
+                  // projection as the conflicted. E.g. for a
+                  // contracting dim matmul, if both the LHS/RHS are
+                  // sharded on the same axis on their respective
+                  // non-contracting dims, the dimension sharding
+                  // will contain the conflicting axes, but the
+                  // factor sharding will not. And we don't want this
+                  // axis as it isn't a newly introduced axis.
+                  for (AxisRefAttr newAxisRef : newFactorSharding.axisRefs) {
+                    if (newAxisRef.prefixOf(axisRef)) {
+                      return true;
+                    }
+                  }
+                  return false;
+                });
+          }
+          // This factor sharding has changed, let's find who changed it.
+          if (std::optional<int64_t> operandSource =
+                  findNewAxisRefMatch(newFactorSharding.axisRefs, factorIndex,
+                                      oldShardingProjection.getOperands())) {
+            saveEdgeSources(newlyIntroducedAxes, oldFactorSharding.axisRefs,
+                            EdgeSourceType::OPERAND, *operandSource,
+                            valueSourceMap[valueIndex]);
+          } else if (std::optional<int64_t> resultSource = findNewAxisRefMatch(
+                         newFactorSharding.axisRefs, factorIndex,
+                         oldShardingProjection.getResults())) {
+            saveEdgeSources(newlyIntroducedAxes, oldFactorSharding.axisRefs,
+                            EdgeSourceType::RESULT, *resultSource,
+                            valueSourceMap[valueIndex]);
+          }
+        }
+      };
 
   for (auto [i, packedOperands] :
        llvm::enumerate(llvm::zip_equal(oldShardingProjection.getOperands(),
                                        newShardingProjection.getOperands()))) {
     auto [oldOperand, newOperand] = packedOperands;
-    visitValue(oldOperand, newOperand, EdgeNodeType::OPERAND, i,
-               shardingRule.getOperandMapping(i), axisToEdgeMap.operands);
+    visitValue(oldOperand, newOperand, i, shardingRule.getOperandMapping(i),
+               axisToEdgeSourceMap.operands);
   }
   for (auto [i, packedResults] :
        llvm::enumerate(llvm::zip_equal(oldShardingProjection.getResults(),
                                        newShardingProjection.getResults()))) {
     auto [oldResult, newResult] = packedResults;
-    visitValue(oldResult, newResult, EdgeNodeType::RESULT, i,
-               shardingRule.getResultMapping(i), axisToEdgeMap.results);
+    visitValue(oldResult, newResult, i, shardingRule.getResultMapping(i),
+               axisToEdgeSourceMap.results);
   }
 
-  return axisToEdgeMap;
+  return axisToEdgeSourceMap;
 }
 
 std::string manualComputationOriginName(OriginShardingType type, StringRef name,
@@ -243,12 +243,6 @@ StringAttr shardingOriginToString(OriginSharding source, MLIRContext* context) {
                          llvm::formatv("{0}: {1}", typeString, source.index));
 }
 
-// Avoid printing the string with escaping quotes, aka "\22".
-void eraseDoubleQuotesInAxisRefString(std::string& axisRefString) {
-  axisRefString.erase(remove(axisRefString.begin(), axisRefString.end(), '"'),
-                      axisRefString.end());
-}
-
 // Create a list of entries from the `axisToOriginSharding` map to save as a
 // `DictionaryAttr`.
 SmallVector<NamedAttribute> createOriginShardingEntries(
@@ -257,7 +251,9 @@ SmallVector<NamedAttribute> createOriginShardingEntries(
   entries.reserve(axisToOriginSharding.size());
   for (const auto& [axisRef, shardingOrigin] : axisToOriginSharding) {
     std::string axisRefString = axisRef.toString();
-    eraseDoubleQuotesInAxisRefString(axisRefString);
+    // Avoid printing the string with escaping quotes, aka "\22".
+    axisRefString.erase(remove(axisRefString.begin(), axisRefString.end(), '"'),
+                        axisRefString.end());
     entries.emplace_back(
         NamedAttribute(StringAttr::get(context, axisRefString),
                        shardingOriginToString(shardingOrigin, context)));
@@ -277,40 +273,33 @@ SmallVector<Attribute> getOriginShardingDicts(Operation* op, Builder& builder) {
   return SmallVector<Attribute>(resultDicts.getValue());
 }
 
-// Gets the `OpOperand` of the `value` in the `funcOp` terminator if the Value
-// is used in the terminator. Else returns `nullptr`.
-OpOperand* getTerminatorOperand(Value value, func::FuncOp funcOp) {
-  ArrayRef<OpOperand> terminatorOperands =
-      getBodyTerminator(funcOp)->getOpOperands();
-  if (auto it = llvm::find_if(value.getUses(),
-                              [&](const OpOperand& use) {
-                                return llvm::is_contained(terminatorOperands,
-                                                          use);
-                              });
-      it != value.getUses().end()) {
-    return it.getOperand();
-  }
-  return nullptr;
-}
-
-// Saves the originating sharding debug information on each `Value` in
-// `valueToOriginShardingMap`.
-void saveShardingOriginsOnModule(
-    MLIRContext* context,
-    const ValueToOriginShardingMap& valueToOriginShardingMap) {
+// Saves the originating sharding debug information on the `moduleOp`.
+void saveShardingOriginsOnModule(ModuleOp moduleOp,
+                                 ShardingDebugMappings* mappings) {
+  MLIRContext* context = moduleOp.getContext();
   Builder builder(context);
-  for (auto& [value, axisToOriginSharding] : valueToOriginShardingMap) {
+  for (auto [value, axisToOriginSharding] :
+       mappings->valueToOriginShardingMap) {
     Operation* owningOp = getOwningOp(value);
 
     func::FuncOp funcOp = getEnclosingOfType<func::FuncOp>(owningOp);
 
     // TODO(bartchr): Swap the map to store `ValueOrFuncResult` to avoid having
     // to do this terminator finding logic just to set the func result attr.
-    OpOperand* terminatorOperand = getTerminatorOperand(value, funcOp);
+    OpOperand* terminatorOperand = nullptr;
+    ArrayRef<OpOperand> terminatorOperands =
+        getBodyTerminator(funcOp)->getOpOperands();
+    if (auto it = llvm::find_if(value.getUses(),
+                                [&](const OpOperand& use) {
+                                  return llvm::is_contained(terminatorOperands,
+                                                            use);
+                                });
+        it != value.getUses().end()) {
+      terminatorOperand = it.getOperand();
+    }
 
     SmallVector<NamedAttribute> entries =
         createOriginShardingEntries(axisToOriginSharding, context);
-
     if (terminatorOperand) {
       int64_t operandNumber = terminatorOperand->getOperandNumber();
       funcOp.setResultAttr(operandNumber, kShardingOriginsAttr,
@@ -339,131 +328,6 @@ void saveShardingOriginsOnModule(
   }
 }
 
-// Converts the `node` to a `NamedAttribute`.
-StringAttr edgeNodeToString(EdgeNode node, Builder& builder) {
-  std::string typeString;
-  switch (node.type) {
-    case EdgeNodeType::OPERAND: {
-      typeString = "operand";
-      break;
-    }
-    case EdgeNodeType::RESULT: {
-      typeString = "result";
-      break;
-    }
-  }
-  return builder.getStringAttr(
-      llvm::formatv("{0}: {1}", typeString, node.index));
-}
-
-// In the case where we have a Value used multiple times as an operand, we
-// should only add the edge once. For example:
-// ```mlir
-// %0 = stablehlo.add %arg0, %arg0 <[<@mesh, [{"a", ?}]>]> : tensor<8xf32>
-// return %0 : tensor<8xf32>
-// ```
-// The sharding projection said that both operand 0 and 1 are updated. However,
-// they are the same value, so we only need to add the edge once. This is only
-// the case for the target of the edge, because if the source appears multiple
-// times, then it's because it effects multiple other operands/results in the
-// op.
-bool insertSeenValue(Operation* op, const PropagationEdge& edge,
-                     llvm::SmallDenseSet<Value>& seenValues) {
-  EdgeNode target = edge.target;
-  switch (target.type) {
-    case EdgeNodeType::OPERAND: {
-      if (auto funcOp = dyn_cast<func::FuncOp>(op)) {
-        return seenValues.insert(
-            getBodyTerminator(funcOp)->getOperand(target.index)).second;
-      }
-      return seenValues.insert(op->getOperand(target.index)).second;
-    }
-    case EdgeNodeType::RESULT: {
-      return true;
-    }
-  }
-}
-
-// Create a list of entries from the `axisToEdge` map to save as a
-// `DictionaryAttr`.
-DictionaryAttr createEdgeEntries(Operation* op,
-                                 const AxisToEdgesMap& axisToEdges,
-                                 MLIRContext* context) {
-  Builder builder(context);
-  SmallVector<NamedAttribute> entries;
-  for (const auto& [axisRef, edges] : axisToEdges) {
-    std::string axisRefString = axisRef.toString();
-    eraseDoubleQuotesInAxisRefString(axisRefString);
-    SmallVector<Attribute> axisEntries;
-    llvm::SmallDenseSet<Value> seenTargetValues;
-    for (const PropagationEdge& edge : edges) {
-      assert(edge.source.type == EdgeNodeType::OPERAND ||
-             edge.source.type == EdgeNodeType::RESULT);
-      if (!insertSeenValue(op, edge, seenTargetValues)) {
-        continue;
-      }
-      StringAttr sourceEntry = edgeNodeToString(edge.source, builder);
-      StringAttr targetEntry = edgeNodeToString(edge.target, builder);
-      DictionaryAttr edgeEntry = builder.getDictionaryAttr({
-          builder.getNamedAttr("source", sourceEntry),
-          builder.getNamedAttr("target", targetEntry),
-          builder.getNamedAttr("propagation_step",
-                               builder.getI64IntegerAttr(edge.propagationStep)),
-      });
-      axisEntries.push_back(edgeEntry);
-    }
-    entries.emplace_back(builder.getStringAttr(axisRefString),
-                         builder.getArrayAttr(axisEntries));
-  }
-  return builder.getDictionaryAttr(entries);
-}
-
-// Saves the originating sharding debug information on each `op` in
-// `mappings->operationToEdgesMap`.
-//
-// This works by having each `Operation*` save a source/target edge, which is
-// always composed of at least one operand. This is because results
-// can be used several times, but an operand only ever has one defining op. So
-// these edges always look "backwards" - never forwards towards a use of a
-// result.
-//
-// As such, the `FuncOp` args don't contain edge source information: only the
-// ops that use them.
-void saveEdgesOnModule(MLIRContext* context,
-                       const OperationToEdgesMap& operationToEdgesMap) {
-  Builder builder(context);
-  for (auto [op, axisToEdges] : operationToEdgesMap) {
-    if (isa<func::FuncOp>(op)) {
-      continue;
-    }
-    op->setAttr(kPropagationEdgesAttr,
-                createEdgeEntries(op, axisToEdges, context));
-  }
-}
-
-// Saves the edge source sharding debug information on the result attrs of
-// `funcOp`.
-//
-// Since only the uses of a sharding save the edge, for `FuncOp` results which
-// have been updated, we save the edges in each result's `resultAttr`. If the
-// function has multiple results, then each `edge_source` on the func result
-// attributes will have index 0. This is because of how propagation works with
-// running propagation on each returned result. Having them have the right index
-// would make sense if the `sdy.edge_sources` were saved as a top level
-// attribute on the func, but since one is saved per result, then an index of 0
-// makes most sense.
-void saveEdgesOnFuncResults(func::FuncOp funcOp,
-                            const FuncResultToEdgesMap& funcResultToEdgesMap) {
-  for (auto [funcOp, resultToEdgesMap] : funcResultToEdgesMap) {
-    for (auto [resultIndex, axisToEdgesMap] :
-         llvm::enumerate(resultToEdgesMap)) {
-      funcOp.setResultAttr(
-          resultIndex, kPropagationEdgesAttr,
-          createEdgeEntries(funcOp, axisToEdgesMap, funcOp->getContext()));
-    }
-  }
-}
-
 // Saves the sharding origin information on the `value` to the `handler`.
 void saveShardingOrigins(ValueToOriginShardingMap& valueToOriginShardingMap,
                          TensorShardingAttr sharding, OriginShardingType type,
@@ -564,14 +428,13 @@ void overrideOriginsToSelf(ModuleOp moduleOp) {
   });
 }
 
-// Sets up `valueToOriginShardingMap` with the initial sharding origin
-// information on the `moduleOp`.
-//
-// The `SourceShardingHandler` will keep `valueToOriginShardingMap` up to date
-// with the origin sharding information on the module during the propagation
-// rewrite patterns.
-void prepareShardingOriginsHandler(
-    ModuleOp moduleOp, ValueToOriginShardingMap& valueToOriginShardingMap) {
+// Sets up the `handler` with the initial sharding origin information on
+// the `moduleOp`.
+// The `SourceShardingHandler` will keep `valueToEdgeSourceMap` and
+// `valueToOriginShardingMap` up to date with the source sharding information
+// on the module during the propagation rewrite patterns.
+void prepareShardingOriginsHandler(ModuleOp moduleOp,
+                                   ShardingDebugMappings* mappings) {
   MLIRContext* context = moduleOp.getContext();
   // Build the initial sharding origin map.
   // NOTE(bartchr): This assumes that we do not propagate across different
@@ -579,21 +442,22 @@ void prepareShardingOriginsHandler(
   // this if we do propagate across `FuncOp`s.
   moduleOp.walk([&](func::FuncOp funcOp) {
     for (BlockArgument arg : funcOp.getArguments()) {
-      saveShardingOrigins(valueToOriginShardingMap, getSharding(arg),
+      saveShardingOrigins(mappings->valueToOriginShardingMap, getSharding(arg),
                           OriginShardingType::INPUT, arg, arg.getArgNumber());
     }
     for (OpOperand& returnOperand : getBodyTerminatorOpOperands(funcOp)) {
       int64_t valueIndex = returnOperand.getOperandNumber();
-      saveShardingOrigins(
-          valueToOriginShardingMap, getFuncResultSharding(funcOp, valueIndex),
-          OriginShardingType::OUTPUT, returnOperand.get(), valueIndex);
+      saveShardingOrigins(mappings->valueToOriginShardingMap,
+                          getFuncResultSharding(funcOp, valueIndex),
+                          OriginShardingType::OUTPUT, returnOperand.get(),
+                          valueIndex);
     }
   });
   // NOTE: all `ManualComputationOp`s and `ShardingConstraintOp`s will have a
   // unique source name, no matter if they aren't in the same `FuncOp`.
   int64_t sourceId = 0;
   moduleOp.walk([&](ShardingConstraintOp shardingConstraintOp) {
-    saveShardingOrigins(valueToOriginShardingMap,
+    saveShardingOrigins(mappings->valueToOriginShardingMap,
                         shardingConstraintOp.getSharding(),
                         OriginShardingType::CONSTRAINT,
                         shardingConstraintOp.getResult(), 0, sourceId);
@@ -612,7 +476,7 @@ void prepareShardingOriginsHandler(
       auto edge =
           DataFlowEdgeOp::lookup(manualComputationOp.getBody().getArgument(i));
       assert(edge);
-      saveShardingOrigins(valueToOriginShardingMap, sharding,
+      saveShardingOrigins(mappings->valueToOriginShardingMap, sharding,
                           OriginShardingType::MC_INPUT, edge.getResult(), i,
                           sourceId);
     }
@@ -621,7 +485,7 @@ void prepareShardingOriginsHandler(
       // Assuming that the edges live as the only use of the op results.
       auto edge = DataFlowEdgeOp::lookup(manualComputationOp.getResult(i));
       assert(edge);
-      saveShardingOrigins(valueToOriginShardingMap, sharding,
+      saveShardingOrigins(mappings->valueToOriginShardingMap, sharding,
                           OriginShardingType::MC_OUTPUT, edge.getResult(), i,
                           sourceId);
     }
@@ -632,26 +496,12 @@ void prepareShardingOriginsHandler(
   });
 }
 
-// Sets up `funcResultToEdgesMap` for saving the edge source information
-// on the `moduleOp`.
-//
-// The `SourceShardingHandler` will keep `funcResultToEdgesMap` up to date
-// with the source sharding information on the module during the propagation
-// rewrite patterns.
-void prepareFuncResultToEdgesHandler(
-    ModuleOp moduleOp, FuncResultToEdgesMap& funcResultToEdgesMap) {
-  moduleOp.walk([&](func::FuncOp funcOp) {
-    funcResultToEdgesMap[funcOp] =
-        SmallVector<AxisToEdgesMap>(funcOp.getNumResults());
-  });
-}
-
 OriginSharding lookUpValueOriginSharding(
     Value value, AxisRefAttr axisRef,
     const ValueToOriginShardingMap& valueToOriginShardingMap) {
   // NOTE: need to call `getShardableValue` in case the operand/result is
   // part of a `ShardableDataFlowOpInterface` and the `Value` the sharding
-  // lives on is a `DataFlowEdgeOp` instead of the `edge` itself.
+  // lives on is a `DataFlowEdgeOp` instead of the `edgeSource` itself.
   const AxisToOriginShardingMap& axisToOriginSharding =
       valueToOriginShardingMap.at(getShardableValue(value));
   if (auto it = axisToOriginSharding.find(axisRef);
@@ -674,9 +524,9 @@ OriginSharding lookUpValueOriginSharding(
 }  // namespace
 
 ShardingDebugMappings::ShardingDebugMappings(bool debugShardingOrigins,
-                                             bool debugPropagationEdgeSharding)
+                                             bool debugEdgeSourceSharding)
     : debugShardingOrigins(debugShardingOrigins),
-      debugPropagationEdgeSharding(debugPropagationEdgeSharding) {}
+      debugEdgeSourceSharding(debugEdgeSourceSharding) {}
 
 SourceShardingHandler::SourceShardingHandler(ShardingDebugMappings* mappings)
     : mappings(mappings) {}
@@ -691,148 +541,68 @@ void SourceShardingHandler::operator()(function_ref<void()> transform,
   }
 
   auto sourceShardingAction = cast<SourceShardingAction>(action);
-  if (!sourceShardingAction.anyUpdated) {
-    return;
-  }
-  FactorsToEdgeMap factorsToEdges =
-      createSourceMap(sourceShardingAction.oldShardingProjection,
-                      sourceShardingAction.newShardingProjection,
-                      sourceShardingAction.shardingRule,
-                      sourceShardingAction.mesh, propagationStep);
-  propagationStep++;
+  FactorsToEdgeSourceMap factorsToEdgeSources = createSourceMap(
+      sourceShardingAction.oldShardingProjection,
+      sourceShardingAction.newShardingProjection,
+      sourceShardingAction.shardingRule, sourceShardingAction.mesh);
   // If the new and old shardings are different, something was propagated to it.
   // Find and save it.
-  auto lookUpOriginSharding = [&](EdgeNode edgeNode,
+  auto lookUpOriginSharding = [&](EdgeSource edgeSource,
                                   AxisRefAttr axisRef) -> OriginSharding {
-    switch (edgeNode.type) {
+    switch (edgeSource.type) {
       case OPERAND:
         return lookUpValueOriginSharding(
-            sourceShardingAction.operands[edgeNode.index], axisRef,
+            sourceShardingAction.operands[edgeSource.index], axisRef,
             mappings->valueToOriginShardingMap);
       case RESULT:
         return lookUpValueOriginSharding(
-            sourceShardingAction.results[edgeNode.index], axisRef,
+            sourceShardingAction.results[edgeSource.index], axisRef,
             mappings->valueToOriginShardingMap);
     }
-    llvm_unreachable("unknown EdgeNode");
+    llvm_unreachable("unknown EdgeSource");
   };
 
-  auto updateMappings = [&](int64_t i, AxisRefAttr axisRef,
-                            PropagationEdge edge, Value value) {
-    if (mappings->debugPropagationEdgeSharding) {
-      if (auto funcOp = dyn_cast<func::FuncOp>(sourceShardingAction.op)) {
-        mappings->funcResultToEdgesMap[funcOp][i][axisRef].push_back(edge);
-      } else {
-        mappings->operationToEdgesMap[sourceShardingAction.op][axisRef]
-            .push_back(edge);
+  auto updateMappings = [&](ShardingDebugMappings* mappings,
+                            AxisToEdgeSourceMap axisToEdgeSource, Value value) {
+    for (auto [axisRef, edgeSource] : axisToEdgeSource) {
+      if (mappings->debugEdgeSourceSharding) {
+        mappings->valueToEdgeSourceMap[value].try_emplace(axisRef, edgeSource);
+      }
+      if (mappings->debugShardingOrigins) {
+        mappings->valueToOriginShardingMap[value].try_emplace(
+            axisRef, lookUpOriginSharding(edgeSource, axisRef));
       }
-    }
-    if (mappings->debugShardingOrigins) {
-      mappings->valueToOriginShardingMap[value].try_emplace(
-          axisRef, lookUpOriginSharding(edge.source, axisRef));
     }
   };
-
-  for (auto [i, operand] : llvm::enumerate(sourceShardingAction.operands)) {
-    for (auto [axisRef, edge] : factorsToEdges.operands[i]) {
-      updateMappings(i, axisRef, edge, operand);
-    }
+  for (auto [operand, axisToEdgeSource] : llvm::zip_equal(
+           sourceShardingAction.operands, factorsToEdgeSources.operands)) {
+    updateMappings(mappings, axisToEdgeSource, operand);
   }
-
-  for (auto [i, result] : llvm::enumerate(sourceShardingAction.results)) {
-    for (auto [axisRef, edge] : factorsToEdges.results[i]) {
-      updateMappings(i, axisRef, edge, result);
-    }
+  for (auto [result, axisToEdgeSource] : llvm::zip_equal(
+           sourceShardingAction.results, factorsToEdgeSources.results)) {
+    updateMappings(mappings, axisToEdgeSource, result);
   }
 }
 
 void SourceShardingHandler::prepareHandler(ModuleOp moduleOp) {
   if (mappings->debugShardingOrigins) {
-    prepareShardingOriginsHandler(moduleOp, mappings->valueToOriginShardingMap);
+    prepareShardingOriginsHandler(moduleOp, mappings);
   }
-  if (mappings->debugPropagationEdgeSharding) {
-    prepareFuncResultToEdgesHandler(moduleOp, mappings->funcResultToEdgesMap);
+  if (mappings->debugEdgeSourceSharding) {
+    llvm_unreachable("edge sharding not implemented yet");
   }
-  if (mappings->debugShardingOrigins ||
-      mappings->debugPropagationEdgeSharding) {
+  if (mappings->debugShardingOrigins || mappings->debugEdgeSourceSharding) {
     moduleOp->getContext()->registerActionHandler(*this);
   }
 }
 
 void SourceShardingHandler::saveOnModule(ModuleOp moduleOp) {
-  MLIRContext* context = moduleOp.getContext();
   if (mappings->debugShardingOrigins) {
-    saveShardingOriginsOnModule(context, mappings->valueToOriginShardingMap);
+    saveShardingOriginsOnModule(moduleOp, mappings);
     overrideOriginsToSelf(moduleOp);
   }
-  if (mappings->debugPropagationEdgeSharding) {
-    saveEdgesOnModule(context, mappings->operationToEdgesMap);
-    moduleOp.walk([&](func::FuncOp funcOp) {
-      saveEdgesOnFuncResults(funcOp, mappings->funcResultToEdgesMap);
-    });
-  }
-}
-
-namespace {
-
-// Looks for the debug info dictionary on the `dataFlowEdgeOp` called
-// `debugAttrName` and pushes it back to the `debugInfoDict`. If the dictionary
-// doesn't exist, pushes an empty dictionary.
-void pushBackToDebugInfoDict(DataFlowEdgeOp dataFlowEdgeOp,
-                             StringRef debugAttrName,
-                             SmallVector<Attribute>& debugInfoDict,
-                             IRRewriter& rewriter) {
-  assert(dataFlowEdgeOp);
-  if (auto edgeDebugInfo =
-          dataFlowEdgeOp->getAttrOfType<DictionaryAttr>(debugAttrName)) {
-    debugInfoDict.push_back(edgeDebugInfo);
-  } else {
-    debugInfoDict.push_back(rewriter.getDictionaryAttr({}));
-  }
-}
-
-}  // namespace
-
-void saveDebugInfoDictsFromDataFlowEdges(ValueRange edgeOwners, Operation* op,
-                                         bool sinkDebugShardingOrigins,
-                                         bool sinkDebugPropagationEdgeSharding,
-                                         EdgeNodeType edgeNodeType,
-                                         IRRewriter& rewriter) {
-  if (!sinkDebugShardingOrigins && !sinkDebugPropagationEdgeSharding) {
-    return;
-  }
-  SmallVector<Attribute> originShardingDicts;
-  if (sinkDebugShardingOrigins) {
-    originShardingDicts.reserve(edgeOwners.size());
-  }
-  SmallVector<Attribute> propagationEdgeDicts;
-  if (sinkDebugPropagationEdgeSharding) {
-    propagationEdgeDicts.reserve(edgeOwners.size());
-  }
-  for (Value edgeOwner : edgeOwners) {
-    if (auto dataFlowEdgeOp = DataFlowEdgeOp::lookup(edgeOwner)) {
-      if (sinkDebugShardingOrigins) {
-        pushBackToDebugInfoDict(dataFlowEdgeOp, kShardingOriginsAttr,
-                                originShardingDicts, rewriter);
-      }
-      if (sinkDebugPropagationEdgeSharding) {
-        pushBackToDebugInfoDict(dataFlowEdgeOp, kPropagationEdgesAttr,
-                                propagationEdgeDicts, rewriter);
-      }
-    }
-  }
-
-  if (sinkDebugShardingOrigins) {
-    op->setAttr(edgeNodeType == EdgeNodeType::OPERAND
-                    ? kBlockArgShardingOriginsAttr
-                    : kResultShardingOriginsAttr,
-                rewriter.getArrayAttr(originShardingDicts));
-  }
-  if (sinkDebugPropagationEdgeSharding) {
-    op->setAttr(edgeNodeType == EdgeNodeType::OPERAND
-                    ? kBlockArgPropagationEdgesAttr
-                    : kResultPropagationEdgesAttr,
-                rewriter.getArrayAttr(propagationEdgeDicts));
+  if (mappings->debugEdgeSourceSharding) {
+    llvm_unreachable("edge sharding not implemented yet");
   }
 }
 
diff --git a/shardy/dialect/sdy/transforms/propagation/debugging/source_sharding.h b/shardy/dialect/sdy/transforms/propagation/debugging/source_sharding.h
index 991194c..b21207d 100644
--- a/shardy/dialect/sdy/transforms/propagation/debugging/source_sharding.h
+++ b/shardy/dialect/sdy/transforms/propagation/debugging/source_sharding.h
@@ -20,12 +20,9 @@ limitations under the License.
 
 #include "llvm/ADT/DenseMap.h"
 #include "llvm/ADT/SmallVector.h"
-#include "mlir/Dialect/Func/IR/FuncOps.h"
 #include "mlir/IR/Action.h"
 #include "mlir/IR/BuiltinOps.h"
 #include "mlir/IR/MLIRContext.h"
-#include "mlir/IR/Operation.h"
-#include "mlir/IR/PatternMatch.h"
 #include "mlir/IR/Unit.h"
 #include "mlir/IR/Value.h"
 #include "mlir/IR/ValueRange.h"
@@ -56,39 +53,24 @@ struct OriginSharding {
 };
 
 // Specifies whether a sharding came from an operand or a result.
-enum EdgeNodeType { OPERAND, RESULT };
+enum EdgeSourceType { OPERAND, RESULT };
 
 // The operand/result a sharding came from through an `Operation` to modify the
 // sharding of some `Value` in the `Operation`.
-struct EdgeNode {
-  EdgeNodeType type;
+struct EdgeSource {
+  EdgeSourceType type;
   int64_t index;
 };
 
-// The source and target of a source sharding edge.
-struct PropagationEdge {
-  EdgeNode source;
-  EdgeNode target;
-  int64_t propagationStep;
-};
-
-// Types used for `debugPropagationEdgeSharding`.
-using AxisToEdgeMap = llvm::DenseMap<AxisRefAttr, PropagationEdge>;
-using AxisToEdgesMap =
-    llvm::DenseMap<AxisRefAttr, SmallVector<PropagationEdge>>;
-using OperationToEdgesMap = llvm::DenseMap<Operation*, AxisToEdgesMap>;
-// Mapping from `FuncOp` to the edges for each result.
-using FuncResultToEdgesMap =
-    llvm::DenseMap<func::FuncOp, SmallVector<AxisToEdgesMap>>;
-
-// Types used for `debugShardingOrigins`.
+using AxisToEdgeSourceMap = llvm::DenseMap<AxisRefAttr, EdgeSource>;
 using AxisToOriginShardingMap = llvm::DenseMap<AxisRefAttr, OriginSharding>;
+using ValueToEdgeSourceMap = llvm::DenseMap<Value, AxisToEdgeSourceMap>;
 using ValueToOriginShardingMap = llvm::DenseMap<Value, AxisToOriginShardingMap>;
 
 // The mappings used for debugging sharding origins and edge sources.
 struct ShardingDebugMappings {
   ShardingDebugMappings(bool debugShardingOrigins,
-                        bool debugPropagationEdgeSharding);
+                        bool debugEdgeSourceSharding);
 
   // We do not allow copying of the mappings, as we don't want the mappings
   // to be copied over to the new instance. There should only ever be one
@@ -96,13 +78,8 @@ struct ShardingDebugMappings {
   ShardingDebugMappings(const ShardingDebugMappings&) = delete;
   ShardingDebugMappings& operator=(const ShardingDebugMappings&) = delete;
 
-  bool debugShardingOrigins, debugPropagationEdgeSharding;
-  OperationToEdgesMap operationToEdgesMap;
-  // NOTE: we need a separate map for `FuncOp` results as propagation is run
-  // per terminator operand/result pair, so we need to figure out which index
-  // the `FuncOp` result is. So this saves the edges for each `FuncOp` result
-  // separately.
-  FuncResultToEdgesMap funcResultToEdgesMap;
+  bool debugShardingOrigins, debugEdgeSourceSharding;
+  ValueToEdgeSourceMap valueToEdgeSourceMap;
   ValueToOriginShardingMap valueToOriginShardingMap;
 };
 
@@ -114,20 +91,17 @@ class SourceShardingAction : public tracing::ActionImpl<SourceShardingAction> {
  public:
   using Base = tracing::ActionImpl<SourceShardingAction>;
 
-  SourceShardingAction(ArrayRef<IRUnit> irUnits, Operation* op,
-                       ValueRange operands, ValueRange results, MeshAttr mesh,
+  SourceShardingAction(ArrayRef<IRUnit> irUnits, ValueRange operands,
+                       ValueRange results, MeshAttr mesh,
                        OpShardingRuleAttr shardingRule,
-                       const ShardingProjection& shardingProjection,
-                       const bool& anyUpdated)
+                       const ShardingProjection& shardingProjection)
       : Base(irUnits),
-        op(op),
         operands(operands),
         results(results),
         mesh(mesh),
         shardingRule(shardingRule),
         oldShardingProjection(shardingProjection),
-        newShardingProjection(shardingProjection),
-        anyUpdated(anyUpdated) {}
+        newShardingProjection(shardingProjection) {}
 
   static constexpr StringLiteral tag = "SourceShardingAction";
   static constexpr StringLiteral desc =
@@ -135,7 +109,6 @@ class SourceShardingAction : public tracing::ActionImpl<SourceShardingAction> {
       "a user defined sharding either on `FuncOp` inputs/outputs, an "
       "`sdy.sharding_constraint`, or `sdy.ManualComputationOp` input/output.";
 
-  Operation* op;
   ValueRange operands, results;
   MeshAttr mesh;
   OpShardingRuleAttr shardingRule;
@@ -144,14 +117,12 @@ class SourceShardingAction : public tracing::ActionImpl<SourceShardingAction> {
   // new sharding projections differ.
   const ShardingProjection oldShardingProjection;
   const ShardingProjection& newShardingProjection;
-  // Whether any of the operands/results were updated.
-  const bool& anyUpdated;
 };
 
 // Handles `SourceShardingAction`s, figuring out what operand/result shardings
 // have been propagated through due to new axes. Saves what was the source of
 // the axis to appear on the sharding of a given `Value` to
-// `operationToEdgesMap`/`funcResultToEdgesMap` and `valueToOriginShardingMap`.
+// `valueToEdgeSourceMap` and `valueToOriginShardingMap`.
 struct SourceShardingHandler {
   SourceShardingHandler(ShardingDebugMappings* mappings);
 
@@ -169,27 +140,8 @@ struct SourceShardingHandler {
 
  private:
   ShardingDebugMappings* mappings;
-  int64_t propagationStep = 0;
 };
 
-// Saves an array of all the origin sharding and propagation edge dictionaries
-// for the given `edgeOwners` on `op`. If non exist, nothing is saved.
-//
-// Saving the info depends on if the corresponding `sinkDebugShardingOrigins`
-// and `sinkDebugPropagationEdgeSharding` are true.
-//
-// For debugging the origin shardings and propagation edges, we want to preserve
-// the debugging dictionaries from the `DataFlowEdgeOp`s on the owning op so
-// that they are preserved after the propagation pipeline.
-//
-// See the `debug-sharding-origins` and `debug-edge-source-sharding` config on
-// propagation for more details.
-void saveDebugInfoDictsFromDataFlowEdges(ValueRange edgeOwners, Operation* op,
-                                         bool sinkDebugShardingOrigins,
-                                         bool sinkDebugPropagationEdgeSharding,
-                                         EdgeNodeType edgeNodeType,
-                                         IRRewriter& rewriter);
-
 }  // namespace sdy
 }  // namespace mlir
 
diff --git a/shardy/dialect/sdy/transforms/propagation/debugging/test/edge_shardings.mlir b/shardy/dialect/sdy/transforms/propagation/debugging/test/edge_shardings.mlir
deleted file mode 100644
index 9a27a63..0000000
--- a/shardy/dialect/sdy/transforms/propagation/debugging/test/edge_shardings.mlir
+++ /dev/null
@@ -1,233 +0,0 @@
-// RUN: sdy_opt %s -split-input-file -sdy-add-data-flow-edges -sdy-aggressive-propagate=debug-propagation-edge-sharding=true -sdy-sink-data-flow-edges="sink-debug-propagation-edge-sharding=true" 2>&1 | FileCheck %s
-
-
-sdy.mesh @mesh = <["a"=2, "b"=2, "c"=8]>
-
-// CHECK-LABEL: input_output_source_sharding
-// CHECK-SAME:    %arg0: tensor<8x8x8xf32> {sdy.sharding = #sdy.sharding<@mesh, [{"a", ?}, {"b", ?}, {"c", ?}]>},
-// CHECK-SAME:    %arg1: tensor<8x8x8xf32> {sdy.sharding = #sdy.sharding<@mesh, [{"a", ?}, {"b", ?}, {"c", ?}]>}
-// CHECK-SAME:  ) -> (tensor<8x8x8xf32> {sdy.propagation_edges = {a = [{propagation_step = 2 : i64, source = "operand: 0", target = "result: 0"}],
-// CHECK-SAME:                                                    b = [{propagation_step = 0 : i64, source = "result: 0", target = "operand: 0"}],
-// CHECK-SAME:                                                    c = [{propagation_step = 2 : i64, source = "operand: 0", target = "result: 0"}]},
-// CHECK-SAME:                           sdy.sharding = #sdy.sharding<@mesh, [{"a", ?}, {"b", ?}, {"c", ?}]>}) {
-func.func @input_output_source_sharding(
-  %arg0: tensor<8x8x8xf32> {sdy.sharding = #sdy.sharding<@mesh, [{"a", ?}, {?}, {?}]>},
-  %arg1: tensor<8x8x8xf32> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {?}, {"c", ?}]>}
-) -> (tensor<8x8x8xf32> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {"b", ?}, {?}]>}) {
-  // CHECK-NEXT:  %[[ADD:.*]] = stablehlo.add %arg0, %arg1 {
-  // CHECK-SAME:    sdy.propagation_edges = {a = [{propagation_step = 1 : i64, source = "operand: 0", target = "operand: 1"},
-  // CHECK-SAME:                                  {propagation_step = 1 : i64, source = "operand: 0", target = "result: 0"}],
-  // CHECK-SAME:                             b = [{propagation_step = 1 : i64, source = "result: 0", target = "operand: 0"},
-  // CHECK-SAME:                                  {propagation_step = 1 : i64, source = "result: 0", target = "operand: 1"}],
-  // CHECK-SAME:                             c = [{propagation_step = 1 : i64, source = "operand: 1", target = "operand: 0"},
-  // CHECK-SAME:                                  {propagation_step = 1 : i64, source = "operand: 1", target = "result: 0"}]},
-  // CHECK-SAME:    sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"a", ?}, {"b", ?}, {"c", ?}]>]>
-  // CHECK-SAME:  } : tensor<8x8x8xf32>
-  // CHECK-NEXT:  return %[[ADD]] : tensor<8x8x8xf32>
-  %0 = stablehlo.add %arg0, %arg1 : tensor<8x8x8xf32>
-  return %0 : tensor<8x8x8xf32>
-}
-
-// -----
-
-sdy.mesh @mesh = <["a"=2]>
-
-// NOTE: Instead of saving `{source = "result: 0", target = "operand: 0"}` and
-// `{source = "result: 0", target = "operand: 1"}` on the add due to the same
-// value being used twice as an operand, we only save the edge once.
-//
-// CHECK-LABEL: duplicate_operands
-// CHECK-SAME:    %arg0: tensor<8xf32> {sdy.sharding = #sdy.sharding<@mesh, [{"a", ?}]>}
-// CHECK-SAME:  ) -> (tensor<8xf32> {sdy.propagation_edges = {a = [{propagation_step = 0 : i64, source = "result: 0", target = "operand: 0"}]},
-// CHECK-SAME:                       sdy.sharding = #sdy.sharding<@mesh, [{"a", ?}]>}) {
-func.func @duplicate_operands(
-  %arg0: tensor<8xf32>
-) -> (tensor<8xf32> {sdy.sharding = #sdy.sharding<@mesh, [{"a", ?}]>}) {
-  // CHECK-NEXT:  %[[ADD:.*]] = stablehlo.add %arg0, %arg0 {
-  // CHECK-SAME:    sdy.propagation_edges = {a = [{propagation_step = 1 : i64, source = "result: 0", target = "operand: 0"}]},
-  // CHECK-SAME:    sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"a", ?}]>]>
-  // CHECK-SAME:  } : tensor<8xf32>
-  // CHECK-NEXT:  return %[[ADD]] : tensor<8xf32>
-  %0 = stablehlo.add %arg0, %arg0 : tensor<8xf32>
-  return %0 : tensor<8xf32>
-}
-
-// -----
-
-sdy.mesh @mesh = <["a"=2, "b"=2]>
-
-// NOTE: since the definition of an edge always contains an operand as a source
-// or target, even though the result sharding added `a` before the arg sharding,
-// then the edge where axis `a` was added to the add is stored on the func
-// result sharding.
-//
-// CHECK-LABEL: multiple_axes
-// CHECK-SAME:    %arg0: tensor<8x8xf32> {sdy.sharding = #sdy.sharding<@mesh, [{"a", "b", ?}, {?}]>}
-// CHECK-SAME:  ) -> (tensor<8x8xf32> {sdy.propagation_edges = {a = [{propagation_step = 0 : i64, source = "result: 0", target = "operand: 0"}],
-// CHECK-SAME:                                                  b = [{propagation_step = 2 : i64, source = "operand: 0", target = "result: 0"}]},
-// CHECK-SAME:                         sdy.sharding = #sdy.sharding<@mesh, [{"a", "b", ?}, {?}]>}) {
-func.func @multiple_axes(
-  %arg0: tensor<8x8xf32> {sdy.sharding = #sdy.sharding<@mesh, [{"a", "b", ?}, {?}]>}
-) -> (tensor<8x8xf32> {sdy.sharding = #sdy.sharding<@mesh, [{"a", ?}, {?}]>}) {
-  // CHECK-NEXT: %[[ADD:.*]] = stablehlo.add %arg0, %arg0 {
-  // CHECK-SAME:   sdy.propagation_edges = {b = [{propagation_step = 1 : i64, source = "operand: 0", target = "result: 0"}]},
-  // CHECK-SAME:   sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"a", "b", ?}, {?}]>]>
-  // CHECK-SAME: } : tensor<8x8xf32>
-  // CHECK-NEXT: return %[[ADD]] : tensor<8x8xf32>
-  %0 = stablehlo.add %arg0, %arg0 : tensor<8x8xf32>
-  return %0 : tensor<8x8xf32>
-}
-
-// -----
-
-sdy.mesh @mesh = <["c"=8]>
-
-// NOTE(b/385908435): note how we save the smaller and larger sub axes on the
-// func result sharding. Maybe this behavior is good, or should change? To be
-// seen.
-//
-// CHECK-LABEL: sub_axis_update
-// CHECK-SAME:    %arg0: tensor<8x8xf32> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {"c":(1)4, ?}]>}
-// CHECK-SAME:  ) -> (tensor<8x8xf32> {sdy.propagation_edges = {"c:(1)2" = [{propagation_step = 0 : i64, source = "result: 0", target = "operand: 0"}],
-// CHECK-SAME:                                                  "c:(1)4" = [{propagation_step = 2 : i64, source = "operand: 0", target = "result: 0"}]},
-// CHECK-SAME:                         sdy.sharding = #sdy.sharding<@mesh, [{?}, {"c":(1)4, ?}]>}) {
-func.func @sub_axis_update(
-  %arg0: tensor<8x8xf32> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {"c":(1)4, ?}]>}
-) -> (tensor<8x8xf32> {sdy.sharding = #sdy.sharding<@mesh, [{?}, {"c":(1)2, ?}]>}) {
-  // CHECK-NEXT: %[[ADD:.*]] = stablehlo.add %arg0, %arg0 {
-  // CHECK-SAME:   sdy.propagation_edges = {"c:(1)4" = [{propagation_step = 1 : i64, source = "operand: 0", target = "result: 0"}]},
-  // CHECK-SAME:   sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"c":(1)4, ?}]>]>
-  // CHECK-SAME: } : tensor<8x8xf32>
-  // CHECK-NEXT: return %[[ADD]] : tensor<8x8xf32>
-  %1 = stablehlo.add %arg0, %arg0 : tensor<8x8xf32>
-  return %1 : tensor<8x8xf32>
-}
-
-// -----
-
-sdy.mesh @mesh = <["a"=2, "b"=2]>
-
-// CHECK-LABEL: manual_computation_manual_axes
-// CHECK-SAME:    %arg0: tensor<32x32x32xf32> {sdy.sharding = #sdy.sharding<@mesh, [{"a", ?}, {"b", ?}, {?}]>}
-// CHECK-SAME:    -> (tensor<32x32x32xf32> {sdy.propagation_edges = {a = [{propagation_step = 5 : i64, source = "operand: 0", target = "result: 0"}],
-// CHECK-SAME:                                                       b = [{propagation_step = 5 : i64, source = "operand: 0", target = "result: 0"}]},
-// CHECK-SAME:                              sdy.sharding = #sdy.sharding<@mesh, [{"a", ?}, {"b", ?}, {?}]>}) {
-func.func @manual_computation_manual_axes(%arg0: tensor<32x32x32xf32>) -> tensor<32x32x32xf32> {
-  // CHECK-NEXT: %[[SUB:.*]] = stablehlo.subtract %arg0, %arg0 {
-  // CHECK-SAME:   sdy.propagation_edges = {a = [{propagation_step = 1 : i64, source = "result: 0", target = "operand: 0"}],
-  // CHECK-SAME:                            b = [{propagation_step = 1 : i64, source = "result: 0", target = "operand: 0"}]},
-  // CHECK-SAME:   sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"a", ?}, {"b", ?}, {?}]>]>
-  // CHECK-SAME: } : tensor<32x32x32xf32>
-  // CHECK-NEXT: %[[MC:.*]] = sdy.manual_computation(%[[SUB]])
-  // CHECK-SAME:   in_shardings=[<@mesh, [{"a", ?}, {"b", ?}, {?}]>]
-  // CHECK-SAME:   out_shardings=[<@mesh, [{"a", ?}, {"b", ?}, {?}]>]
-  // CHECK-SAME:   manual_axes={"a"} (%arg1: tensor<16x32x32xf32>) {
-  // CHECK-NEXT:   %[[ADD:.*]] = stablehlo.add %arg1, %arg1 {
-  // CHECK-SAME:     sdy.propagation_edges = {b = [{propagation_step = 2 : i64, source = "operand: 0", target = "result: 0"}]},
-  // CHECK-SAME:     sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"b", ?}, {?}]>]>}
-  // CHECK-NEXT:   sdy.return %[[ADD]]
-  // CHECK-NEXT: } {
-  // CHECK-SAME:   sdy.block_arg_propagation_edges = [{
-  // CHECK-SAME:     a = [{propagation_step = 0 : i64, source = "result: 0", target = "operand: 0"}],
-  // CHECK-SAME:     b = [{propagation_step = 0 : i64, source = "result: 0", target = "operand: 0"}]}],
-  // CHECK-SAME:   sdy.result_propagation_edges = [{
-  // CHECK-SAME:     b = [{propagation_step = 3 : i64, source = "operand: 0", target = "result: 0"}]}]
-  // CHECK-SAME: } : (tensor<32x32x32xf32>) -> tensor<32x32x32xf32>
-  // CHECK-NEXT: %[[SUB_2:.*]] = stablehlo.subtract %[[MC]], %[[MC]] {
-  // CHECK-SAME:   sdy.propagation_edges = {a = [{propagation_step = 4 : i64, source = "operand: 0", target = "result: 0"}],
-  // CHECK-SAME:                            b = [{propagation_step = 4 : i64, source = "operand: 0", target = "result: 0"}]},
-  // CHECK-SAME:   sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"a", ?}, {"b", ?}, {?}]>]>
-  // CHECK-SAME: } : tensor<32x32x32xf32>
-  // CHECK-NEXT: return %[[SUB_2]]
-  %0 = stablehlo.subtract %arg0, %arg0 : tensor<32x32x32xf32>
-  %1 = sdy.manual_computation(%0) in_shardings=[<@mesh, [{"a", ?}, {"b", ?}, {?}]>] out_shardings=[<@mesh, [{"a", ?}, {?}, {?}]>] manual_axes={"a"} (%arg1: tensor<16x32x32xf32>) {
-    %3 = stablehlo.add %arg1, %arg1 : tensor<16x32x32xf32>
-    sdy.return %3 : tensor<16x32x32xf32>
-  } : (tensor<32x32x32xf32>) -> tensor<32x32x32xf32>
-  %2 = stablehlo.subtract %1, %1 : tensor<32x32x32xf32>
-  return %2: tensor<32x32x32xf32>
-}
-
-// -----
-
-sdy.mesh @mesh = <["a"=2, "b"=2]>
-
-// TODO(b/391840483): If the function has multiple results, then each
-// `edge_source` on the func result attributes will have index 0. This is
-// because of how propagation works with running propagation on each returned
-// result. Reconsider this behavior.
-//
-// CHECK-LABEL: manual_computation_multiple_results
-// CHECK-SAME:    %arg0: tensor<32x32xf32> {sdy.sharding = #sdy.sharding<@mesh, [{"b", ?}, {"a", ?}]>})
-// CHECK-SAME:    -> (tensor<16x32xf32> {sdy.propagation_edges = {a = [{propagation_step = 0 : i64, source = "operand: 0", target = "result: 0"},
-// CHECK-SAME:                                                         {propagation_step = 6 : i64, source = "operand: 0", target = "result: 0"}],
-// CHECK-SAME:                                                    b = [{propagation_step = 0 : i64, source = "operand: 0", target = "result: 0"}]},
-// CHECK-SAME:                           sdy.sharding = #sdy.sharding<@mesh, [{?}, {"a", ?}]>},
-// CHECK-SAME:        tensor<32x32xf32> {sdy.propagation_edges = {},
-// CHECK-SAME:                           sdy.sharding = #sdy.sharding<@mesh, [{"b", ?}, {"a", ?}]>}) {
-func.func @manual_computation_multiple_results(%arg0: tensor<32x32xf32>) -> (tensor<16x32xf32>, tensor<32x32xf32>) {
-  // CHECK-NEXT: %[[MC:.*]]:2 = sdy.manual_computation(%arg0) in_shardings=[<@mesh, [{"b", ?}, {"a", ?}]>] out_shardings=[<@mesh, [{?}, {"a", ?}], replicated={"b"}>, <@mesh, [{"b", ?}, {"a", ?}]>] manual_axes={"b"} (%arg1: tensor<16x32xf32>) {
-  // CHECK-NEXT:   %[[ADD:.*]] = stablehlo.add %arg1, %arg1 {
-  // CHECK-SAME:     sdy.propagation_edges = {a = [{propagation_step = 4 : i64, source = "result: 0", target = "operand: 0"}]},
-  // CHECK-SAME:     sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{?}, {"a", ?}]>]>
-  // CHECK-SAME:   } : tensor<16x32xf32>
-  // CHECK-NEXT:   sdy.return %[[ADD]], %[[ADD]] : tensor<16x32xf32>, tensor<16x32xf32>
-  // CHECK-NEXT: } {
-  // CHECK-SAME:   sdy.block_arg_propagation_edges = [{
-  // CHECK-SAME:     a = [{propagation_step = 5 : i64, source = "result: 0", target = "operand: 0"}],
-  // CHECK-SAME:     b = [{propagation_step = 1 : i64, source = "result: 0", target = "operand: 0"}]}],
-  // CHECK-SAME:   sdy.result_propagation_edges = [
-  // CHECK-SAME:     {a = [{propagation_step = 3 : i64, source = "operand: 0", target = "result: 0"}]},
-  // CHECK-SAME:     {a = [{propagation_step = 2 : i64, source = "result: 0", target = "operand: 0"}]}]
-  // CHECK-SAME: } : (tensor<32x32xf32>) -> (tensor<16x32xf32>, tensor<32x32xf32>)
-  // CHECK-NEXT: return %[[MC]]#0, %[[MC]]#1 : tensor<16x32xf32>, tensor<32x32xf32>
-  %0:2 = sdy.manual_computation(%arg0) in_shardings=[<@mesh, [{"b", ?}, {?}]>] out_shardings=[<@mesh, [{?}, {?}], replicated={"b"}>, <@mesh, [{"b", ?}, {"a", ?}]>] manual_axes={"b"} (%arg1: tensor<16x32xf32>) {
-    %1 = stablehlo.add %arg1, %arg1 : tensor<16x32xf32>
-    sdy.return %1, %1 : tensor<16x32xf32>, tensor<16x32xf32>
-  } : (tensor<32x32xf32>) -> (tensor<16x32xf32>, tensor<32x32xf32>)
-  return %0#0, %0#1 : tensor<16x32xf32>, tensor<32x32xf32>
-}
-
-// -----
-
-sdy.mesh @mesh = <["c"=8]>
-
-// CHECK-LABEL: sub_axes_splitting_reshape
-// CHECK-SAME:    %arg0: tensor<16xf32> {sdy.sharding = #sdy.sharding<@mesh, [{"c", ?}]>}
-// CHECK-SAME:  ) -> (tensor<4x4xf32> {sdy.propagation_edges = {"c:(1)4" = [{propagation_step = 1 : i64, source = "operand: 0", target = "result: 0"}],
-// CHECK-SAME:                                                  "c:(4)2" = [{propagation_step = 1 : i64, source = "operand: 0", target = "result: 0"}]},
-// CHECK-SAME:                         sdy.sharding = #sdy.sharding<@mesh, [{"c":(1)4, ?}, {"c":(4)2, ?}]>}) {
-func.func @sub_axes_splitting_reshape(
-  %arg0: tensor<16xf32> {sdy.sharding = #sdy.sharding<@mesh, [{"c", ?}]>}
-) -> tensor<4x4xf32> {
-  // CHECK-NEXT: %[[RESHAPE:.*]] = stablehlo.reshape %arg0 {
-  // CHECK-SAME:   sdy.propagation_edges = {"c:(1)4" = [{propagation_step = 0 : i64, source = "operand: 0", target = "result: 0"}],
-  // CHECK-SAME:                         "c:(4)2" = [{propagation_step = 0 : i64, source = "operand: 0", target = "result: 0"}]},
-  // CHECK-SAME:   sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"c":(1)4, ?}, {"c":(4)2, ?}]>]>
-  // CHECK-SAME: } : (tensor<16xf32>) -> tensor<4x4xf32>
-  // CHECK-NEXT: return %[[RESHAPE]]
-  %0 = stablehlo.reshape %arg0 : (tensor<16xf32>) -> tensor<4x4xf32>
-  return %0 : tensor<4x4xf32>
-}
-
-// -----
-
-sdy.mesh @mesh = <["c"=8]>
-
-// NOTE: since the reshape combines the two sub axes into one, we only save the
-// merged axis on the reshape as an edge between the operand and result.
-//
-// CHECK-LABEL: sub_axes_merging_reshape
-// CHECK-SAME:    %arg0: tensor<4x4xf32> {sdy.sharding = #sdy.sharding<@mesh, [{"c":(1)4, ?}, {"c":(4)2, ?}]>}
-// CHECK-SAME:  ) -> (tensor<16xf32> {sdy.propagation_edges = {c = [{propagation_step = 1 : i64, source = "operand: 0", target = "result: 0"}]},
-// CHECK-SAME:                        sdy.sharding = #sdy.sharding<@mesh, [{"c", ?}]>}) {
-func.func @sub_axes_merging_reshape(
-  %arg0: tensor<4x4xf32> {sdy.sharding = #sdy.sharding<@mesh, [{"c":(1)4, ?}, {"c":(4)2, ?}]>})
-  -> tensor<16xf32> {
-  // CHECK-NEXT: stablehlo.reshape %arg0 {
-  // CHECK-SAME:   sdy.propagation_edges = {c = [{propagation_step = 0 : i64, source = "operand: 0", target = "result: 0"}]},
-  // CHECK-SAME:   sdy.sharding = #sdy.sharding_per_value<[<@mesh, [{"c", ?}]>]>
-  // CHECK-SAME: } : (tensor<4x4xf32>) -> tensor<16xf32>
-  %0 = stablehlo.reshape %arg0 : (tensor<4x4xf32>) -> tensor<16xf32>
-  return %0 : tensor<16xf32>
-}
diff --git a/shardy/dialect/sdy/transforms/propagation/debugging/test/sharding_origins.mlir b/shardy/dialect/sdy/transforms/propagation/debugging/test/sharding_origins.mlir
index 9935aed..89cc0dc 100644
--- a/shardy/dialect/sdy/transforms/propagation/debugging/test/sharding_origins.mlir
+++ b/shardy/dialect/sdy/transforms/propagation/debugging/test/sharding_origins.mlir
@@ -1,4 +1,4 @@
-// RUN: sdy_opt %s -sdy-add-data-flow-edges -sdy-aggressive-propagate=debug-sharding-origins=true -sdy-sink-data-flow-edges="sink-debug-sharding-origins=true" 2>&1 | FileCheck %s
+// RUN: sdy_opt %s -sdy-add-data-flow-edges -sdy-aggressive-propagate="debug-sharding-origins=true" -sdy-sink-data-flow-edges 2>&1 | FileCheck %s
 
 sdy.mesh @mesh = <["a"=2, "b"=2, "c"=8]>
 
diff --git a/shardy/dialect/sdy/transforms/propagation/op_priority_propagation.cc b/shardy/dialect/sdy/transforms/propagation/op_priority_propagation.cc
index c468b55..4528ac5 100644
--- a/shardy/dialect/sdy/transforms/propagation/op_priority_propagation.cc
+++ b/shardy/dialect/sdy/transforms/propagation/op_priority_propagation.cc
@@ -46,13 +46,36 @@ namespace sdy {
 namespace {
 
 // A function that determines in which direction propagation should happen for a
-// given op and factor index.
-using GetDirectionToPropagateFnPtr = PropagationDirection (*)(Operation*,
-                                                              int64_t);
+// given op.
+using GetDirectionToPropagateFnPtr = PropagationDirection (*)(Operation*);
 
-PropagationDirection isPassThrough(Operation* op, int64_t) {
+template <typename... OpTs>
+PropagationDirection isaBoth(Operation* op) {
+  return isa<OpTs...>(op) ? PropagationDirection::BOTH
+                          : PropagationDirection::NONE;
+}
+
+template <typename... OpTs>
+PropagationDirection isNotABoth(Operation* op) {
+  return !isa<OpTs...>(op) ? PropagationDirection::BOTH
+                           : PropagationDirection::NONE;
+}
+
+template <typename... OpTs>
+PropagationDirection isaForward(Operation* op) {
+  return isa<OpTs...>(op) ? PropagationDirection::FORWARD
+                          : PropagationDirection::NONE;
+}
+
+template <typename... OpTs>
+PropagationDirection isaBackward(Operation* op) {
+  return isa<OpTs...>(op) ? PropagationDirection::BACKWARD
+                          : PropagationDirection::NONE;
+}
+
+PropagationDirection isPassThrough(Operation* op) {
   if (isElementwise(op) ||
-      isa<stablehlo::ReshapeOp, stablehlo::TransposeOp, DataFlowEdgeOp>(op)) {
+      isa<stablehlo::ReshapeOp, stablehlo::TransposeOp>(op)) {
     return PropagationDirection::BOTH;
   }
   if (isa<stablehlo::DynamicSliceOp, stablehlo::DynamicUpdateSliceOp>(op)) {
@@ -70,19 +93,18 @@ constexpr std::array<GetDirectionToPropagateFnPtr, 2> opPropagationSchedule = {
 // a caller. It will return the intersection of the passed in
 // `getDirectionToPropagate` and the op based direction.
 GetDirectionToPropagateFn getOpBasedDirectionToPropagate(
-    int64_t currentPriority,
+    int64_t currentOpPriority,
     GetDirectionToPropagateFn getDirectionToPropagate) {
-  return [currentPriority, getDirectionToPropagate](Operation* op,
-                                                    int64_t factorIndex) {
+  return [currentOpPriority, getDirectionToPropagate](Operation* op) {
     PropagationDirection opBasedDirection = std::accumulate(
         opPropagationSchedule.begin(),
-        opPropagationSchedule.begin() + currentPriority + 1,
+        opPropagationSchedule.begin() + currentOpPriority + 1,
         PropagationDirection::NONE,
         [&](PropagationDirection acc, GetDirectionToPropagateFnPtr dirFn) {
-          return unionOfPropagationDirections(acc, dirFn(op, factorIndex));
+          return unionOfPropagationDirections(acc, dirFn(op));
         });
-    return intersectionOfPropagationDirections(
-        opBasedDirection, getDirectionToPropagate(op, factorIndex));
+    return intersectionOfPropagationDirections(opBasedDirection,
+                                               getDirectionToPropagate(op));
   };
 }
 
@@ -107,13 +129,13 @@ LogicalResult OpPriorityPropagationPassImpl::propagate(
     return AggressivePropagationPassImpl::propagate(
         moduleOp, symbolTable, shardingGroupMap, getDirectionToPropagate);
   }
-  // Reset currentPriority to 0. Before running the pass. This same instance
+  // Reset currentOpPriority to 0. Before running the pass. This same instance
   // could have been run earlier already (e.g. with a different user priority).
-  for (int64_t currentPriority = 0;
-       currentPriority < opPropagationSchedule.size(); currentPriority++) {
+  for (int64_t currentOpPriority = 0;
+       currentOpPriority < opPropagationSchedule.size(); currentOpPriority++) {
     if (AggressivePropagationPassImpl::propagate(
             moduleOp, symbolTable, shardingGroupMap,
-            getOpBasedDirectionToPropagate(currentPriority,
+            getOpBasedDirectionToPropagate(currentOpPriority,
                                            getDirectionToPropagate))
             .failed()) {
       return failure();
diff --git a/shardy/dialect/sdy/transforms/propagation/passes.h b/shardy/dialect/sdy/transforms/propagation/passes.h
index d56485e..aa75168 100644
--- a/shardy/dialect/sdy/transforms/propagation/passes.h
+++ b/shardy/dialect/sdy/transforms/propagation/passes.h
@@ -46,7 +46,7 @@ struct PropagationOptions {
   // Whether to save debug information about the sharding origins on the module.
   bool debugShardingOrigins = false;
   // Whether to save debug information about the edge shardings on the module.
-  bool debugPropagationEdgeSharding = false;
+  bool debugEdgeSourceSharding = false;
   // Whether to avoid converting `sdy::ShardingConstraintOp` to
   // `sdy::ReshardOp`.
   bool skipConvertToReshard = false;
diff --git a/third_party/llvm/generated.patch b/third_party/llvm/generated.patch
index 509398d..be80184 100644
--- a/third_party/llvm/generated.patch
+++ b/third_party/llvm/generated.patch
@@ -1 +1,132 @@
 Auto generated patch. Do not edit or delete it, even if empty.
+diff -ruN --strip-trailing-cr a/clang/include/clang/Basic/BuiltinsX86.td b/clang/include/clang/Basic/BuiltinsX86.td
+--- a/clang/include/clang/Basic/BuiltinsX86.td
++++ b/clang/include/clang/Basic/BuiltinsX86.td
+@@ -130,10 +130,6 @@
+   }
+ }
+ 
+-let Features = "sse", Header = "xmmintrin.h", Attributes = [NoThrow, Const] in {
+-  def _mm_prefetch : X86LibBuiltin<"void(void const *, int)">;
+-}
+-
+ // AVX
+ let Attributes = [Const, NoThrow, RequiredVectorWidth<256>], Features = "avx" in {
+   foreach Op = ["addsub", "hadd", "hsub", "max", "min"] in {
+@@ -142,12 +138,6 @@
+   }
+ }
+ 
+-// PRFCHW
+-let Features = "prfchw", Header = "intrin.h", Attributes = [NoThrow, Const] in {
+-  def _m_prefetch : X86LibBuiltin<"void(void *)">;
+-  def _m_prefetchw : X86LibBuiltin<"void(void volatile const *)">;
+-}
+-
+ 
+ // Mechanically ported builtins from the original `.def` file.
+ //
+@@ -156,6 +146,10 @@
+ // current formulation is based on what was easiest to recognize from the
+ // pre-TableGen version.
+ 
++let Features = "mmx", Attributes = [NoThrow, Const] in {
++  def _mm_prefetch : X86NoPrefixBuiltin<"void(char const *, int)">;
++}
++
+ let Features = "sse", Attributes = [NoThrow] in {
+   def ldmxcsr : X86Builtin<"void(unsigned int)">;
+ }
+diff -ruN --strip-trailing-cr a/clang/lib/CodeGen/CGBuiltin.cpp b/clang/lib/CodeGen/CGBuiltin.cpp
+--- a/clang/lib/CodeGen/CGBuiltin.cpp
++++ b/clang/lib/CodeGen/CGBuiltin.cpp
+@@ -15374,17 +15374,6 @@
+     Function *F = CGM.getIntrinsic(Intrinsic::prefetch, Address->getType());
+     return Builder.CreateCall(F, {Address, RW, Locality, Data});
+   }
+-  case X86::BI_m_prefetch:
+-  case X86::BI_m_prefetchw: {
+-    Value *Address = Ops[0];
+-    // The 'w' suffix implies write.
+-    Value *RW =
+-        ConstantInt::get(Int32Ty, BuiltinID == X86::BI_m_prefetchw ? 1 : 0);
+-    Value *Locality = ConstantInt::get(Int32Ty, 0x3);
+-    Value *Data = ConstantInt::get(Int32Ty, 1);
+-    Function *F = CGM.getIntrinsic(Intrinsic::prefetch, Address->getType());
+-    return Builder.CreateCall(F, {Address, RW, Locality, Data});
+-  }
+   case X86::BI_mm_clflush: {
+     return Builder.CreateCall(CGM.getIntrinsic(Intrinsic::x86_sse2_clflush),
+                               Ops[0]);
+diff -ruN --strip-trailing-cr a/clang/lib/Headers/prfchwintrin.h b/clang/lib/Headers/prfchwintrin.h
+--- a/clang/lib/Headers/prfchwintrin.h
++++ b/clang/lib/Headers/prfchwintrin.h
+@@ -14,10 +14,6 @@
+ #ifndef __PRFCHWINTRIN_H
+ #define __PRFCHWINTRIN_H
+ 
+-#if defined(__cplusplus)
+-extern "C" {
+-#endif
+-
+ /// Loads a memory sequence containing the specified memory address into
+ ///    all data cache levels.
+ ///
+@@ -30,7 +26,11 @@
+ ///
+ /// \param __P
+ ///    A pointer specifying the memory address to be prefetched.
+-void _m_prefetch(void *__P);
++static __inline__ void __attribute__((__always_inline__, __nodebug__))
++_m_prefetch(void *__P)
++{
++  __builtin_prefetch (__P, 0, 3 /* _MM_HINT_T0 */);
++}
+ 
+ /// Loads a memory sequence containing the specified memory address into
+ ///    the L1 data cache and sets the cache-coherency state to modified.
+@@ -48,10 +48,13 @@
+ ///
+ /// \param __P
+ ///    A pointer specifying the memory address to be prefetched.
+-void _m_prefetchw(volatile const void *__P);
+-
+-#if defined(__cplusplus)
+-} // extern "C"
+-#endif
++static __inline__ void __attribute__((__always_inline__, __nodebug__))
++_m_prefetchw(volatile const void *__P)
++{
++#pragma clang diagnostic push
++#pragma clang diagnostic ignored "-Wcast-qual"
++  __builtin_prefetch ((const void*)__P, 1, 3 /* _MM_HINT_T0 */);
++#pragma clang diagnostic pop
++}
+ 
+ #endif /* __PRFCHWINTRIN_H */
+diff -ruN --strip-trailing-cr a/clang/lib/Headers/xmmintrin.h b/clang/lib/Headers/xmmintrin.h
+--- a/clang/lib/Headers/xmmintrin.h
++++ b/clang/lib/Headers/xmmintrin.h
+@@ -2197,7 +2197,10 @@
+ #define _MM_HINT_T2  1
+ #define _MM_HINT_NTA 0
+ 
+-#if 0
++#ifndef _MSC_VER
++/* FIXME: We have to #define this because "sel" must be a constant integer, and
++   Sema doesn't do any form of constant propagation yet. */
++
+ /// Loads one cache line of data from the specified address to a location
+ ///    closer to the processor.
+ ///
+@@ -2222,10 +2225,6 @@
+ ///    be generated. \n
+ ///    _MM_HINT_T2: Move data using the T2 hint. The PREFETCHT2 instruction will
+ ///    be generated.
+-///
+-/// _mm_prefetch is implemented as a "library builtin" directly in Clang,
+-/// similar to how it is done in MSVC. Clang will warn if the user doesn't
+-/// include xmmintrin.h or immintrin.h.
+ #define _mm_prefetch(a, sel) (__builtin_prefetch((const void *)(a), \
+                                                  ((sel) >> 2) & 1, (sel) & 0x3))
+ #endif
diff --git a/third_party/llvm/workspace.bzl b/third_party/llvm/workspace.bzl
index c4a6676..dc3cead 100644
--- a/third_party/llvm/workspace.bzl
+++ b/third_party/llvm/workspace.bzl
@@ -4,8 +4,8 @@ load("//third_party:repo.bzl", "tf_http_archive")
 
 def repo(name):
     """Imports LLVM."""
-    LLVM_COMMIT = "386af4a5c64ab75eaee2448dc38f2e34a40bfed0"
-    LLVM_SHA256 = "4b752a2dfb5e4e55cf9812a353bce7e437e0852f4eef64929f48d74732080c50"
+    LLVM_COMMIT = "f8287f6c373fcf993643dd6f0e30dde304c1be73"
+    LLVM_SHA256 = "add2841174abc79c45aa309bdf0cf631aa8f97e7a4df57dcfca57c60df27527f"
 
     tf_http_archive(
         name = name,
