//  Copyright (c) Qualcomm Innovation Center, Inc.
//  All Rights Reserved.

#include "tensorflow/lite/experimental/litert/vendors/qualcomm/core/builders/matmul_op_builder.h"

namespace qnn {

std::vector<OpWrapper> BuildMatmulOp(
    TensorPool& tensor_pool, const std::vector<TensorWrapperRef>& inputs,
    const std::vector<TensorWrapperRef>& outputs, const bool adj_x,
    const bool adj_y) {
  std::vector<OpWrapper> res;

  auto& matmul_op = CreateOpWrapper(res, QNN_OP_MAT_MUL);
  for (const auto& input : inputs) {
    matmul_op.AddInputTensor(input);
  }
  matmul_op.AddOutputTensor(outputs[0]);
  matmul_op.AddScalarParam<bool>(QNN_OP_MAT_MUL_PARAM_TRANSPOSE_IN0, adj_x);
  matmul_op.AddScalarParam<bool>(QNN_OP_MAT_MUL_PARAM_TRANSPOSE_IN1, adj_y);

  return res;
}

}  // namespace qnn
