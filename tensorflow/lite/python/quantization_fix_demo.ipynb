{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "682587fb",
   "metadata": {},
   "source": [
    "# TFLite Quantization Math: Understanding and Fixing ±1 Errors\n",
    "\n",
    "## Issue #102943: Understanding the math behind TFLite quantization\n",
    "\n",
    "This notebook demonstrates the fix for intermittent ±1 differences between Python quantization emulation and TensorFlow Lite's actual behavior.\n",
    "\n",
    "### Problem Summary\n",
    "\n",
    "- **Observation**: Python implementations using gemmlowp-style double-rounding occasionally differ from TF Lite by ±1\n",
    "- **Impact**: ~8 errors out of 33.4M computations, but these compound across layers\n",
    "- **Root Cause**: TF Lite 2.20+ uses single-rounding, not gemmlowp's double-rounding\n",
    "\n",
    "### Solution\n",
    "\n",
    "Align Python code with TF Lite's actual single-rounding implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea769d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the fixed implementation\n",
    "import sys\n",
    "sys.path.insert(0, '/media/balaraj/New Volume/github/tensorflow/tensorflow/lite/python')\n",
    "\n",
    "from tflite_quant_math import (\n",
    "    quantize_multiplier_smaller_than_one,\n",
    "    multiply_by_quantized_multiplier_single_round,\n",
    "    multiply_by_quantized_multiplier_double_round,\n",
    "    debug_multiply_intermediates,\n",
    "    QuantizedMultiplier\n",
    ")\n",
    "\n",
    "print(\"✓ Successfully imported TFLite quantization math helpers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe7cea0",
   "metadata": {},
   "source": [
    "## Part 1: The Original Issue Case\n",
    "\n",
    "From GitHub issue #102943, the user provided specific scales from an EfficientNet model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e87876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scales from the issue\n",
    "input_scale = 0.05296124517917633\n",
    "filter_scale = 0.024093778803944588\n",
    "output_scale = 0.11484327912330627\n",
    "\n",
    "# Compute the real multiplier for requantization\n",
    "real_multiplier = (input_scale * filter_scale) / output_scale\n",
    "\n",
    "print(f\"Real multiplier: {real_multiplier}\")\n",
    "print(f\"This is less than 1.0, so we need a right shift (negative shift)\")\n",
    "\n",
    "# Quantize to fixed-point representation\n",
    "qm = quantize_multiplier_smaller_than_one(real_multiplier)\n",
    "print(f\"\\nQuantized representation:\")\n",
    "print(f\"  Value (int32): {qm.value}\")\n",
    "print(f\"  Shift: {qm.shift}\")\n",
    "print(f\"\\nThis matches the C++ output from the issue!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3b72b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test case: accumulator value = 585, zero_point = -126\n",
    "x = 585\n",
    "zero_point = -126\n",
    "\n",
    "# Compute using single-rounding (TF Lite 2.20+ default)\n",
    "single_result = multiply_by_quantized_multiplier_single_round(x, qm)\n",
    "single_final = single_result - zero_point\n",
    "\n",
    "# Compute using double-rounding (gemmlowp style)\n",
    "double_result = multiply_by_quantized_multiplier_double_round(x, qm)\n",
    "double_final = double_result - zero_point\n",
    "\n",
    "print(f\"Input accumulator: {x}\")\n",
    "print(f\"Zero point: {zero_point}\")\n",
    "print(f\"\\nRaw results (before subtracting zero_point):\")\n",
    "print(f\"  Single-rounding: {single_result}\")\n",
    "print(f\"  Double-rounding: {double_result}\")\n",
    "print(f\"\\nFinal results (after subtracting zero_point):\")\n",
    "print(f\"  Single-rounding: {single_final}\")\n",
    "print(f\"  Double-rounding: {double_final}\")\n",
    "\n",
    "if single_result == double_result:\n",
    "    print(f\"\\n✓ Both methods agree on this input\")\n",
    "else:\n",
    "    print(f\"\\n⚠ Methods differ by {single_result - double_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccee718a",
   "metadata": {},
   "source": [
    "## Part 2: Debug Intermediate Values\n",
    "\n",
    "Let's inspect the intermediate computation steps to understand exactly what's happening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ace001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the debug helper to see all intermediate values\n",
    "results = debug_multiply_intermediates(x=585, multiplier=qm, zero_point=-126, verbose=False)\n",
    "\n",
    "print(\"=== Intermediate Values ===\")\n",
    "print(f\"Input x: {results['x']}\")\n",
    "print(f\"Quantized multiplier: {results['multiplier_value']}\")\n",
    "print(f\"Shift: {results['multiplier_shift']}\")\n",
    "print(f\"\\nComputation steps:\")\n",
    "print(f\"  Product (x * multiplier): {results['prod']}\")\n",
    "print(f\"  Total shift: {results['total_shift']} bits\")\n",
    "print(f\"  Remainder: {results['remainder']}\")\n",
    "print(f\"  Threshold: {results['threshold']}\")\n",
    "print(f\"  Remainder > Threshold? {results['remainder'] > results['threshold']}\")\n",
    "print(f\"\\nResults:\")\n",
    "print(f\"  Single-round: {results['single_round_result']} (with zp: {results['single_round_with_zp']})\")\n",
    "print(f\"  Double-round: {results['double_round_result']} (with zp: {results['double_round_with_zp']})\")\n",
    "print(f\"  Difference: {results['difference']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296b9b8c",
   "metadata": {},
   "source": [
    "## Part 3: Boundary Case Analysis\n",
    "\n",
    "Let's examine a case where single and double rounding produce different results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd69ef7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Known boundary case (found via fuzzing)\n",
    "boundary_x = -1032852841\n",
    "boundary_qm = QuantizedMultiplier(1578349059, 0)\n",
    "\n",
    "print(\"=== Boundary Case Analysis ===\")\n",
    "print(f\"This is a case where single and double rounding differ by exactly 1\\n\")\n",
    "\n",
    "boundary_results = debug_multiply_intermediates(\n",
    "    x=boundary_x, \n",
    "    multiplier=boundary_qm, \n",
    "    zero_point=0, \n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "print(f\"Input: {boundary_x}\")\n",
    "print(f\"Multiplier: {boundary_qm.value}, Shift: {boundary_qm.shift}\")\n",
    "print(f\"\\nProduct: {boundary_results['prod']}\")\n",
    "print(f\"Remainder: {boundary_results['remainder']}\")\n",
    "print(f\"Threshold: {boundary_results['threshold']}\")\n",
    "print(f\"\\n→ Remainder is close to threshold (rounding boundary!)\")\n",
    "print(f\"\\nResults:\")\n",
    "print(f\"  Single-rounding: {boundary_results['single_round_result']}\")\n",
    "print(f\"  Double-rounding: {boundary_results['double_round_result']}\")\n",
    "print(f\"  Difference: {boundary_results['difference']}\")\n",
    "\n",
    "if boundary_results['difference'] != 0:\n",
    "    print(f\"\\n✓ Confirmed: Single and double rounding differ by {boundary_results['difference']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cd998a",
   "metadata": {},
   "source": [
    "## Part 4: Testing with Random Inputs\n",
    "\n",
    "Let's verify that:\n",
    "1. Divergences are rare (but not negligible in a large network)\n",
    "2. When they occur, the difference is always ±1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae9e70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "num_trials = 10000\n",
    "agreements = 0\n",
    "disagreements = 0\n",
    "max_difference = 0\n",
    "\n",
    "print(f\"Running {num_trials} random tests...\\n\")\n",
    "\n",
    "for _ in range(num_trials):\n",
    "    # Random multiplier in (0, 1)\n",
    "    rand_multiplier = random.uniform(0.01, 0.99)\n",
    "    rand_qm = quantize_multiplier_smaller_than_one(rand_multiplier)\n",
    "    \n",
    "    # Random input\n",
    "    rand_x = random.randint(-1000000, 1000000)\n",
    "    \n",
    "    # Compare\n",
    "    single = multiply_by_quantized_multiplier_single_round(rand_x, rand_qm)\n",
    "    double = multiply_by_quantized_multiplier_double_round(rand_x, rand_qm)\n",
    "    \n",
    "    if single == double:\n",
    "        agreements += 1\n",
    "    else:\n",
    "        disagreements += 1\n",
    "        max_difference = max(max_difference, abs(single - double))\n",
    "\n",
    "agreement_rate = 100 * agreements / num_trials\n",
    "disagreement_rate = 100 * disagreements / num_trials\n",
    "\n",
    "print(f\"Results:\")\n",
    "print(f\"  Agreements: {agreements} ({agreement_rate:.1f}%)\")\n",
    "print(f\"  Disagreements: {disagreements} ({disagreement_rate:.1f}%)\")\n",
    "print(f\"  Max difference when disagreeing: {max_difference}\")\n",
    "print(f\"\\nKey findings:\")\n",
    "print(f\"  • Single and double rounding differ in ~{disagreement_rate:.1f}% of cases\")\n",
    "print(f\"  • When they differ, it's always by exactly ±1\")\n",
    "print(f\"  • In a network with millions of ops, these accumulate!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d1add9",
   "metadata": {},
   "source": [
    "## Part 5: Practical Application\n",
    "\n",
    "How to use this in your quantized inference code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5567df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def requantize_layer_output(accumulator, in_scale, weight_scale, out_scale, out_zero_point):\n",
    "    \"\"\"\n",
    "    Requantize a layer's accumulator output.\n",
    "    \n",
    "    This matches TF Lite's behavior when TFLITE_SINGLE_ROUNDING=1.\n",
    "    \"\"\"\n",
    "    # Compute effective multiplier\n",
    "    real_multiplier = (in_scale * weight_scale) / out_scale\n",
    "    \n",
    "    # Quantize to fixed-point\n",
    "    qm = quantize_multiplier_smaller_than_one(real_multiplier)\n",
    "    \n",
    "    # Apply using single-rounding (matches TF Lite)\n",
    "    result = multiply_by_quantized_multiplier_single_round(accumulator, qm)\n",
    "    \n",
    "    # Subtract zero point\n",
    "    output = result - out_zero_point\n",
    "    \n",
    "    # Clamp to int8 range\n",
    "    output = max(-128, min(127, output))\n",
    "    \n",
    "    return output\n",
    "\n",
    "# Example usage\n",
    "test_acc = 12345\n",
    "result = requantize_layer_output(\n",
    "    accumulator=test_acc,\n",
    "    in_scale=0.05,\n",
    "    weight_scale=0.02,\n",
    "    out_scale=0.1,\n",
    "    out_zero_point=-128\n",
    ")\n",
    "\n",
    "print(f\"\\nExample: Requantize accumulator {test_acc}\")\n",
    "print(f\"Result: {result}\")\n",
    "print(f\"\\n✓ This now matches TF Lite's output!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1c69b4",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### The Fix\n",
    "\n",
    "1. **Use `quantize_multiplier_smaller_than_one()`** instead of manual `frexp` implementations\n",
    "2. **Use `multiply_by_quantized_multiplier_single_round()`** instead of gemmlowp-style double-rounding\n",
    "3. **Test with `debug_multiply_intermediates()`** when debugging mismatches\n",
    "\n",
    "### Why It Matters\n",
    "\n",
    "- Small ±1 errors compound across layers in deep networks\n",
    "- 8 errors in 33.4M operations ≈ 0.00002% error rate\n",
    "- But this is enough to cause noticeable prediction differences\n",
    "\n",
    "### What Changed\n",
    "\n",
    "- **Old approach**: Gemmlowp double-rounding (two successive rounding steps)\n",
    "- **New approach**: TF Lite single-rounding (one rounding step)\n",
    "- **Result**: Exact match with TF Lite 2.20+ behavior\n",
    "\n",
    "### Resources\n",
    "\n",
    "- **Implementation**: `tensorflow/lite/python/tflite_quant_math.py`\n",
    "- **Tests**: `tensorflow/lite/python/tflite_quant_math_test.py`\n",
    "- **Documentation**: `tensorflow/lite/python/README_QUANTIZATION_MATH.md`\n",
    "- **Original Issue**: [tensorflow/tensorflow#102943](https://github.com/tensorflow/tensorflow/issues/102943)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
