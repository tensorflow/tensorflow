path: "tensorflow.keras.optimizers.Adagrad"
tf_class {
  is_instance: "<class \'tensorflow.python.keras._impl.keras.optimizers.Adagrad\'>"
  is_instance: "<class \'tensorflow.python.keras._impl.keras.optimizers.Optimizer\'>"
  is_instance: "<type \'object\'>"
  member_method {
    name: "__init__"
    argspec: "args=[\'self\', \'lr\', \'epsilon\', \'decay\'], varargs=None, keywords=kwargs, defaults=[\'0.01\', \'1e-08\', \'0.0\'], "
  }
  member_method {
    name: "from_config"
    argspec: "args=[\'cls\', \'config\'], varargs=None, keywords=None, defaults=None"
  }
  member_method {
    name: "get_config"
    argspec: "args=[\'self\'], varargs=None, keywords=None, defaults=None"
  }
  member_method {
    name: "get_gradients"
    argspec: "args=[\'self\', \'loss\', \'params\'], varargs=None, keywords=None, defaults=None"
  }
  member_method {
    name: "get_updates"
    argspec: "args=[\'self\', \'loss\', \'params\'], varargs=None, keywords=None, defaults=None"
  }
  member_method {
    name: "get_weights"
    argspec: "args=[\'self\'], varargs=None, keywords=None, defaults=None"
  }
  member_method {
    name: "set_weights"
    argspec: "args=[\'self\', \'weights\'], varargs=None, keywords=None, defaults=None"
  }
}
