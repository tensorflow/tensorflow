# RUN: tf_tfl_translate -tf-input-arrays=input0,input1 \
# RUN:                  -tf-input-shapes=4:4 \
# RUN:                  -tf-input-data-types=DT_FLOAT,DT_FLOAT \
# RUN:                  -tf-output-arrays=Add \
# RUN:                  -tf-inference-type=DT_QUINT8 \
# RUN:                  -tf-input-min-values='-2,-3' \
# RUN:                  -tf-input-max-values='2,3' \
# RUN:                  --quant-stats=%s.stats \
# RUN:                  %s -o - --output-mlir 2>&1 \
# RUN:  | FileCheck --check-prefix=MLIR %s
# RUN: tf_tfl_translate -tf-input-arrays=input0,input1 \
# RUN:                  -tf-input-shapes=4:4 \
# RUN:                  -tf-input-data-types=DT_FLOAT,DT_FLOAT \
# RUN:                  -tf-output-arrays=Add \
# RUN:                  -tf-inference-type=DT_QUINT8 \
# RUN:                  -tf-input-min-values='-2,-3' \
# RUN:                  -tf-input-max-values='2,3' \
# RUN:                  --quant-stats=%s.stats \
# RUN:                  %s -o - \
# RUN:  | flatbuffer_to_string - \
# RUN:  | FileCheck %s

node {
  name: "Add"
  op: "Add"
  input: "input0"
  input: "input1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "input0"
  op: "Placeholder"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "input1"
  op: "Placeholder"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
}
versions {
  producer: 27
}

# MLIR-LABEL: func @main(%arg0: tensor<4x!quant.uniform<u8:f32, 0.015686274509803921:128>>, %arg1: tensor<4x!quant.uniform<u8:f32, 0.023529411764705882:128>>) -> tensor<4x!quant.uniform<u8:f32, 0.0078431372549019607:128>>
# MLIR-SAME:    attributes {tf.entry_function = {control_outputs = "", inputs = "input0,input1", outputs = "Add"}} {
# MLIR-NEXT:    %[[add:.*]] = tfl.add(%arg0, %arg1) {fused_activation_function = "NONE"} : (tensor<4x!quant.uniform<u8:f32, 0.015686274509803921:128>>, tensor<4x!quant.uniform<u8:f32, 0.023529411764705882:128>>) -> tensor<4x!quant.uniform<u8:f32, 0.0078431372549019607:128>>
# MLIR-NEXT:    return %[[add]] : tensor<4x!quant.uniform<u8:f32, 0.0078431372549019607:128>>
# MLIR-NEXT:  }

# CHECK-LABEL: {
# CHECK-NEXT:  version: 3,
# CHECK-NEXT:  operator_codes: [ {
# CHECK-NEXT:    version: 1
# CHECK-NEXT:  } ],
# CHECK-NEXT:    subgraphs: [ {
# CHECK-NEXT:      tensors: [ {
# CHECK-NEXT:        shape: [ 4 ],
# CHECK-NEXT:        type: UINT8,
# CHECK-NEXT:        buffer: 1,
# CHECK-NEXT:        name: "input0",
# CHECK-NEXT:        quantization: {
# CHECK-NEXT:          scale: [ 0.015686 ],
# CHECK-NEXT:          zero_point: [ 128 ]
# CHECK-NEXT:        }
# CHECK-NEXT:      }, {
# CHECK-NEXT:        shape: [ 4 ],
# CHECK-NEXT:        type: UINT8,
# CHECK-NEXT:        buffer: 2,
# CHECK-NEXT:        name: "input1",
# CHECK-NEXT:        quantization: {
# CHECK-NEXT:          scale: [ 0.023529 ],
# CHECK-NEXT:          zero_point: [ 128 ]
# CHECK-NEXT:        }
# CHECK-NEXT:      }, {
# CHECK-NEXT:        shape: [ 4 ],
# CHECK-NEXT:        type: UINT8,
# CHECK-NEXT:        buffer: 3,
# CHECK-NEXT:        name: "Add",
# CHECK-NEXT:        quantization: {
# CHECK-NEXT:          scale: [ 0.007843 ],
# CHECK-NEXT:          zero_point: [ 128 ]
# CHECK-NEXT:        }
# CHECK-NEXT:      } ],
# CHECK-NEXT:      inputs: [ 0, 1 ],
# CHECK-NEXT:      outputs: [ 2 ],
# CHECK-NEXT:      operators: [ {
# CHECK-NEXT:        inputs: [ 0, 1 ],
# CHECK-NEXT:        outputs: [ 2 ],
# CHECK-NEXT:        builtin_options_type: AddOptions,
# CHECK-NEXT:        builtin_options: {
# CHECK-EMPTY:
# CHECK-NEXT:        }
# CHECK-NEXT:      } ],
# CHECK-NEXT:      name: "main"
# CHECK-NEXT:    } ],
# CHECK-NEXT:    description: "MLIR Converted.",
# CHECK-NEXT:    buffers: [ {
# CHECK-EMPTY:
# CHECK-NEXT:    }, {
# CHECK-EMPTY:
# CHECK-NEXT:    }, {
# CHECK-EMPTY:
# CHECK-NEXT:    }, {
# CHECK:          data: [ 49, 46, 53, 46, 48, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 ]
# CHECK-NEXT:    } ]

