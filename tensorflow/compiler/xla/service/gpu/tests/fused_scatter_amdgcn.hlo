// RUN: hlo_to_llvm_ir %s | FileCheck %s

// NOTE: Assertions have been autogenerated by utils/generate-test-checks.py

// CHECK-LABEL: entry:
// CHECK:         %[[VAL_0:.*]] = call i32 @llvm.amdgcn.workgroup.id.x(), !range !4
// CHECK:         %[[VAL_1:.*]] = call i32 @llvm.amdgcn.workitem.id.x(), !range !5
// CHECK:         %[[VAL_2:.*]] = mul nuw nsw i32 %[[VAL_0]], 2
// CHECK:         %[[VAL_3:.*]] = add nuw nsw i32 %[[VAL_2]], %[[VAL_1]]
// CHECK:         %[[VAL_4:.*]] = icmp ult i32 %[[VAL_3]], 2
// CHECK:         call void @llvm.assume(i1 %[[VAL_4]])
// CHECK:         %[[VAL_5:.*]] = udiv i32 %[[VAL_3]], 1
// CHECK:         %[[VAL_6:.*]] = icmp ult i32 %[[VAL_3]], 2
// CHECK:         br i1 %[[VAL_6]], label %[[VAL_7:.*]], label %[[VAL_8:.*]]
// CHECK:       indices.in_bounds-after:                          ; preds = %[[VAL_7]], %[[VAL_9:.*]]
// CHECK:         ret void
// CHECK:       indices.in_bounds-true:                           ; preds = %[[VAL_9]]
// CHECK:         %[[VAL_10:.*]] = getelementptr inbounds i32, ptr %[[VAL_11:.*]], i32 %[[VAL_3]]
// CHECK:         %[[VAL_12:.*]] = load i32, ptr %[[VAL_10]], align 4, !invariant.load !6
// CHECK:         %[[VAL_13:.*]] = getelementptr inbounds i32, ptr %[[VAL_11:.*]], i32 %[[VAL_3]]
// CHECK:         %[[VAL_14:.*]] = load i32, ptr %[[VAL_13]], align 4, !invariant.load !6
// CHECK:         %[[VAL_15:.*]] = add i32 %[[VAL_12]], %[[VAL_14]]
// CHECK:         %[[VAL_16:.*]] = getelementptr inbounds i32, ptr %[[VAL_17:.*]], i32 %[[VAL_3]]
// CHECK:         store i32 %[[VAL_15]], ptr %[[VAL_16]], align 4
// CHECK:         br label %[[VAL_8]]
// CHECK:       entry:
// CHECK:         %[[VAL_18:.*]] = call i32 @llvm.amdgcn.workgroup.id.x(), !range !4
// CHECK:         %[[VAL_19:.*]] = call i32 @llvm.amdgcn.workitem.id.x(), !range !7
// CHECK:         %[[VAL_20:.*]] = mul nuw nsw i32 %[[VAL_18]], 6
// CHECK:         %[[VAL_21:.*]] = add nuw nsw i32 %[[VAL_20]], %[[VAL_19]]
// CHECK:         %[[VAL_22:.*]] = icmp ult i32 %[[VAL_21]], 6
// CHECK:         call void @llvm.assume(i1 %[[VAL_22]])
// CHECK:         %[[VAL_23:.*]] = udiv i32 %[[VAL_21]], 1
// CHECK:         %[[VAL_24:.*]] = urem i32 %[[VAL_23]], 3
// CHECK:         %[[VAL_25:.*]] = udiv i32 %[[VAL_21]], 3
// CHECK:         %[[VAL_26:.*]] = icmp ult i32 %[[VAL_21]], 6
// CHECK:         br i1 %[[VAL_26]], label %[[VAL_27:.*]], label %[[VAL_28:.*]]
// CHECK:       updates.in_bounds-after:                          ; preds = %[[VAL_27]], %[[VAL_29:.*]]
// CHECK:         ret void
// CHECK:       updates.in_bounds-true:                           ; preds = %[[VAL_29]]
// CHECK:         %[[VAL_30:.*]] = getelementptr inbounds i32, ptr %[[VAL_31:.*]], i32 %[[VAL_21]]
// CHECK:         %[[VAL_32:.*]] = load i32, ptr %[[VAL_30]], align 4, !invariant.load !6
// CHECK:         %[[VAL_33:.*]] = getelementptr inbounds i32, ptr %[[VAL_31:.*]], i32 %[[VAL_21]]
// CHECK:         %[[VAL_34:.*]] = load i32, ptr %[[VAL_33]], align 4, !invariant.load !6
// CHECK:         %[[VAL_35:.*]] = add i32 %[[VAL_32]], %[[VAL_34]]
// CHECK:         %[[VAL_36:.*]] = getelementptr inbounds i32, ptr %[[VAL_37:.*]], i32 %[[VAL_21]]
// CHECK:         store i32 %[[VAL_35]], ptr %[[VAL_36]], align 4
// CHECK:         br label %[[VAL_28]]
// CHECK:       entry:
// CHECK:         %[[VAL_38:.*]] = call i32 @llvm.amdgcn.workgroup.id.x(), !range !4
// CHECK:         %[[VAL_39:.*]] = call i32 @llvm.amdgcn.workitem.id.x(), !range !8
// CHECK:         %[[VAL_40:.*]] = mul nuw nsw i32 %[[VAL_38]], 9
// CHECK:         %[[VAL_41:.*]] = add nuw nsw i32 %[[VAL_40]], %[[VAL_39]]
// CHECK:         %[[VAL_42:.*]] = icmp ult i32 %[[VAL_41]], 9
// CHECK:         call void @llvm.assume(i1 %[[VAL_42]])
// CHECK:         %[[VAL_43:.*]] = udiv i32 %[[VAL_41]], 1
// CHECK:         %[[VAL_44:.*]] = urem i32 %[[VAL_43]], 3
// CHECK:         %[[VAL_45:.*]] = udiv i32 %[[VAL_41]], 3
// CHECK:         %[[VAL_46:.*]] = icmp ult i32 %[[VAL_41]], 9
// CHECK:         br i1 %[[VAL_46]], label %[[VAL_47:.*]], label %[[VAL_48:.*]]
// CHECK:       operand.in_bounds-after:                          ; preds = %[[VAL_47]], %[[VAL_49:.*]]
// CHECK:         ret void
// CHECK:       operand.in_bounds-true:                           ; preds = %[[VAL_49]]
// CHECK:         %[[VAL_50:.*]] = getelementptr inbounds i32, ptr %[[VAL_51:.*]], i32 %[[VAL_41]]
// CHECK:         %[[VAL_52:.*]] = load i32, ptr %[[VAL_50]], align 4, !invariant.load !6
// CHECK:         %[[VAL_53:.*]] = getelementptr inbounds i32, ptr %[[VAL_51:.*]], i32 %[[VAL_41]]
// CHECK:         %[[VAL_54:.*]] = load i32, ptr %[[VAL_53]], align 4, !invariant.load !6
// CHECK:         %[[VAL_55:.*]] = add i32 %[[VAL_52]], %[[VAL_54]]
// CHECK:         %[[VAL_56:.*]] = getelementptr inbounds i32, ptr %[[VAL_57:.*]], i32 %[[VAL_41]]
// CHECK:         store i32 %[[VAL_55]], ptr %[[VAL_56]], align 4
// CHECK:         br label %[[VAL_48]]
// CHECK:       entry:
// CHECK:         %[[VAL_58:.*]] = alloca i32, align 4, addrspace(5)
// CHECK:         %[[VAL_59:.*]] = call i32 @llvm.amdgcn.workgroup.id.x(), !range !4
// CHECK:         %[[VAL_60:.*]] = call i32 @llvm.amdgcn.workitem.id.x(), !range !7
// CHECK:         %[[VAL_61:.*]] = mul nuw nsw i32 %[[VAL_59]], 6
// CHECK:         %[[VAL_62:.*]] = add nuw nsw i32 %[[VAL_61]], %[[VAL_60]]
// CHECK:         %[[VAL_63:.*]] = icmp ult i32 %[[VAL_62]], 6
// CHECK:         call void @llvm.assume(i1 %[[VAL_63]])
// CHECK:         %[[VAL_64:.*]] = udiv i32 %[[VAL_62]], 1
// CHECK:         %[[VAL_65:.*]] = urem i32 %[[VAL_64]], 3
// CHECK:         %[[VAL_66:.*]] = udiv i32 %[[VAL_62]], 3
// CHECK:         %[[VAL_67:.*]] = icmp ult i32 %[[VAL_62]], 6
// CHECK:         br i1 %[[VAL_67]], label %[[VAL_68:.*]], label %[[VAL_69:.*]]
// CHECK:       scatter.in_bounds-after:                          ; preds = %[[VAL_70:.*]], %[[VAL_71:.*]]
// CHECK:         ret void
// CHECK:       scatter.in_bounds-true:                           ; preds = %[[VAL_71]]
// CHECK:         %[[VAL_72:.*]] = getelementptr inbounds [2 x i32], ptr %[[VAL_73:.*]], i32 0, i32 %[[VAL_66]]
// CHECK:         %[[VAL_74:.*]] = load i32, ptr %[[VAL_72]], align 4, !invariant.load !6
// CHECK:         %[[VAL_75:.*]] = add i32 0, %[[VAL_74]]
// CHECK:         %[[VAL_76:.*]] = icmp ult i32 %[[VAL_74]], 3
// CHECK:         %[[VAL_77:.*]] = and i1 true, %[[VAL_76]]
// CHECK:         br i1 %[[VAL_77]], label %[[VAL_78:.*]], label %[[VAL_70]]
// CHECK:       scatter.in_bounds-after3:                         ; preds = %[[VAL_78]], %[[VAL_68]]
// CHECK:         br label %[[VAL_69]]
// CHECK:       scatter.in_bounds-true2:                          ; preds = %[[VAL_68]]
// CHECK:         %[[VAL_79:.*]] = getelementptr inbounds [3 x [3 x i32]], ptr %[[VAL_80:.*]], i32 0, i32 %[[VAL_75]], i32 %[[VAL_65]]
// CHECK:         %[[VAL_81:.*]] = getelementptr inbounds i32, ptr %[[VAL_82:.*]], i32 %[[VAL_62]]
// CHECK:         %[[VAL_83:.*]] = load i32, ptr %[[VAL_81]], align 4, !invariant.load !6
// CHECK:         store i32 %[[VAL_83]], ptr  addrspace(5)  %[[VAL_58]], align 4
// CHECK:         %[[VAL_84:.*]] = load i32, ptr addrspace(5)  %[[VAL_58]], align 4
// CHECK:         store atomic i32 %[[VAL_84]], ptr %[[VAL_79]] unordered, align 4
// CHECK:         br label %[[VAL_70]]

HloModule TensorFlowScatterV1

update_s32 (lhs: s32[], rhs: s32[]) -> s32[] {
  lhs = s32[] parameter(0)
  ROOT rhs = s32[] parameter(1)
}

ENTRY main {
  p0 = s32[3,3] parameter(0)
  operand = s32[3,3] add(p0, p0)
  p1 = s32[2] parameter(1)
  indices = s32[2] add(p1, p1)
  p2 = s32[2,3] parameter(2)
  updates = s32[2,3] add(p2, p2)
  ROOT scatter = s32[3,3] scatter(operand, indices, updates),
      to_apply=update_s32,
      update_window_dims={1},
      inserted_window_dims={0},
      scatter_dims_to_operand_dims={0},
      index_vector_dim=1
}
